{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very basic SAE Training Tutorial\n",
    "\n",
    "Please note that it is very easy for tutorial code to go stale so please have a low bar for raising an issue in the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sae_lens.training.config import LanguageModelSAERunnerConfig\n",
    "from sae_lens.training.lm_runner import language_model_sae_runner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Evaluation (Feel Free to Skip)\n",
    "\n",
    "We'll use the runner to train an SAE on a TinyStories Model. This is a very small model so we can train an SAE on it quite quickly. Before we get started, let's load in the model with `transformer_lens` and see what it can do. \n",
    "\n",
    "TransformerLens gives us 2 functions that are useful here (and circuits viz provides a third):\n",
    "1. `transformer_lens.utils.test_prompt` will help us see when the model can infer one token.\n",
    "2. `HookedTransformer.generate` will help us see what happens when we sample from the model.\n",
    "3. `circuitsvis.logits.token_log_probs` will help us visualize the log probs of tokens at several positions in a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-1L-21M\"\n",
    ")  # This will wrap huggingface models and has lots of nice utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a vibe for a model using `model.generate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by generating some stories using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use generate to get 10 completeions with temperature 1. Feel free to play with the prompt to make it more interesting.\n",
    "for i in range(5):\n",
    "    display(\n",
    "        model.generate(\n",
    "            \"Once upon a time\",\n",
    "            stop_at_eos=False,  # avoids a bug on MPS\n",
    "            temperature=1,\n",
    "            verbose=False,\n",
    "            max_new_tokens=50,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we notice is that the model seems to be able to repeat the name of the main character very consistently. It can output a pronoun intead but in some stories will repeat the protagonists name. This seems like an interesting capability to analyse with SAEs. To better understand the models ability to remember the protagonists name, let's extract a prompt where the next character is determined and use the \"test_prompt\" utility from TransformerLens to check the ranking of the token for that name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot checking model abilities with `transformer_lens.utils.test_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "# Test the model with a prompt\n",
    "test_prompt(\n",
    "    \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little girl. On her big adventure,\",\n",
    "    \" Lily\",\n",
    "    model,\n",
    "    prepend_space_to_answer=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, we see that the model assigns ~ 70% probability to \"she\" being the next token, and a 13% chance to \" Lily\" being the next token. Other names like Lucy or Anna are not highly ranked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Model Capabilities with Log Probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at token ranking for a single prompt is interesting, but a much higher through way to understand models is to look at token log probs for all tokens in text. We can use the `circuits_vis` package to get a nice visualization where we can see tokenization, and hover to get the top5 tokens by log probability. Darker tokens are tokens where the model assigned a higher probability to the actual next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
    "\n",
    "# Let's make a longer prompt and see the log probabilities of the tokens\n",
    "example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")\n",
    "# hover on the output to see the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine `model.generate` and the token log probs visualization to see the log probs on text generated by the model. Note that we can play with the temperature and this should sample less likely trajectories according to the model. I've increased the maximum number of tokens in order to get a full story.\n",
    "\n",
    "Some things to explore:\n",
    "- Which tokens does the model assign high probability to? Can you see how the model should know which word comes next?\n",
    "- What happens if you increase / decrease the temperature?\n",
    "- Do the rankings of tokens seem sensible to you? What about where the model doesn't assign a high probability to the token which came next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = model.generate(\n",
    "    \"Once upon a time\",\n",
    "    stop_at_eos=False,  # avoids a bug on MPS\n",
    "    temperature=1,\n",
    "    verbose=True,\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an SAE\n",
    "\n",
    "Now we're ready to train out SAE. We'll make a runner config, instantiate the runner and the rest is taken care of for us!\n",
    "\n",
    "During training, you use weights and biases to check key metrics which indicate how well we are able to optimize the variables we care about.\n",
    "\n",
    "To get a better sense of which variables to look at, you can read my (Joseph's) post [here](https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream) and especially look at my weights and biases report [here](https://links-cdn.wandb.ai/wandb-public-images/links/jbloom/uue9i416.html).\n",
    "\n",
    "A few tips:\n",
    "- Feel free to reorganize your wandb dashboard to put L0, CE_Loss_score, explained variance and other key metrics in one section at the top.\n",
    "- Make a [run comparer](https://docs.wandb.ai/guides/app/features/panels/run-comparer) when tuning hyperparameters.\n",
    "- You can download the resulting sparse autoencoder / sparsity estimate from wandb and upload them to huggingface if you want to share your SAE with other.\n",
    "    - cfg.json (training config)\n",
    "    - sae_weight.safetensors (model weights)\n",
    "    - sparsity.safetensors (sparsity estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Out\n",
    "\n",
    "I've tuned the hyperparameters below for a decent SAE which achieves 93% CE Loss recovered and an L0 of ~60, and runs in about 22 minutes on an A100 (sorry peeps, that is the kinda hardware you'll want to be using moving on). I think you could hyperparameter tune toward a much better SAE in the future (and would welcome PR's that improve on the hyperparameters here!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12208| MSE Loss 0.046 | L1 0.024: 100%|█████████▉| 49999872/50000000 [21:53<00:00, 20740.30it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f17a1a615184dcaab0752df36759ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='128.133 MB of 128.133 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_learning_rate</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████████</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▄▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/CE_loss_score</td><td>▁▇▄▄▅▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>▄▃▄▄▂▃▅▄▄▄▄▄▃▃▆▄▃▅▆▅▅▄▄█▆▄▁▄▅▅▄▂▁▁▄▃▄▃▇▄</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>█▂▅▅▄▃▃▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>▂▅▃▃▃▃▇▅▂▇▇▇▃▁▄█▃▅▄▃▆▅▃▃▅▆▆▆▄▅▇▃▆▂██▇▂▇▄</td></tr><tr><td>metrics/explained_variance</td><td>▁▅▄▅▅▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▃█▇▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l2_norm</td><td>▇▃▁▂▂▄▄▅▅▅▄▄▆▇▆▅▅▇▇▇█▆▇▇▇▇▆▇▇▇▇▇██▇▇▇▇▇▇</td></tr><tr><td>metrics/l2_ratio</td><td>█▄▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▆▄▃▂▁▂▃▃▃▃▂</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▁▁▁███▇▇███</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁▁▁▄█▆▁▁▁▁▂</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇█▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▅▆▇▇█▇▆▃▂▂▁▁▂▂▂▂▂▂▂▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_learning_rate</td><td>0.0008</td></tr><tr><td>details/n_training_tokens</td><td>49971200</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0</td></tr><tr><td>losses/l1_loss</td><td>24.04761</td></tr><tr><td>losses/mse_loss</td><td>0.04528</td></tr><tr><td>losses/overall_loss</td><td>0.06932</td></tr><tr><td>metrics/CE_loss_score</td><td>0.92973</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>8.24038</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>2.35799</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>1.91329</td></tr><tr><td>metrics/explained_variance</td><td>0.72311</td></tr><tr><td>metrics/explained_variance_std</td><td>0.09559</td></tr><tr><td>metrics/l0</td><td>58.08691</td></tr><tr><td>metrics/l2_norm</td><td>14.84319</td></tr><tr><td>metrics/l2_ratio</td><td>0.86348</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-4.57345</td></tr><tr><td>sparsity/below_1e-5</td><td>11532</td></tr><tr><td>sparsity/below_1e-6</td><td>983</td></tr><tr><td>sparsity/dead_features</td><td>31</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>125.78119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">16384-L1-0.001-LR-0.0008-Tokens-5.000e+07</strong> at: <a href='https://wandb.ai/jbloom/sae_lens_tutorial/runs/54j1tm6n' target=\"_blank\">https://wandb.ai/jbloom/sae_lens_tutorial/runs/54j1tm6n</a><br/> View project at: <a href='https://wandb.ai/jbloom/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/jbloom/sae_lens_tutorial</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240415_152556-54j1tm6n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12208| MSE Loss 0.046 | L1 0.024: : 50003968it [22:10, 20740.30it/s]                            /home/paperspace/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2265: UserWarning: Run (54j1tm6n) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    }
   ],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_point=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_point_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"geometric_median\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    # Training Parameters\n",
    "    lr=0.0008,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=10000,  # this can help avoid too many dead features initially.\n",
    "    l1_coefficient=0.001,  # will control how sparse the feature activations are\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size=4096,\n",
    "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=1_000_000\n",
    "    * 50,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=10,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: Understanding TinyStories-1L with our SAE\n",
    "\n",
    "I haven't had time yet to complete this section, but I'd love to see a PR where someones uses an SAE they trained in this tutorial to understand this model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16211</th>\n",
       "      <th>9873</th>\n",
       "      <th>7694</th>\n",
       "      <th>13782</th>\n",
       "      <th>9370</th>\n",
       "      <th>7699</th>\n",
       "      <th>9477</th>\n",
       "      <th>7443</th>\n",
       "      <th>227</th>\n",
       "      <th>6926</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>checking</td>\n",
       "      <td>Restore</td>\n",
       "      <td>cere</td>\n",
       "      <td>In</td>\n",
       "      <td>speakers</td>\n",
       "      <td>ju</td>\n",
       "      <td>32</td>\n",
       "      <td>ow</td>\n",
       "      <td>bum</td>\n",
       "      <td>owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berry</td>\n",
       "      <td>telling</td>\n",
       "      <td>uc</td>\n",
       "      <td>Kn</td>\n",
       "      <td>roller</td>\n",
       "      <td>Boot</td>\n",
       "      <td>insert</td>\n",
       "      <td>o</td>\n",
       "      <td>?!\"</td>\n",
       "      <td>clerk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Squ</td>\n",
       "      <td>ruce</td>\n",
       "      <td>lesson</td>\n",
       "      <td>grand</td>\n",
       "      <td>moss</td>\n",
       "      <td>drunk</td>\n",
       "      <td>improve</td>\n",
       "      <td>stop</td>\n",
       "      <td>simply</td>\n",
       "      <td>window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reason</td>\n",
       "      <td>observ</td>\n",
       "      <td>debate</td>\n",
       "      <td>Today</td>\n",
       "      <td>escal</td>\n",
       "      <td>upstream</td>\n",
       "      <td>xious</td>\n",
       "      <td>e</td>\n",
       "      <td>sheet</td>\n",
       "      <td>keeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bro</td>\n",
       "      <td>erc</td>\n",
       "      <td>minor</td>\n",
       "      <td>Jay</td>\n",
       "      <td>mac</td>\n",
       "      <td>,'</td>\n",
       "      <td>Todd</td>\n",
       "      <td>ah</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>merge</td>\n",
       "      <td>gracious</td>\n",
       "      <td>mentioned</td>\n",
       "      <td>Finally</td>\n",
       "      <td>hy</td>\n",
       "      <td>traffic</td>\n",
       "      <td>Mor</td>\n",
       "      <td>you</td>\n",
       "      <td>double</td>\n",
       "      <td>keepers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Las</td>\n",
       "      <td>self</td>\n",
       "      <td>succeeding</td>\n",
       "      <td>Then</td>\n",
       "      <td>bumper</td>\n",
       "      <td>Soldier</td>\n",
       "      <td>allergy</td>\n",
       "      <td>wo</td>\n",
       "      <td>Joyce</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angling</td>\n",
       "      <td>regretted</td>\n",
       "      <td>national</td>\n",
       "      <td>Family</td>\n",
       "      <td>salad</td>\n",
       "      <td>pitched</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>hey</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>slid</td>\n",
       "      <td>sense</td>\n",
       "      <td>fines</td>\n",
       "      <td>During</td>\n",
       "      <td>hooks</td>\n",
       "      <td>narrator</td>\n",
       "      <td>itability</td>\n",
       "      <td>whe</td>\n",
       "      <td>pron</td>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blast</td>\n",
       "      <td>restoration</td>\n",
       "      <td>ul</td>\n",
       "      <td>H</td>\n",
       "      <td>rings</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>aback</td>\n",
       "      <td>Ow</td>\n",
       "      <td>Dahl</td>\n",
       "      <td>employees</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      16211         9873         7694     13782      9370         7699   \\\n",
       "0  checking       Restore         cere       In   speakers           ju   \n",
       "1     Berry       telling           uc       Kn     roller         Boot   \n",
       "2       Squ          ruce       lesson    grand       moss        drunk   \n",
       "3    reason        observ       debate    Today      escal     upstream   \n",
       "4       Bro           erc        minor      Jay        mac           ,'   \n",
       "5     merge      gracious    mentioned  Finally         hy      traffic   \n",
       "6       Las          self   succeeding     Then     bumper      Soldier   \n",
       "7   angling     regretted     national   Family      salad      pitched   \n",
       "8      slid         sense        fines   During      hooks     narrator   \n",
       "9     blast   restoration           ul        H      rings   vegetarian   \n",
       "\n",
       "       9477   7443        227         6926   \n",
       "0         32     ow         bum       owner  \n",
       "1     insert      o         ?!\"       clerk  \n",
       "2    improve   stop      simply      window  \n",
       "3      xious      e       sheet      keeper  \n",
       "4       Todd     ah   Charlotte       owner  \n",
       "5        Mor    you      double     keepers  \n",
       "6    allergy     wo       Joyce      worker  \n",
       "7    Phillip    hey   fantastic     manager  \n",
       "8  itability    whe        pron    employee  \n",
       "9      aback     Ow        Dahl   employees  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's start by getting the top 10 logits for each feature\n",
    "\n",
    "sparse_autoencoder = next(iter(sparse_autoencoder_dictionary))[1]\n",
    "projection_onto_unembed = sparse_autoencoder.W_dec @ model.W_U\n",
    "\n",
    "\n",
    "# get the top 10 logits.\n",
    "vals, inds = torch.topk(projection_onto_unembed, 10, dim=1)\n",
    "\n",
    "# get 10 random features\n",
    "random_indices = torch.randint(0, projection_onto_unembed.shape[0], (10,))\n",
    "\n",
    "# Show the top 10 logits promoted by those features\n",
    "top_10_logits_df = pd.DataFrame(\n",
    "    [model.to_str_tokens(i) for i in inds[random_indices]],\n",
    "    index=random_indices.tolist(),\n",
    ").T\n",
    "top_10_logits_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
