{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNk7IylTv610"
      },
      "source": [
        "# Loading and Analysing Pre-Trained Sparse Autoencoders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing DeepSeek R1 Distill Llama 8B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1b1375108684ddd969fa0773e0f766a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model meta-llama/Llama-3.1-8B into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "from transformer_lens import HookedTransformer\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "hf_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        ")\n",
        "\n",
        "model = HookedTransformer.from_pretrained(\n",
        "    \"meta-llama/Llama-3.1-8B\", hf_model=hf_model, device=\"mps\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_prompt = \"\"\"Problem: If x + 3 = 8, what is the value of x?\n",
        "\n",
        "Let's solve this step by step.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_prompt = \"\"\"Problem: A quadratic equation has roots at x = 2 and x = -3. \n",
        "1) What is the equation in standard form (ax² + bx + c)?\n",
        "2) What is the sum of the coefficients (a + b + c)?\n",
        "3) What is the axis of symmetry?\n",
        "\n",
        "Let's solve this step by step.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_prompt = \"What color is the sky on a clear day?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ebc14e98a784c7a848f7f65ff552995",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\"Problem: A quadratic equation has roots at x = 2 and x = -3. \\n1) What is the equation in standard form (ax² + bx + c)?\\n2) What is the sum of the coefficients (a + b + c)?\\n3) What is the axis of symmetry?\\n\\nLet's solve this step by step. \\n\\nFirst, we need to remember the relationship between the roots of a quadratic equation and its standard form. If r1 and r2 are the roots of the equation ax² + bx + c = 0, then the sum of the roots r1 + r2 = -b/a and the product r1*r2 = c/a.\\n\\nGiven that the roots are x=2 and x=-3, let's find the sum and product of the roots.\\n\\nSum of roots: 2 + (-3) = -1  \\nProduct of roots: 2 * (-3) = -6\\n\\nSo, from this, we have:  \\nr1 + r2 = -b/a = -1  \\nr1 * r2 = c/a = -6\\n\\nSince a quadratic equation can be written in several forms, and the standard form is ax² + bx + c, we'll need to determine a, b, and c.\\n\\nTo do that, let's choose a value for 'a', because quadratic equations are defined up to a non-zero constant multiple. The simplest choice is usually a=1.\\n\\nIf a = 1, then:  \\nb = -(r1 + r2) = -(-1) = 1  \\nc = r1 * r2 = -6\\n\\nSo, the equation in standard form is x² + x - 6 = 0.\\n\\nTo double-check, let's verify the roots of this equation. If we substitute x=2:  \\n(2)² + 2 - 6 = 4 + 2 -6 = 0, which is correct\\n\\nSimilarly, x=-3:  \\n(-3)² + (-3) -6 = 9 -3 -6 = 0, also correct.\\n\\nSo, the standard form is indeed x² + x -6 = 0.\\n\\nNow, to find the sum of the coefficients a + b + c:  \\na = 1  \\nb = 1  \\nc = -6  \\nSum = 1 + 1 + (-6) = 1 + 1 -6 = -4\\n\\nLastly, the axis of symmetry for a quadratic equation ax² + bx + c is given by x = -b/(2a).\\n\\nIn this case, b=1 and a=1, so:  \\nAxis of symmetry = -1/(2*1) = -0.5\\n\\nLet me write down all the results:\\n\\n1) Equation: x² + x -6 = 0  \\n2) Sum of coefficients: -4  \\n3) Axis of symmetry: x = -0.5\\n\\nWait a moment, in part 3, isn't the axis of symmetry a vertical line on the coordinate plane, so it's just a number, which is -0.5, which can also be written as -1/2 or -½.\\n\\nYes, that's correct.\\n\\nSo, the summary would be:\\n1. x² + x -6 = 0  \\n2. Sum of coefficients is -4  \\n3. The axis of symmetry is x = -0.5\\n\\nI don't see any mistakes in this reasoning. To be thorough, we can consider alternative approaches:\\n\\nAnother approach to find the equation is using (x - r1)(x - r2) = 0. Where r1 and r2 are the roots.\\n\\nSo, (x - 2)(x + 3) = 0  \\nExpanding this: x² + 3x -2x -6 = x² + x -6, which is the same as before.\\n\\nTherefore, calculations are correct.\\n<|reserved_special_token_6|>\\n\\n**Solution:**\\n\\nTo determine the required aspects of the quadratic equation with roots at \\\\( x = 2 \\\\) and \\\\( x = -3 \\\\), follow these steps:\\n\\n### 1. **Find the Quadratic Equation in Standard Form**\\n\\nThe standard form of a quadratic equation is \\\\( ax^2 + bx + c \\\\). To form the equation given the roots, use the fact that if \\\\( \\\\alpha \\\\) and \\\\( \\\\beta \\\\) are the roots, the equation can be written as:\\n\\\\[\\n(x - \\\\alpha)(x - \\\\beta) = 0\\n\\\\]\\nSubstituting the given roots:\\n\\\\[\\n(x - 2)(x + 3) = 0\\n\\\\]\\nExpanding this:\\n\\\\[\\nx^2 + 3x - 2x - 6 = x^2 + x - 6\\n\\\\]\\nThus, the equation in standard form is \\\\( x^2 + x - 6 = 0 \\\\).\\n\\n### 2. **Calculate the Sum of the Coefficients**\\n\\nThe coefficients are \\\\( a = 1 \\\\), \\\\( b = 1 \\\\), and \\\\( c = -6 \\\\). Summing them:\\n\\\\[\\n1 + 1 - 6 = -4\\n\\\\]\\nHowever,\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.generate(test_prompt, max_new_tokens=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_DusoOvwV0M"
      },
      "source": [
        "## Imports & Installs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yfDUxRx0wSRl"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    from google.colab import output\n",
        "\n",
        "    COLAB = True\n",
        "    %pip install sae-lens transformer-lens sae-dashboard\n",
        "except:\n",
        "    COLAB = False\n",
        "    from IPython import get_ipython  # type: ignore\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    assert ipython is not None\n",
        "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
        "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
        "\n",
        "# Standard imports\n",
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import plotly.express as px\n",
        "\n",
        "# Imports for displaying vis in Colab / notebook\n",
        "import webbrowser\n",
        "import http.server\n",
        "import socketserver\n",
        "import threading\n",
        "\n",
        "PORT = 8000\n",
        "\n",
        "torch.set_grad_enabled(False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aGgWkbav610"
      },
      "source": [
        "## Set Up\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQSD7trbv610",
        "outputId": "222a40c4-75d4-46e2-ed3f-991841144926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: mps\n"
          ]
        }
      ],
      "source": [
        "# For the most part I'll try to import functions and classes near where they are used\n",
        "# to make it clear where they come from.\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cPUq_bdW8mcp"
      },
      "outputs": [],
      "source": [
        "def display_vis_inline(filename: str, height: int = 850):\n",
        "    \"\"\"\n",
        "    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n",
        "    vis has a unique port without having to define a port within the function.\n",
        "    \"\"\"\n",
        "    if not (COLAB):\n",
        "        webbrowser.open(filename)\n",
        "\n",
        "    else:\n",
        "        global PORT\n",
        "\n",
        "        def serve(directory):\n",
        "            os.chdir(directory)\n",
        "\n",
        "            # Create a handler for serving files\n",
        "            handler = http.server.SimpleHTTPRequestHandler\n",
        "\n",
        "            # Create a socket server with the handler\n",
        "            with socketserver.TCPServer((\"\", PORT), handler) as httpd:\n",
        "                print(f\"Serving files from {directory} on port {PORT}\")\n",
        "                httpd.serve_forever()\n",
        "\n",
        "        thread = threading.Thread(target=serve, args=(\"/content\",))\n",
        "        thread.start()\n",
        "\n",
        "        output.serve_kernel_port_as_iframe(\n",
        "            PORT, path=f\"/{filename}\", height=height, cache_in_notebook=True\n",
        "        )\n",
        "\n",
        "        PORT += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoMx3VZpv611"
      },
      "source": [
        "# Loading a pretrained Sparse Autoencoder\n",
        "\n",
        "Below we load a Transformerlens model, a pretrained SAE and a dataset from huggingface.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sNSfL80Uv611"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aebe5e1296fd457481aa93ce9bbc31f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model meta-llama/Llama-3.1-8B into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformer_lens import HookedTransformer\n",
        "from sae_lens import SAE\n",
        "from transformers import AutoModelForCausalLM\n",
        "from huggingface_hub import login\n",
        "\n",
        "# login(\"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\")\n",
        "device = \"mps\"\n",
        "\n",
        "hf_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        ")\n",
        "model = HookedTransformer.from_pretrained(\n",
        "    \"meta-llama/Llama-3.1-8B\", hf_model=hf_model, device=device\n",
        ")\n",
        "\n",
        "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
        "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
        "# We also return the feature sparsities which are stored in HF for convenience.\n",
        "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
        "    release=\"deepseek-r1-distill-llama-8b-qresearch\",  # see other options in sae_lens/pretrained_saes.yaml\n",
        "    sae_id=\"blocks.19.hook_resid_post\",  # won't always be a hook point\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformer_lens.utils import tokenize_and_concatenate\n",
        "\n",
        "dataset = load_dataset(\n",
        "    path=\"NeelNanda/pile-10k\",\n",
        "    split=\"train\",\n",
        "    streaming=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset.select(range(256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e92eb62f52a4e59b5d4ac56d60b434e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "token_dataset = tokenize_and_concatenate(\n",
        "    dataset=dataset,  # type: ignore\n",
        "    tokenizer=model.tokenizer,  # type: ignore\n",
        "    streaming=True,\n",
        "    max_length=128,\n",
        "    add_bos_token=sae.cfg.prepend_bos,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy2uUl38v611"
      },
      "source": [
        "## Basic Analysis\n",
        "\n",
        "Let's check some basic stats on this SAE in order to see how some basic functionality in the codebase works.\n",
        "\n",
        "We'll calculate:\n",
        "\n",
        "- L0 (the number of features that fire per activation)\n",
        "- The cross entropy loss when the output of the SAE is used in place of the activations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOcubgsRv611"
      },
      "source": [
        "### L0 Test and Reconstruction Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gAUR5CRBv611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average l0 117.59973907470703\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "alignmentgroup": "True",
                  "bingroup": "x",
                  "hovertemplate": "variable=0<br>value=%{x}<br>count=%{y}<extra></extra>",
                  "legendgroup": "0",
                  "marker": {
                    "color": "#636efa",
                    "pattern": {
                      "shape": ""
                    }
                  },
                  "name": "0",
                  "offsetgroup": "0",
                  "orientation": "v",
                  "showlegend": true,
                  "type": "histogram",
                  "x": [
                    8,
                    49,
                    51,
                    82,
                    97,
                    111,
                    125,
                    117,
                    85,
                    81,
                    88,
                    61,
                    61,
                    65,
                    70,
                    77,
                    67,
                    89,
                    98,
                    114,
                    110,
                    99,
                    114,
                    115,
                    126,
                    98,
                    116,
                    118,
                    113,
                    128,
                    65,
                    147,
                    122,
                    136,
                    175,
                    98,
                    112,
                    128,
                    104,
                    95,
                    171,
                    152,
                    93,
                    126,
                    133,
                    157,
                    135,
                    133,
                    133,
                    138,
                    153,
                    106,
                    85,
                    89,
                    114,
                    109,
                    120,
                    96,
                    100,
                    127,
                    105,
                    124,
                    119,
                    101,
                    106,
                    94,
                    117,
                    98,
                    117,
                    137,
                    88,
                    113,
                    135,
                    95,
                    94,
                    130,
                    108,
                    145,
                    135,
                    125,
                    149,
                    143,
                    131,
                    93,
                    113,
                    132,
                    111,
                    113,
                    150,
                    124,
                    122,
                    102,
                    116,
                    121,
                    135,
                    149,
                    118,
                    134,
                    130,
                    142,
                    145,
                    131,
                    157,
                    138,
                    133,
                    140,
                    136,
                    155,
                    155,
                    72,
                    143,
                    104,
                    119,
                    127,
                    121,
                    143,
                    176,
                    167,
                    171,
                    143,
                    136,
                    107,
                    130,
                    98,
                    118,
                    142,
                    131,
                    48,
                    42,
                    87,
                    93,
                    97,
                    71,
                    90,
                    91,
                    117,
                    108,
                    106,
                    110,
                    105,
                    115,
                    128,
                    102,
                    95,
                    99,
                    128,
                    100,
                    134,
                    109,
                    98,
                    126,
                    135,
                    124,
                    79,
                    84,
                    75,
                    104,
                    105,
                    129,
                    105,
                    110,
                    133,
                    129,
                    118,
                    87,
                    76,
                    99,
                    149,
                    123,
                    106,
                    98,
                    133,
                    162,
                    131,
                    147,
                    113,
                    92,
                    135,
                    155,
                    133,
                    130,
                    90,
                    100,
                    138,
                    138,
                    124,
                    104,
                    125,
                    142,
                    134,
                    132,
                    111,
                    132,
                    168,
                    131,
                    163,
                    128,
                    98,
                    93,
                    158,
                    157,
                    147,
                    152,
                    129,
                    130,
                    152,
                    112,
                    124,
                    120,
                    126,
                    127,
                    141,
                    141,
                    128,
                    142,
                    122,
                    118,
                    134,
                    152,
                    138,
                    134,
                    148,
                    148,
                    112,
                    146,
                    134,
                    135,
                    118,
                    176,
                    140,
                    141,
                    117,
                    128,
                    147,
                    130,
                    111,
                    127,
                    137,
                    180,
                    161,
                    148,
                    95,
                    160,
                    155,
                    130,
                    133,
                    119,
                    137,
                    158,
                    156,
                    178,
                    139,
                    124,
                    173,
                    32,
                    58,
                    91,
                    77,
                    86,
                    85,
                    94,
                    112,
                    128,
                    128,
                    113,
                    106,
                    114,
                    131,
                    92,
                    137,
                    143,
                    114,
                    112,
                    128,
                    95,
                    133,
                    139,
                    134,
                    77,
                    109,
                    134,
                    106,
                    82,
                    124,
                    104,
                    125,
                    121,
                    123,
                    111,
                    107,
                    101,
                    119,
                    85,
                    74,
                    144,
                    122,
                    115,
                    66,
                    104,
                    147,
                    146,
                    133,
                    119,
                    101,
                    101,
                    103,
                    97,
                    110,
                    107,
                    86,
                    148,
                    76,
                    80,
                    142,
                    144,
                    123,
                    100,
                    71,
                    121,
                    127,
                    121,
                    112,
                    98,
                    119,
                    129,
                    121,
                    117,
                    107,
                    134,
                    111,
                    104,
                    128,
                    117,
                    144,
                    124,
                    116,
                    141,
                    116,
                    104,
                    111,
                    138,
                    120,
                    94,
                    103,
                    87,
                    125,
                    124,
                    138,
                    97,
                    103,
                    108,
                    143,
                    152,
                    147,
                    131,
                    130,
                    135,
                    148,
                    128,
                    99,
                    110,
                    95,
                    97,
                    109,
                    137,
                    102,
                    113,
                    142,
                    112,
                    102,
                    145,
                    159,
                    148,
                    115,
                    152,
                    141,
                    123,
                    120,
                    153,
                    82,
                    145,
                    61,
                    65,
                    97,
                    76,
                    113,
                    114,
                    76,
                    118,
                    124,
                    91,
                    69,
                    72,
                    99,
                    89,
                    101,
                    94,
                    112,
                    115,
                    98,
                    89,
                    85,
                    89,
                    58,
                    113,
                    153,
                    151,
                    100,
                    90,
                    147,
                    138,
                    105,
                    94,
                    101,
                    135,
                    117,
                    116,
                    120,
                    134,
                    108,
                    114,
                    145,
                    144,
                    81,
                    51,
                    101,
                    119,
                    111,
                    109,
                    91,
                    102,
                    99,
                    122,
                    148,
                    88,
                    91,
                    128,
                    106,
                    89,
                    113,
                    123,
                    95,
                    120,
                    123,
                    112,
                    110,
                    111,
                    127,
                    148,
                    124,
                    120,
                    112,
                    128,
                    112,
                    128,
                    112,
                    135,
                    156,
                    135,
                    124,
                    117,
                    119,
                    120,
                    116,
                    121,
                    97,
                    95,
                    120,
                    109,
                    125,
                    136,
                    134,
                    138,
                    140,
                    116,
                    146,
                    151,
                    155,
                    129,
                    168,
                    81,
                    155,
                    161,
                    132,
                    152,
                    130,
                    143,
                    124,
                    120,
                    128,
                    144,
                    124,
                    81,
                    135,
                    128,
                    142,
                    121,
                    121,
                    143,
                    143,
                    109,
                    102,
                    115,
                    119,
                    94,
                    65,
                    120,
                    137,
                    27,
                    52,
                    86,
                    87,
                    99,
                    91,
                    106,
                    51,
                    67,
                    87,
                    85,
                    86,
                    82,
                    116,
                    98,
                    130,
                    134,
                    118,
                    108,
                    67,
                    92,
                    93,
                    131,
                    126,
                    121,
                    141,
                    116,
                    97,
                    117,
                    114,
                    129,
                    131,
                    77,
                    63,
                    70,
                    131,
                    147,
                    141,
                    150,
                    162,
                    129,
                    155,
                    123,
                    117,
                    129,
                    140,
                    132,
                    164,
                    128,
                    90,
                    121,
                    126,
                    136,
                    149,
                    141,
                    125,
                    119,
                    141,
                    161,
                    144,
                    101,
                    101,
                    80,
                    99,
                    135,
                    178,
                    143,
                    137,
                    133,
                    109,
                    153,
                    102,
                    105,
                    116,
                    124,
                    127,
                    125,
                    109,
                    153,
                    127,
                    126,
                    112,
                    154,
                    117,
                    118,
                    117,
                    118,
                    128,
                    107,
                    126,
                    126,
                    129,
                    104,
                    91,
                    113,
                    119,
                    102,
                    143,
                    130,
                    163,
                    152,
                    128,
                    163,
                    107,
                    126,
                    144,
                    137,
                    118,
                    138,
                    119,
                    143,
                    156,
                    149,
                    132,
                    114,
                    119,
                    135,
                    124,
                    176,
                    128,
                    120,
                    85,
                    96,
                    127,
                    105,
                    153,
                    103,
                    76,
                    65,
                    56,
                    83,
                    91,
                    93,
                    84,
                    88,
                    86,
                    68,
                    67,
                    72,
                    64,
                    116,
                    113,
                    109,
                    123,
                    90,
                    81,
                    103,
                    131,
                    109,
                    135,
                    129,
                    116,
                    120,
                    144,
                    108,
                    121,
                    99,
                    120,
                    115,
                    111,
                    82,
                    119,
                    109,
                    115,
                    75,
                    83,
                    92,
                    113,
                    134,
                    107,
                    114,
                    131,
                    117,
                    134,
                    124,
                    113,
                    104,
                    149,
                    118,
                    120,
                    120,
                    165,
                    124,
                    117,
                    134,
                    132,
                    104,
                    119,
                    135,
                    113,
                    125,
                    100,
                    88,
                    65,
                    60,
                    80,
                    115,
                    88,
                    100,
                    135,
                    171,
                    150,
                    136,
                    157,
                    138,
                    139,
                    111,
                    124,
                    95,
                    109,
                    134,
                    120,
                    133,
                    123,
                    95,
                    145,
                    155,
                    144,
                    129,
                    104,
                    120,
                    90,
                    100,
                    94,
                    140,
                    107,
                    115,
                    100,
                    125,
                    94,
                    131,
                    132,
                    106,
                    152,
                    151,
                    107,
                    157,
                    101,
                    140,
                    101,
                    105,
                    134,
                    118,
                    140,
                    79,
                    104,
                    177,
                    136,
                    135,
                    140,
                    148,
                    124,
                    122,
                    114
                  ],
                  "xaxis": "x",
                  "yaxis": "y"
                }
              ],
              "layout": {
                "barmode": "relative",
                "legend": {
                  "title": {
                    "text": "variable"
                  },
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "value"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "count"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "sae.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n",
        "\n",
        "with torch.no_grad():\n",
        "    # activation store can give us tokens.\n",
        "    batch_tokens = token_dataset[:6][\"tokens\"]\n",
        "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
        "\n",
        "    # Use the SAE\n",
        "    feature_acts = sae.encode(cache[sae.cfg.metadata.hook_name])\n",
        "    sae_out = sae.decode(feature_acts)\n",
        "\n",
        "    # save some room\n",
        "    del cache\n",
        "\n",
        "    # ignore the bos token, get the number of features that activated in each token, averaged accross batch and position\n",
        "    l0 = (feature_acts[:, 1:] > 0).float().sum(-1).detach()\n",
        "    print(\"average l0\", l0.mean().item())\n",
        "    px.histogram(l0.flatten().cpu().numpy()).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijoelLtdv611"
      },
      "source": [
        "Note that while the mean L0 is 64, it varies with the specific activation.\n",
        "\n",
        "To estimate reconstruction performance, we calculate the CE loss of the model with and without the SAE being used in place of the activations. This will vary depending on the tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fwrSvREJv612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orig 3.82660174369812\n",
            "reconstr 4.13746452331543\n",
            "Zero 11.7617826461792\n"
          ]
        }
      ],
      "source": [
        "from transformer_lens import utils\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "# next we want to do a reconstruction test.\n",
        "def reconstr_hook(activation, hook, sae_out):\n",
        "    return sae_out\n",
        "\n",
        "\n",
        "def zero_abl_hook(activation, hook):\n",
        "    return torch.zeros_like(activation)\n",
        "\n",
        "\n",
        "print(\"Orig\", model(batch_tokens, return_type=\"loss\").item())\n",
        "print(\n",
        "    \"reconstr\",\n",
        "    model.run_with_hooks(\n",
        "        batch_tokens,\n",
        "        fwd_hooks=[\n",
        "            (\n",
        "                sae.cfg.metadata.hook_name,\n",
        "                partial(reconstr_hook, sae_out=sae_out),\n",
        "            )\n",
        "        ],\n",
        "        return_type=\"loss\",\n",
        "    ).item(),\n",
        ")\n",
        "print(\n",
        "    \"Zero\",\n",
        "    model.run_with_hooks(\n",
        "        batch_tokens,\n",
        "        return_type=\"loss\",\n",
        "        fwd_hooks=[(sae.cfg.metadata.hook_name, zero_abl_hook)],\n",
        "    ).item(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_TRq_lFv612"
      },
      "source": [
        "## Specific Capability Test\n",
        "\n",
        "Validating model performance on specific tasks when using the reconstructed activation is quite important when studying specific tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "npxKip_Qv612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized prompt: ['<|begin_of_text|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' John', ' gave', ' the', ' bag', ' to']\n",
            "Tokenized answer: [' Mary']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.38</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85.86</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m20.38\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m85.86\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0th token. Logit: 20.38 Prob: 85.86% Token: | Mary|\n",
            "Top 1th token. Logit: 18.23 Prob: 10.03% Token: | the|\n",
            "Top 2th token. Logit: 16.40 Prob:  1.60% Token: | a|\n",
            "Top 3th token. Logit: 15.58 Prob:  0.71% Token: | his|\n",
            "Top 4th token. Logit: 13.95 Prob:  0.14% Token: | her|\n",
            "Top 5th token. Logit: 13.94 Prob:  0.14% Token: | Maria|\n",
            "Top 6th token. Logit: 13.71 Prob:  0.11% Token: | me|\n",
            "Top 7th token. Logit: 13.67 Prob:  0.10% Token: | someone|\n",
            "Top 8th token. Logit: 13.26 Prob:  0.07% Token: | Sarah|\n",
            "Top 9th token. Logit: 12.99 Prob:  0.05% Token: | be|\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orig 3.5946052074432373\n",
            "reconstr 3.6316676139831543\n",
            "Zero 11.761781692504883\n",
            "Tokenized prompt: ['<|begin_of_text|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' John', ' gave', ' the', ' bag', ' to']\n",
            "Tokenized answer: [' Mary']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.05</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.87</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.05\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m11.87\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0th token. Logit: 16.93 Prob: 28.71% Token: | his|\n",
            "Top 1th token. Logit: 16.55 Prob: 19.56% Token: | the|\n",
            "Top 2th token. Logit: 16.05 Prob: 11.87% Token: | Mary|\n",
            "Top 3th token. Logit: 15.89 Prob: 10.14% Token: | a|\n",
            "Top 4th token. Logit: 14.78 Prob:  3.33% Token: | someone|\n",
            "Top 5th token. Logit: 14.60 Prob:  2.79% Token: | Sarah|\n",
            "Top 6th token. Logit: 14.52 Prob:  2.57% Token: | Maria|\n",
            "Top 7th token. Logit: 13.65 Prob:  1.08% Token: | me|\n",
            "Top 8th token. Logit: 13.46 Prob:  0.89% Token: | another|\n",
            "Top 9th token. Logit: 13.38 Prob:  0.82% Token: | Henry|\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "example_prompt = \"When John and Mary went to the shops, John gave the bag to\"\n",
        "example_answer = \" Mary\"\n",
        "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)\n",
        "\n",
        "logits, cache = model.run_with_cache(example_prompt, prepend_bos=True)\n",
        "tokens = model.to_tokens(example_prompt)\n",
        "sae_out = sae(cache[sae.cfg.metadata.hook_name])\n",
        "\n",
        "\n",
        "def reconstr_hook(activations, hook, sae_out):\n",
        "    return sae_out\n",
        "\n",
        "\n",
        "def zero_abl_hook(mlp_out, hook):\n",
        "    return torch.zeros_like(mlp_out)\n",
        "\n",
        "\n",
        "hook_name = sae.cfg.metadata.hook_name\n",
        "\n",
        "print(\"Orig\", model(tokens, return_type=\"loss\").item())\n",
        "print(\n",
        "    \"reconstr\",\n",
        "    model.run_with_hooks(\n",
        "        tokens,\n",
        "        fwd_hooks=[\n",
        "            (\n",
        "                hook_name,\n",
        "                partial(reconstr_hook, sae_out=sae_out),\n",
        "            )\n",
        "        ],\n",
        "        return_type=\"loss\",\n",
        "    ).item(),\n",
        ")\n",
        "print(\n",
        "    \"Zero\",\n",
        "    model.run_with_hooks(\n",
        "        tokens,\n",
        "        return_type=\"loss\",\n",
        "        fwd_hooks=[(hook_name, zero_abl_hook)],\n",
        "    ).item(),\n",
        ")\n",
        "\n",
        "\n",
        "with model.hooks(\n",
        "    fwd_hooks=[\n",
        "        (\n",
        "            hook_name,\n",
        "            partial(reconstr_hook, sae_out=sae_out),\n",
        "        )\n",
        "    ]\n",
        "):\n",
        "    utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1swj9KA7v612"
      },
      "source": [
        "# Generating Feature Interfaces\n",
        "\n",
        "Feature dashboards are an important part of SAE Evaluation. They work by:\n",
        "\n",
        "- 1. Collecting feature activations over a larger number of examples.\n",
        "- 2. Aggregating feature specific statistics (such as max activating examples).\n",
        "- 3. Representing that information in a standardized way\n",
        "\n",
        "For our feature visualizations, we will use a separate library called SAEDashboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "edt8ag4fv612"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "810c926fe5c94d24a93b6903522adf58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Forward passes to cache data for vis:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fd4efc62bee4de9a7e21fdedeb01b08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting vis data from cached data:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Task </span>┃<span style=\"font-weight: bold\"> Time </span>┃<span style=\"font-weight: bold\"> Pct % </span>┃\n",
              "┡━━━━━━╇━━━━━━╇━━━━━━━┩\n",
              "└──────┴──────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTask\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPct %\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━╇━━━━━━━┩\n",
              "└──────┴──────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sae_dashboard.sae_vis_data import SaeVisConfig\n",
        "from sae_dashboard.sae_vis_runner import SaeVisRunner\n",
        "import random\n",
        "\n",
        "# generate a list of 10 random features between 0 and 65k\n",
        "test_feature_idx_gpt = random.sample(range(65536), 10)\n",
        "\n",
        "feature_vis_config_gpt = SaeVisConfig(\n",
        "    hook_point=hook_name,\n",
        "    features=test_feature_idx_gpt,\n",
        "    minibatch_size_features=64,\n",
        "    minibatch_size_tokens=256,\n",
        "    verbose=True,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "visualization_data_gpt = SaeVisRunner(\n",
        "    feature_vis_config_gpt\n",
        ").run(\n",
        "    encoder=sae,  # type: ignore\n",
        "    model=model,\n",
        "    tokens=token_dataset[:256][\"tokens\"],  # type: ignore\n",
        ")\n",
        "# SaeVisData.create(\n",
        "#     encoder=sae,\n",
        "#     model=model, # type: ignore\n",
        "#     tokens=token_dataset[:10000][\"tokens\"],  # type: ignore\n",
        "#     cfg=feature_vis_config_gpt,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yQ94Frzbv612"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e4fbf4d688422f930b8d6121359f52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sae_dashboard.data_writing_fns import save_feature_centric_vis\n",
        "\n",
        "filename = f\"demo_feature_dashboards.html\"\n",
        "save_feature_centric_vis(sae_vis_data=visualization_data_gpt, filename=filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUaD6CFDv612"
      },
      "source": [
        "Now, since generating feature dashboards can be done once per sparse autoencoder, for pre-trained SAEs in the public domain, everyone can use the same dashboards. Neuronpedia hosts dashboards which we can load via the integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxluyNRBv612"
      },
      "outputs": [],
      "source": [
        "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
        "\n",
        "# this function should open\n",
        "neuronpedia_quick_list = get_neuronpedia_quick_list(sae, test_feature_idx_gpt)\n",
        "\n",
        "if COLAB:\n",
        "    # If you're on colab, click the link below\n",
        "    print(neuronpedia_quick_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sae-l",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
