{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution Demo for Neuronpedia\n",
    "\n",
    "\n",
    "\n",
    "Format:\n",
    "- Pick a prompt. \n",
    "- Look at next token probs\n",
    "- Pick a positive and a negative token. \n",
    "- Pick an SAE.\n",
    "- Do attribution to features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Literal, NamedTuple, Callable\n",
    "\n",
    "import torch\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "\n",
    "class SaeReconstructionCache(NamedTuple):\n",
    "    sae_in: torch.Tensor\n",
    "    feature_acts: torch.Tensor\n",
    "    sae_out: torch.Tensor\n",
    "    sae_error: torch.Tensor\n",
    "\n",
    "\n",
    "def track_grad(tensor: torch.Tensor) -> None:\n",
    "    \"\"\"wrapper around requires_grad and retain_grad\"\"\"\n",
    "    tensor.requires_grad_(True)\n",
    "    tensor.retain_grad()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ApplySaesAndRunOutput:\n",
    "    model_output: torch.Tensor\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    sae_activations: dict[str, SaeReconstructionCache]\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        \"\"\"Helper to zero grad all tensors in this object.\"\"\"\n",
    "        self.model_output.grad = None\n",
    "        for act in self.model_activations.values():\n",
    "            act.grad = None\n",
    "        for cache in self.sae_activations.values():\n",
    "            cache.sae_in.grad = None\n",
    "            cache.feature_acts.grad = None\n",
    "            cache.sae_out.grad = None\n",
    "            cache.sae_error.grad = None\n",
    "\n",
    "\n",
    "def apply_saes_and_run(\n",
    "    model: HookedTransformer,\n",
    "    saes: dict[str, SAE],\n",
    "    input: Any,\n",
    "    include_error_term: bool = True,\n",
    "    track_model_hooks: list[str] | None = None,\n",
    "    return_type: Literal[\"logits\", \"loss\"] = \"logits\",\n",
    "    track_grads: bool = False,\n",
    ") -> ApplySaesAndRunOutput:\n",
    "    \"\"\"\n",
    "    Apply the SAEs to the model at the specific hook points, and run the model.\n",
    "    By default, this will include a SAE error term which guarantees that the SAE\n",
    "    will not affect model output. This function is designed to work correctly with\n",
    "    backprop as well, so it can be used for gradient-based feature attribution.\n",
    "\n",
    "    Args:\n",
    "        model: the model to run\n",
    "        saes: the SAEs to apply\n",
    "        input: the input to the model\n",
    "        include_error_term: whether to include the SAE error term to ensure the SAE doesn't affect model output. Default True\n",
    "        track_model_hooks: a list of hook points to record the activations and gradients. Default None\n",
    "        return_type: this is passed to the model.run_with_hooks function. Default \"logits\"\n",
    "        track_grads: whether to track gradients. Default False\n",
    "    \"\"\"\n",
    "\n",
    "    fwd_hooks = []\n",
    "    bwd_hooks = []\n",
    "\n",
    "    sae_activations: dict[str, SaeReconstructionCache] = {}\n",
    "    model_activations: dict[str, torch.Tensor] = {}\n",
    "\n",
    "    # this hook just track the SAE input, output, features, and error. If `track_grads=True`, it also ensures\n",
    "    # that requires_grad is set to True and retain_grad is called for intermediate values.\n",
    "    def reconstruction_hook(\n",
    "        sae_in: torch.Tensor, hook: HookPoint, hook_point: str\n",
    "    ):  # noqa: ARG001\n",
    "        sae = saes[hook_point]\n",
    "        feature_acts = sae.encode(sae_in)\n",
    "        sae_out = sae.decode(feature_acts)\n",
    "        sae_error = (sae_in - sae_out).detach().clone()\n",
    "        if track_grads:\n",
    "            track_grad(sae_error)\n",
    "            track_grad(sae_out)\n",
    "            track_grad(feature_acts)\n",
    "            track_grad(sae_in)\n",
    "        sae_activations[hook_point] = SaeReconstructionCache(\n",
    "            sae_in=sae_in,\n",
    "            feature_acts=feature_acts,\n",
    "            sae_out=sae_out,\n",
    "            sae_error=sae_error,\n",
    "        )\n",
    "\n",
    "        if include_error_term:\n",
    "            return sae_out + sae_error\n",
    "        return sae_out\n",
    "\n",
    "    def sae_bwd_hook(output_grads: torch.Tensor, hook: HookPoint):  # noqa: ARG001\n",
    "        # this just passes the output grads to the input, so the SAE gets the same grads despite the error term hackery\n",
    "        return (output_grads,)\n",
    "\n",
    "    # this hook just records model activations, and ensures that intermediate activations have gradient tracking turned on if needed\n",
    "    def tracking_hook(\n",
    "        hook_input: torch.Tensor, hook: HookPoint, hook_point: str\n",
    "    ):  # noqa: ARG001\n",
    "        model_activations[hook_point] = hook_input\n",
    "        if track_grads:\n",
    "            track_grad(hook_input)\n",
    "        return hook_input\n",
    "\n",
    "    for hook_point in saes.keys():\n",
    "        fwd_hooks.append(\n",
    "            (hook_point, partial(reconstruction_hook, hook_point=hook_point))\n",
    "        )\n",
    "        bwd_hooks.append((hook_point, sae_bwd_hook))\n",
    "    for hook_point in track_model_hooks or []:\n",
    "        fwd_hooks.append((hook_point, partial(tracking_hook, hook_point=hook_point)))\n",
    "\n",
    "    # now, just run the model while applying the hooks\n",
    "    with model.hooks(fwd_hooks=fwd_hooks, bwd_hooks=bwd_hooks):\n",
    "        model_output = model(input, return_type=return_type)\n",
    "\n",
    "    return ApplySaesAndRunOutput(\n",
    "        model_output=model_output,\n",
    "        model_activations=model_activations,\n",
    "        sae_activations=sae_activations,\n",
    "    )\n",
    "    \n",
    "from dataclasses import dataclass\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Literal, NamedTuple\n",
    "\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AttributionGrads:\n",
    "    metric: torch.Tensor\n",
    "    model_output: torch.Tensor\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    sae_activations: dict[str, SaeReconstructionCache]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Attribution:\n",
    "    model_attributions: dict[str, torch.Tensor]\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    model_grads: dict[str, torch.Tensor]\n",
    "    sae_feature_attributions: dict[str, torch.Tensor]\n",
    "    sae_feature_activations: dict[str, torch.Tensor]\n",
    "    sae_feature_grads: dict[str, torch.Tensor]\n",
    "    sae_errors_attribution_proportion: dict[str, float]\n",
    "\n",
    "\n",
    "def calculate_attribution_grads(\n",
    "    model: HookedSAETransformer,\n",
    "    prompt: str,\n",
    "    metric_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    track_hook_points: list[str] | None = None,\n",
    "    include_saes: dict[str, SAE] | None = None,\n",
    "    return_logits: bool = True,\n",
    "    include_error_term: bool = True,\n",
    ") -> AttributionGrads:\n",
    "    \"\"\"\n",
    "    Wrapper around apply_saes_and_run that calculates gradients wrt to the metric_fn.\n",
    "    Tracks grads for both SAE feature and model neurons, and returns them in a structured format.\n",
    "    \"\"\"\n",
    "    output = apply_saes_and_run(\n",
    "        model,\n",
    "        saes=include_saes or {},\n",
    "        input=prompt,\n",
    "        return_type=\"logits\" if return_logits else \"loss\",\n",
    "        track_model_hooks=track_hook_points,\n",
    "        include_error_term=include_error_term,\n",
    "        track_grads=True,\n",
    "    )\n",
    "    metric = metric_fn(output.model_output)\n",
    "    output.zero_grad()\n",
    "    metric.backward()\n",
    "    return AttributionGrads(\n",
    "        metric=metric,\n",
    "        model_output=output.model_output,\n",
    "        model_activations=output.model_activations,\n",
    "        sae_activations=output.sae_activations,\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_feature_attribution(\n",
    "    model: HookedSAETransformer,\n",
    "    input: Any,\n",
    "    metric_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    track_hook_points: list[str] | None = None,\n",
    "    include_saes: dict[str, SAE] | None = None,\n",
    "    return_logits: bool = True,\n",
    "    include_error_term: bool = True,\n",
    ") -> Attribution:\n",
    "    \"\"\"\n",
    "    Calculate feature attribution for SAE features and model neurons following\n",
    "    the procedure in https://transformer-circuits.pub/2024/march-update/index.html#feature-heads.\n",
    "    This include the SAE error term by default, so inserting the SAE into the calculation is\n",
    "    guaranteed to not affect the model output. This can be disabled by setting `include_error_term=False`.\n",
    "\n",
    "    Args:\n",
    "        model: The model to calculate feature attribution for.\n",
    "        input: The input to the model.\n",
    "        metric_fn: A function that takes the model output and returns a scalar metric.\n",
    "        track_hook_points: A list of model hook points to track activations for, if desired\n",
    "        include_saes: A dictionary of SAEs to include in the calculation. The key is the hook point to apply the SAE to.\n",
    "        return_logits: Whether to return the model logits or loss. This is passed to TLens, so should match whatever the metric_fn expects (probably logits)\n",
    "        include_error_term: Whether to include the SAE error term in the calculation. This is recommended, as it ensures that the SAE will not affecting the model output.\n",
    "    \"\"\"\n",
    "    # first, calculate gradients wrt to the metric_fn.\n",
    "    # these will be multiplied with the activation values to get the attributions\n",
    "    outputs_with_grads = calculate_attribution_grads(\n",
    "        model,\n",
    "        input,\n",
    "        metric_fn,\n",
    "        track_hook_points,\n",
    "        include_saes=include_saes,\n",
    "        return_logits=return_logits,\n",
    "        include_error_term=include_error_term,\n",
    "    )\n",
    "    model_attributions = {}\n",
    "    model_activations = {}\n",
    "    model_grads = {}\n",
    "    sae_feature_attributions = {}\n",
    "    sae_feature_activations = {}\n",
    "    sae_feature_grads = {}\n",
    "    sae_error_proportions = {}\n",
    "    # this code is long, but all it's doing is multiplying the grads by the activations\n",
    "    # and recording grads, acts, and attributions in dictionaries to return to the user\n",
    "    with torch.no_grad():\n",
    "        for name, act in outputs_with_grads.model_activations.items():\n",
    "            assert act.grad is not None\n",
    "            raw_activation = act.detach().clone()\n",
    "            model_attributions[name] = (act.grad * raw_activation).detach().clone()\n",
    "            model_activations[name] = raw_activation\n",
    "            model_grads[name] = act.grad.detach().clone()\n",
    "        for name, act in outputs_with_grads.sae_activations.items():\n",
    "            assert act.feature_acts.grad is not None\n",
    "            assert act.sae_out.grad is not None\n",
    "            raw_activation = act.feature_acts.detach().clone()\n",
    "            sae_feature_attributions[name] = (\n",
    "                (act.feature_acts.grad * raw_activation).detach().clone()\n",
    "            )\n",
    "            sae_feature_activations[name] = raw_activation\n",
    "            sae_feature_grads[name] = act.feature_acts.grad.detach().clone()\n",
    "            if include_error_term:\n",
    "                assert act.sae_error.grad is not None\n",
    "                error_grad_norm = act.sae_error.grad.norm().item()\n",
    "            else:\n",
    "                error_grad_norm = 0\n",
    "            sae_out_norm = act.sae_out.grad.norm().item()\n",
    "            sae_error_proportions[name] = error_grad_norm / (\n",
    "                sae_out_norm + error_grad_norm + EPS\n",
    "            )\n",
    "        return Attribution(\n",
    "            model_attributions=model_attributions,\n",
    "            model_activations=model_activations,\n",
    "            model_grads=model_grads,\n",
    "            sae_feature_attributions=sae_feature_attributions,\n",
    "            sae_feature_activations=sae_feature_activations,\n",
    "            sae_feature_grads=sae_feature_grads,\n",
    "            sae_errors_attribution_proportion=sae_error_proportions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"mps\"\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"gpt2-small\")\n",
    "\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release = \"gpt2-small-res-jb\",\n",
    "        sae_id = \"blocks.10.hook_resid_pre\",\n",
    "        device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', ' Tiger', ' Woods', ' plays', ' the', ' sport', ' of']\n",
      "Tokenized answer: [' golf']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.41</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59.12</span><span style=\"font-weight: bold\">% Token: | golf|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.41\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m59.12\u001b[0m\u001b[1m% Token: | golf|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.41 Prob: 59.12% Token: | golf|\n",
      "Top 1th token. Logit: 13.69 Prob:  3.90% Token: | tennis|\n",
      "Top 2th token. Logit: 13.49 Prob:  3.21% Token: | Tiger|\n",
      "Top 3th token. Logit: 13.18 Prob:  2.35% Token: | baseball|\n",
      "Top 4th token. Logit: 12.80 Prob:  1.60% Token: | basketball|\n",
      "Top 5th token. Logit: 12.59 Prob:  1.29% Token: | football|\n",
      "Top 6th token. Logit: 12.31 Prob:  0.98% Token: | the|\n",
      "Top 7th token. Logit: 11.76 Prob:  0.56% Token: | cricket|\n",
      "Top 8th token. Logit: 11.74 Prob:  0.56% Token: | gol|\n",
      "Top 9th token. Logit: 11.60 Prob:  0.48% Token: | Golf|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' golf'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' golf'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = \" Tiger Woods plays the sport of\"\n",
    "pos_token = model.tokenizer.encode(\" golf\")[0]\n",
    "neg_token = model.tokenizer.encode(\" tennis\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', ' Tiger', ' Woods', ' plays', ' the', ' sport', ' of']\n",
      "Tokenized answer: [' golf']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.41</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59.12</span><span style=\"font-weight: bold\">% Token: | golf|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.41\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m59.12\u001b[0m\u001b[1m% Token: | golf|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.41 Prob: 59.12% Token: | golf|\n",
      "Top 1th token. Logit: 13.69 Prob:  3.90% Token: | tennis|\n",
      "Top 2th token. Logit: 13.49 Prob:  3.21% Token: | Tiger|\n",
      "Top 3th token. Logit: 13.18 Prob:  2.35% Token: | baseball|\n",
      "Top 4th token. Logit: 12.80 Prob:  1.60% Token: | basketball|\n",
      "Top 5th token. Logit: 12.59 Prob:  1.29% Token: | football|\n",
      "Top 6th token. Logit: 12.31 Prob:  0.98% Token: | the|\n",
      "Top 7th token. Logit: 11.76 Prob:  0.56% Token: | cricket|\n",
      "Top 8th token. Logit: 11.74 Prob:  0.56% Token: | gol|\n",
      "Top 9th token. Logit: 11.60 Prob:  0.48% Token: | Golf|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' golf'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' golf'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>rank</th>\n",
       "      <th>logit</th>\n",
       "      <th>probability</th>\n",
       "      <th>is_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golf</td>\n",
       "      <td>0</td>\n",
       "      <td>16.408287</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tennis</td>\n",
       "      <td>1</td>\n",
       "      <td>13.689954</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tiger</td>\n",
       "      <td>2</td>\n",
       "      <td>13.493741</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseball</td>\n",
       "      <td>3</td>\n",
       "      <td>13.182872</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>12.801028</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>football</td>\n",
       "      <td>5</td>\n",
       "      <td>12.586832</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>6</td>\n",
       "      <td>12.305334</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cricket</td>\n",
       "      <td>7</td>\n",
       "      <td>11.756577</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gol</td>\n",
       "      <td>8</td>\n",
       "      <td>11.743678</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Golf</td>\n",
       "      <td>9</td>\n",
       "      <td>11.604863</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  rank      logit  probability  is_answer\n",
       "0         golf     0  16.408287     0.591173       True\n",
       "1       tennis     1  13.689954     0.039008      False\n",
       "2        Tiger     2  13.493741     0.032059      False\n",
       "3     baseball     3  13.182872     0.023493      False\n",
       "4   basketball     4  12.801028     0.016036      False\n",
       "5     football     5  12.586832     0.012944      False\n",
       "6          the     6  12.305334     0.009768      False\n",
       "7      cricket     7  11.756577     0.005643      False\n",
       "8          gol     8  11.743678     0.005571      False\n",
       "9         Golf     9  11.604863     0.004849      False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from typing import Optional\n",
    "\n",
    "def test_prompt_pandas(\n",
    "    prompt: str,\n",
    "    model: HookedTransformer,  # Can't give type hint due to circular imports\n",
    "    prepend_bos: Optional[bool] = True,\n",
    "    top_k: int = 10,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Test if the Model Can Give the Correct Answer to a Prompt.\n",
    "    Returns results as a pandas DataFrame containing token predictions and their metrics.\n",
    "\n",
    "    Args: [previous args remain the same]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Contains columns for:\n",
    "            - answer_token: The expected next token\n",
    "            - rank: Position of the answer token in sorted predictions\n",
    "            - logit: Raw logit value for the answer token  \n",
    "            - probability: Probability assigned to the answer token\n",
    "            - is_answer: Boolean indicating if this is the actual answer token\n",
    "    \"\"\"\n",
    "        \n",
    "    prompt_tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n",
    "\n",
    "    logits = model(prompt_tokens)\n",
    "\n",
    "    if logits.shape[0] == 1:\n",
    "        logits = logits.squeeze(0)\n",
    "    else:\n",
    "        logits = logits\n",
    "\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    \n",
    "    # get top k predictions\n",
    "    top_k_probs, top_k_inds = probs[-1].topk(top_k)\n",
    "    \n",
    "    top_k_probs_str = [model.to_string(v) for v in top_k_inds]\n",
    "    \n",
    "    # make a table with the tokem, rank, logit, probability, and is_answer\n",
    "    df = pd.DataFrame({\n",
    "        'token': top_k_probs_str,\n",
    "        'rank': torch.arange(len(top_k_probs_str)),\n",
    "        'logit': logits[-1, top_k_inds].detach().cpu().numpy(),\n",
    "        'probability': top_k_probs.detach().cpu().numpy(),\n",
    "        'is_answer': [t == \" golf\" for t in top_k_probs_str]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "from transformer_lens.utils import test_prompt\n",
    "test_prompt(prompt, \"golf\", model)\n",
    "test_prompt_pandas(prompt, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., -0., -0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [-0., -0., 0.,  ..., -0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., -0., -0., 0.],\n",
       "         [0., 0., 0.,  ..., -0., -0., 0.],\n",
       "         [0., 0., -0.,  ..., -0., -0., 0.]]], device='mps:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def metric_fn(\n",
    "    logits: torch.tensor,\n",
    "    pos_token: torch.tensor = pos_token,\n",
    "    neg_token: torch.Tensor = neg_token,\n",
    ") -> torch.Tensor:\n",
    "    return logits[0, -1, pos_token] - logits[0, -1, neg_token]\n",
    "\n",
    "\n",
    "attribution_output = calculate_feature_attribution(\n",
    "    input=prompt,\n",
    "    model=model,\n",
    "    metric_fn=metric_fn,\n",
    "    include_saes={sae.cfg.hook_name: sae},\n",
    "    include_error_term=True,\n",
    "    return_logits=True,\n",
    ")\n",
    "\n",
    "feature_attribution_df = attribution_output.sae_feature_attributions[sae.cfg.hook_name]\n",
    "feature_attribution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "0/<|endoftext|>",
          "1/ Tiger",
          "2/ Woods",
          "3/ plays",
          "4/ the",
          "5/ sport",
          "6/ of"
         ],
         "xaxis": "x",
         "y": [
          -0.034759134,
          -0.23910812,
          1.4776471,
          -0.14941126,
          0.013407486,
          -0.13211074,
          -1.0221896
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "tokens = model.to_str_tokens(prompt)\n",
    "unique_tokens = [f\"{i}/{t}\" for i, t in enumerate(tokens)]\n",
    "\n",
    "px.bar(\n",
    "    x=unique_tokens,\n",
    "    y=attribution_output.sae_feature_attributions[sae.cfg.hook_name][0]\n",
    "    .sum(-1)\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>feature</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "      <td>14535</td>\n",
       "      <td>0.388522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1059</td>\n",
       "      <td>0.344248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2</td>\n",
       "      <td>23219</td>\n",
       "      <td>0.124019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.117193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2</td>\n",
       "      <td>13075</td>\n",
       "      <td>0.087566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>6</td>\n",
       "      <td>23581</td>\n",
       "      <td>-0.091620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>-0.174772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6</td>\n",
       "      <td>3646</td>\n",
       "      <td>-0.195749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6</td>\n",
       "      <td>8880</td>\n",
       "      <td>-0.226573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>6</td>\n",
       "      <td>17490</td>\n",
       "      <td>-0.499832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     position  feature  attribution\n",
       "176         2    14535     0.388522\n",
       "11          2     1059     0.344248\n",
       "275         2    23219     0.124019\n",
       "120         2    10499     0.117193\n",
       "158         2    13075     0.087566\n",
       "..        ...      ...          ...\n",
       "281         6    23581    -0.091620\n",
       "0           1      332    -0.174772\n",
       "47          6     3646    -0.195749\n",
       "108         6     8880    -0.226573\n",
       "207         6    17490    -0.499832\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_long_nonzero.sort_values(\"attribution\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/7-res-jb/20797?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x42ad8b450>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# get a random feature from the SAE\n",
    "feature_idx = torch.randint(0, sae.cfg.d_sae, (1,)).item()\n",
    "\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "\n",
    "def get_dashboard_html(sae_release=\"gpt2-small\", sae_id=\"7-res-jb\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "\n",
    "html = get_dashboard_html(\n",
    "    sae_release=\"gpt2-small\", sae_id=\"7-res-jb\", feature_idx=feature_idx\n",
    ")\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 14535 had a total attribution of 0.39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"300\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/10-res-jb/14535?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x42ad4edd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1059 had a total attribution of 0.34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"300\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/10-res-jb/1059?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x4b84e6c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 23219 had a total attribution of 0.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"300\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/10-res-jb/23219?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x42ad4edd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 10499 had a total attribution of 0.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"300\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/10-res-jb/10499?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x42ad4edd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 13075 had a total attribution of 0.09\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"300\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/10-res-jb/13075?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x40739dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, v in (\n",
    "    df_long_nonzero.query(\"position==2\")\n",
    "    .groupby(\"feature\")\n",
    "    .attribution.sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(5)\n",
    "    .items()\n",
    "):\n",
    "    print(f\"Feature {i} had a total attribution of {v:.2f}\")\n",
    "    html = get_dashboard_html(\n",
    "        sae_release=\"gpt2-small\",\n",
    "        sae_id=f\"{sae.cfg.hook_layer}-res-jb\",\n",
    "        feature_idx=int(i),\n",
    "    )\n",
    "    display(IFrame(html, width=1200, height=300))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
