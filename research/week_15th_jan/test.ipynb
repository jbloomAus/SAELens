{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephbloom/miniforge3/envs/mats_sae_training/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/josephbloom/miniforge3/envs/mats_sae_training/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/josephbloom/miniforge3/envs/mats_sae_training/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x116cd5e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "LanguageModelSAERunnerConfig(model_name='gpt2-small', hook_point='blocks.10.hook_resid_pre', hook_point_layer=10, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/gpt2-small/blocks.10.hook_resid_pre', d_in=768, n_batches_in_buffer=128, total_training_tokens=3000000000, store_batch_size=32, device='mps', seed=42, dtype=torch.float32, b_dec_init_method='geometric_median', expansion_factor=64, from_pretrained_path=None, l1_coefficient=8e-05, lr=0.0012, lr_scheduler_name=None, lr_warm_up_steps=5000, train_batch_size=4096, feature_sampling_window=1500, feature_sampling_method='anthropic', resample_batches=1028, feature_reinit_scale=0.2, dead_feature_window=50000, dead_feature_estimation_method='no_fire', dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='mats_sae_training_gpt2_small_resid_pre', wandb_entity=None, wandb_log_frequency=100, n_checkpoints=30, checkpoint_path='checkpoints/v8md4kf6')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3225, device='mps:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    # \"tiny-stories-2L-33M\",\n",
    "    # \"attn-only-2l\",\n",
    "    # center_unembed=True,\n",
    "    # center_writing_weights=True,\n",
    "    # fold_ln=True,\n",
    "    # refactor_factored_attn_matrices=True,\n",
    "    fold_ln=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "\n",
    "path = \"../week_8_jan/artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/1100001280_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152.pt\"\n",
    "# path = \"./artifacts/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9/final_sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "model(text, return_type=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', '\\n', 'Putting', ' Cats', ',', ' Dogs', ',', ' M', 'ice', ' in', ' alphabet', 'ical', ' order', ',', ' we', ' get', ':', '\\n', '1', '.', ' Cats', ' 2', '.', ' Dogs', ' 3', '.', ' M', 'ice', '\\n', 'Putting', ' Car', 'rot', ',', ' Apple', ',', ' Banana', ' in', ' alphabet', 'ical', ' order', ',', ' we', ' get', ':', '\\n', '1', '.']\n",
      "Tokenized answer: [' Car', 'rot']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.38</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.65</span><span style=\"font-weight: bold\">% Token: | Car|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.38\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m20.65\u001b[0m\u001b[1m% Token: | Car|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.16 Prob: 44.83% Token: | Cats|\n",
      "Top 1th token. Logit: 16.38 Prob: 20.65% Token: | Car|\n",
      "Top 2th token. Logit: 15.51 Prob:  8.61% Token: | Cat|\n",
      "Top 3th token. Logit: 13.74 Prob:  1.48% Token: | Dogs|\n",
      "Top 4th token. Logit: 13.44 Prob:  1.10% Token: | C|\n",
      "Top 5th token. Logit: 12.92 Prob:  0.65% Token: | Birds|\n",
      "Top 6th token. Logit: 12.72 Prob:  0.53% Token: | Animals|\n",
      "Top 7th token. Logit: 12.67 Prob:  0.51% Token: | Apple|\n",
      "Top 8th token. Logit: 12.67 Prob:  0.50% Token: | A|\n",
      "Top 9th token. Logit: 12.38 Prob:  0.38% Token: | Cars|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.75</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71.52</span><span style=\"font-weight: bold\">% Token: |rot|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m22.75\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m71.52\u001b[0m\u001b[1m% Token: |rot|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 22.75 Prob: 71.52% Token: |rot|\n",
      "Top 1th token. Logit: 21.79 Prob: 27.58% Token: |rots|\n",
      "Top 2th token. Logit: 17.24 Prob:  0.29% Token: |p|\n",
      "Top 3th token. Logit: 16.74 Prob:  0.18% Token: |ro|\n",
      "Top 4th token. Logit: 15.96 Prob:  0.08% Token: |ot|\n",
      "Top 5th token. Logit: 15.44 Prob:  0.05% Token: |pet|\n",
      "Top 6th token. Logit: 14.32 Prob:  0.02% Token: |pe|\n",
      "Top 7th token. Logit: 13.73 Prob:  0.01% Token: |rel|\n",
      "Top 8th token. Logit: 13.68 Prob:  0.01% Token: |r|\n",
      "Top 9th token. Logit: 13.43 Prob:  0.01% Token: |ole|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Car'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'rot'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Car'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'rot'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Putting Cats, Dogs, Mice in alphabetical order, we get:\n",
    "1. Cats 2. Dogs 3. Mice\n",
    "Putting Carrot, Apple, Banana in alphabetical order, we get:\n",
    "1.\"\"\"\n",
    "answer = \" Carrot\"\n",
    "utils.test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"words\")\n",
    "\n",
    "from nltk.corpus import words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>string</th>\n",
       "      <th>string_lower_stripped</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_word</th>\n",
       "      <th>is_fragment</th>\n",
       "      <th>has_space</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>%</td>\n",
       "      <td>%</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50252</th>\n",
       "      <td>50252</td>\n",
       "      <td>regress</td>\n",
       "      <td>regress</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50253</th>\n",
       "      <td>50253</td>\n",
       "      <td>Collider</td>\n",
       "      <td>collider</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50254</th>\n",
       "      <td>50254</td>\n",
       "      <td>informants</td>\n",
       "      <td>informants</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50255</th>\n",
       "      <td>50255</td>\n",
       "      <td>gazed</td>\n",
       "      <td>gazed</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50256</th>\n",
       "      <td>50256</td>\n",
       "      <td>&lt;|endoftext|&gt;</td>\n",
       "      <td>&lt;|endoftext|&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50257 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       token         string string_lower_stripped  is_alpha  is_word  \\\n",
       "0          0              !                     !     False    False   \n",
       "1          1              \"                     \"     False    False   \n",
       "2          2              #                     #     False    False   \n",
       "3          3              $                     $     False    False   \n",
       "4          4              %                     %     False    False   \n",
       "...      ...            ...                   ...       ...      ...   \n",
       "50252  50252        regress               regress      True     True   \n",
       "50253  50253       Collider              collider     False    False   \n",
       "50254  50254     informants            informants      True    False   \n",
       "50255  50255          gazed                 gazed      True    False   \n",
       "50256  50256  <|endoftext|>         <|endoftext|>     False    False   \n",
       "\n",
       "       is_fragment  has_space  num_chars  \n",
       "0            False      False          1  \n",
       "1            False      False          1  \n",
       "2            False      False          1  \n",
       "3            False      False          1  \n",
       "4            False      False          1  \n",
       "...            ...        ...        ...  \n",
       "50252        False       True          7  \n",
       "50253        False       True          8  \n",
       "50254        False       True         10  \n",
       "50255        False       True          5  \n",
       "50256        False      False         13  \n",
       "\n",
       "[50257 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vocab = model.tokenizer.vocab_size\n",
    "vocab_df = pd.DataFrame(\n",
    "    {\n",
    "        \"token\": np.arange(d_vocab),\n",
    "        \"string\": model.to_str_tokens(np.arange(d_vocab)),\n",
    "    }\n",
    ")\n",
    "vocab_df[\"string_lower_stripped\"] = vocab_df.string.str.lower().str.strip()\n",
    "vocab_df[\"is_alpha\"] = vocab_df.string.str.match(r\"^( ?)[a-z]+$\")\n",
    "vocab_df[\"is_word\"] = vocab_df.string_lower_stripped.isin(words.words())\n",
    "vocab_df[\"is_fragment\"] = vocab_df.string.str.match(r\"^[a-z]+$\")\n",
    "vocab_df[\"has_space\"] = vocab_df.string.str.match(r\"^ [A-Za-z]+$\")\n",
    "vocab_df[\"num_chars\"] = vocab_df.string.apply(lambda n: len(n.strip()))\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>string</th>\n",
       "      <th>string_lower_stripped</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_word</th>\n",
       "      <th>is_fragment</th>\n",
       "      <th>has_space</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>511</td>\n",
       "      <td>their</td>\n",
       "      <td>their</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>543</td>\n",
       "      <td>which</td>\n",
       "      <td>which</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>546</td>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>561</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>584</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>612</td>\n",
       "      <td>there</td>\n",
       "      <td>there</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>706</td>\n",
       "      <td>after</td>\n",
       "      <td>after</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>714</td>\n",
       "      <td>could</td>\n",
       "      <td>could</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>717</td>\n",
       "      <td>first</td>\n",
       "      <td>first</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>739</td>\n",
       "      <td>under</td>\n",
       "      <td>under</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>757</td>\n",
       "      <td>again</td>\n",
       "      <td>again</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>777</td>\n",
       "      <td>these</td>\n",
       "      <td>these</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>790</td>\n",
       "      <td>every</td>\n",
       "      <td>every</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>where</td>\n",
       "      <td>where</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>826</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>being</td>\n",
       "      <td>being</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>883</td>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>892</td>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>954</td>\n",
       "      <td>count</td>\n",
       "      <td>count</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>966</td>\n",
       "      <td>point</td>\n",
       "      <td>point</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>981</td>\n",
       "      <td>while</td>\n",
       "      <td>while</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>987</td>\n",
       "      <td>inter</td>\n",
       "      <td>inter</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>991</td>\n",
       "      <td>still</td>\n",
       "      <td>still</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1016</td>\n",
       "      <td>going</td>\n",
       "      <td>going</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1043</td>\n",
       "      <td>found</td>\n",
       "      <td>found</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1049</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1115</td>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1176</td>\n",
       "      <td>power</td>\n",
       "      <td>power</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token  string string_lower_stripped  is_alpha  is_word  is_fragment  \\\n",
       "511     511   their                 their      True     True        False   \n",
       "543     543   which                 which      True     True        False   \n",
       "546     546   about                 about      True     True        False   \n",
       "561     561   would                 would      True     True        False   \n",
       "584     584   other                 other      True     True        False   \n",
       "612     612   there                 there      True     True        False   \n",
       "706     706   after                 after      True     True        False   \n",
       "714     714   could                 could      True     True        False   \n",
       "717     717   first                 first      True     True        False   \n",
       "739     739   under                 under      True     True        False   \n",
       "757     757   again                 again      True     True        False   \n",
       "777     777   these                 these      True     True        False   \n",
       "790     790   every                 every      True     True        False   \n",
       "810     810   where                 where      True     True        False   \n",
       "826     826   right                 right      True     True        False   \n",
       "852     852   being                 being      True     True        False   \n",
       "883     883   those                 those      True     True        False   \n",
       "892     892   think                 think      True     True        False   \n",
       "923     923   start                 start      True     True        False   \n",
       "954     954   count                 count      True     True        False   \n",
       "966     966   point                 point      True     True        False   \n",
       "981     981   while                 while      True     True        False   \n",
       "987     987   inter                 inter      True     True        False   \n",
       "991     991   still                 still      True     True        False   \n",
       "995     995   world                 world      True     True        False   \n",
       "1016   1016   going                 going      True     True        False   \n",
       "1043   1043   found                 found      True     True        False   \n",
       "1049   1049   great                 great      True     True        False   \n",
       "1115   1115   three                 three      True     True        False   \n",
       "1176   1176   power                 power      True     True        False   \n",
       "\n",
       "      has_space  num_chars  \n",
       "511        True          5  \n",
       "543        True          5  \n",
       "546        True          5  \n",
       "561        True          5  \n",
       "584        True          5  \n",
       "612        True          5  \n",
       "706        True          5  \n",
       "714        True          5  \n",
       "717        True          5  \n",
       "739        True          5  \n",
       "757        True          5  \n",
       "777        True          5  \n",
       "790        True          5  \n",
       "810        True          5  \n",
       "826        True          5  \n",
       "852        True          5  \n",
       "883        True          5  \n",
       "892        True          5  \n",
       "923        True          5  \n",
       "954        True          5  \n",
       "966        True          5  \n",
       "981        True          5  \n",
       "987        True          5  \n",
       "991        True          5  \n",
       "995        True          5  \n",
       "1016       True          5  \n",
       "1043       True          5  \n",
       "1049       True          5  \n",
       "1115       True          5  \n",
       "1176       True          5  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = vocab_df[vocab_df.is_word & vocab_df.has_space & (vocab_df.num_chars == 5)]\n",
    "word_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['siege', 'Spell', 'Bundy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Question: Put the following words in order: siege, Spell, Bundy\\nAnswer: Bundy, Spell, siege'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_single_prompt():\n",
    "    words = [word_df.string.sample().item().strip() for _ in range(3)]\n",
    "    print(words)\n",
    "    sorted_words = sorted(words)\n",
    "    return f\"Question: Put the following words in order: {', '.join(words)}\\nAnswer: {', '.join(sorted_words)}\"\n",
    "make_single_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GROUP', 'Cheap', 'funky']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-d5314508-7d5d\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-d5314508-7d5d\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<|endoftext|>\", \"Question\", \":\", \" Put\", \" the\", \" following\", \" words\", \" in\", \" order\", \":\", \" GROUP\", \",\", \" Cheap\", \",\", \" funky\", \"\\n\", \"Answer\", \":\", \" Cheap\", \",\", \" GROUP\", \",\", \" funky\"], \"topKLogProbs\": [[-2.775815963745117, -3.278092384338379, -3.725003242492676, -3.942326545715332, -3.9997053146362305, -4.458623886108398, -4.482796669006348, -4.6977643966674805, -4.749504089355469, -4.858044624328613], [-0.6912921071052551, -1.8707659244537354, -3.9095070362091064, -4.265255451202393, -4.400646686553955, -4.4368367195129395, -4.497450351715088, -4.752347469329834, -4.91165018081665, -4.937767505645752], [-1.9027512073516846, -2.2403833866119385, -2.554588556289673, -2.8791449069976807, -3.062317132949829, -3.2024900913238525, -3.2512123584747314, -3.476585626602173, -3.742910623550415, -3.998607873916626], [-2.2055134773254395, -2.2100768089294434, -2.3914475440979004, -3.1978230476379395, -3.299879550933838, -3.5414767265319824, -3.834764003753662, -3.849277973175049, -3.9036507606506348, -3.9557528495788574], [-4.304831504821777, -4.465287208557129, -4.914952278137207, -5.044099807739258, -5.086916923522949, -5.248508453369141, -5.283454895019531, -5.396611213684082, -5.443692207336426, -5.509023666381836], [-1.8169136047363281, -2.19095516204834, -2.93674373626709, -2.9623451232910156, -3.3644704818725586, -3.76859188079834, -3.864518165588379, -4.109494209289551, -4.332145690917969, -4.3396711349487305], [-1.0227036476135254, -1.465416431427002, -2.412245273590088, -2.6530346870422363, -2.763336658477783, -4.1328606605529785, -4.434462070465088, -4.685267925262451, -4.812321186065674, -4.9024529457092285], [-1.7023351192474365, -1.7861402034759521, -2.030647039413452, -2.899310827255249, -3.416757345199585, -3.8360707759857178, -4.190672874450684, -4.298316955566406, -4.424055099487305, -4.424297332763672], [-0.6980454921722412, -1.3913838863372803, -2.967008352279663, -3.6124398708343506, -3.623213529586792, -4.155671119689941, -4.223492622375488, -4.288820266723633, -4.502035140991211, -4.59710693359375], [-1.385829210281372, -1.8562605381011963, -3.652602434158325, -4.670016288757324, -4.697491645812988, -4.740564346313477, -4.857083320617676, -5.072966575622559, -5.206789970397949, -5.281037330627441], [-2.252176284790039, -2.9017419815063477, -3.2297964096069336, -3.260890007019043, -3.2742395401000977, -3.402644157409668, -3.570859909057617, -3.8071584701538086, -3.8409814834594727, -3.931309700012207], [-2.711416482925415, -3.851580858230591, -4.2999677658081055, -4.322050094604492, -4.34812068939209, -4.460021018981934, -4.486651420593262, -4.4979448318481445, -4.523593902587891, -4.549277305603027], [-0.9896790385246277, -4.152402400970459, -4.2399678230285645, -4.414414882659912, -4.516346454620361, -4.630161762237549, -5.109899997711182, -5.117151737213135, -5.153199672698975, -5.226521015167236], [-3.370309591293335, -4.182413101196289, -4.463031768798828, -5.016263008117676, -5.054840087890625, -5.166084289550781, -5.184337615966797, -5.195418357849121, -5.205793380737305, -5.263893127441406], [-0.36164864897727966, -2.6338844299316406, -3.8544673919677734, -4.043108940124512, -4.335322380065918, -4.754329681396484, -4.919395446777344, -4.993826866149902, -5.156157493591309, -5.3690032958984375], [-0.016127724200487137, -6.837357521057129, -7.447675704956055, -7.751659393310547, -7.947597503662109, -8.057038307189941, -8.122228622436523, -8.161591529846191, -8.637280464172363, -8.672382354736328], [-0.01265424769371748, -6.493247985839844, -6.666409492492676, -7.302006721496582, -7.456591606140137, -7.635929107666016, -8.04136848449707, -8.315943717956543, -8.375052452087402, -8.599869728088379], [-2.433246612548828, -3.4023351669311523, -3.4114036560058594, -3.4753026962280273, -3.764402389526367, -3.9764633178710938, -4.006224632263184, -4.109687805175781, -4.255411148071289, -4.295215606689453], [-1.7971243858337402, -2.024869441986084, -2.2235779762268066, -2.265347957611084, -3.2755789756774902, -3.5137972831726074, -4.017271518707275, -4.023895740509033, -4.181912899017334, -4.242838382720947], [-0.4085599184036255, -4.544920921325684, -4.761282920837402, -4.766927719116211, -5.448098182678223, -5.625704765319824, -5.65037727355957, -5.814838409423828, -5.850811004638672, -6.001986503601074], [-0.27702993154525757, -3.205023765563965, -3.3102598190307617, -4.024568557739258, -4.1688947677612305, -4.649984359741211, -4.793217658996582, -5.537127494812012, -5.554065704345703, -5.693720817565918], [-2.790605068206787, -3.3397088050842285, -3.530351161956787, -3.783351421356201, -3.948106288909912, -4.079278469085693, -4.100851535797119, -4.200048923492432, -4.298232555389404, -4.359787464141846]], \"topKTokens\": [[\"\\n\", \"The\", \"\\\"\", \"A\", \"I\", \"In\", \".\", \"It\", \"S\", \"This\"], [\":\", \"\\n\", \" of\", \" from\", \" 1\", \"able\", \" is\", \" by\", \".\", \" #\"], [\"\\n\", \" What\", \" How\", \" I\", \" Is\", \" Why\", \" Can\", \" Do\", \" If\", \" When\"], [\" a\", \" your\", \" the\", \" it\", \" this\", \" another\", \" me\", \" in\", \" some\", \" up\"], [\" word\", \" \\\"\", \" question\", \" two\", \" money\", \" name\", \" following\", \" number\", \" same\", \" whole\"], [\" in\", \" on\", \" into\", \" together\", \" question\", \" to\", \" code\", \" information\", \" up\", \" words\"], [\" in\", \" into\", \" together\", \" on\", \" to\", \" under\", \" at\", \" (\", \" or\", \" and\"], [\" the\", \" your\", \" a\", \" front\", \" quotation\", \" an\", \" quotes\", \" one\", \" any\", \" my\"], [\" of\", \":\", \".\", \" to\", \",\", \" from\", \" (\", \" in\", \" and\", \" for\"], [\"\\n\", \" \\\"\", \"\\n\\n\", \" 1\", \" The\", \" '\", \" *\", \" I\", \" A\", \" (\"], [\" BY\", \"_\", \" OF\", \",\", \" A\", \":\", \" (\", \"ING\", \" 1\", \"\\n\"], [\" GROUP\", \" PART\", \" N\", \" S\", \" B\", \" F\", \" P\", \" A\", \" G\", \" M\"], [\",\", \" and\", \" &\", \" (\", \".\", \"\\n\", \" Food\", \" Goods\", \" or\", \"/\"], [\" Cheap\", \" Low\", \" and\", \" Fast\", \" Un\", \" or\", \" L\", \" High\", \" S\", \" Short\"], [\",\", \".\", \"\\n\", \" and\", \" (\", \"...\", \" or\", \"-\", \"/\", \";\"], [\"\\n\", \"I\", \"The\", \"A\", \"What\", \"This\", \"Answer\", \"Why\", \"Question\", \"In\"], [\":\", \" to\", \",\", \"\\n\", \" (\", \" :\", \".\", \" 1\", \" -\", \"/\"], [\" Group\", \" The\", \"\\n\", \" I\", \" GROUP\", \" A\", \" Cheap\", \" \\\"\", \" Yes\", \" No\"], [\",\", \" is\", \"\\n\", \".\", \" and\", \"!\", \" -\", \" (\", \" Cheap\", \"?\"], [\" funky\", \" trendy\", \" fun\", \" hip\", \" cool\", \" but\", \" cheap\", \" not\", \" weird\", \" the\"], [\",\", \".\", \"\\n\", \" and\", \"!\", \" (\", \" is\", \" or\", \":\", \"?\"], [\" Cheap\", \" funky\", \" B\", \" F\", \" and\", \" DJ\", \" D\", \" GOOD\", \" G\", \" FUN\"]], \"correctTokenRank\": [1068, 0, 318, 2, 6, 9, 0, 12, 1, 12270, 3, 26733, 0, 12424, 2, 6, 0, 6, 0, 9452, 0, 1], \"correctTokenLogProb\": [-9.032979965209961, -0.6912921071052551, -9.152267456054688, -2.3914475440979004, -5.283454895019531, -4.3396711349487305, -1.0227036476135254, -4.711691856384277, -1.3913838863372803, -12.119393348693848, -3.260890007019043, -15.63582706451416, -0.9896790385246277, -12.70504379272461, -3.8544673919677734, -8.122228622436523, -0.01265424769371748, -4.006224632263184, -1.7971243858337402, -13.24411392211914, -0.27702993154525757, -3.3397088050842285]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x41d66e010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import circuitsvis as cv\n",
    "\n",
    "example_prompt = make_single_prompt()\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "display(cv.logits.token_log_probs(model.to_tokens(example_prompt), model(example_prompt)[0].log_softmax(dim=-1), model.to_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_prompt():\n",
    "    word = short_chars_vocab_df.string.sample().item().strip()\n",
    "    return f\" {word}:\" + \"\".join([f\" {c.upper()}\" for c in word.strip()])\n",
    "\n",
    "\n",
    "def make_kshot_prompt(k=3):\n",
    "    return \"\\n\".join([make_single_prompt() for _ in range(k)])\n",
    "\n",
    "\n",
    "def make_kshot_prompts(n=10, k=3):\n",
    "    return [make_kshot_prompt(k) for _ in range(n)]\n",
    "\n",
    "\n",
    "def get_answer_index(prompts):\n",
    "    batch_size = len(prompts)\n",
    "    answer_index = torch.zeros((batch_size, 5), device=\"cuda\", dtype=torch.int64) - 1\n",
    "    for i in range(batch_size):\n",
    "        for j in range(5):\n",
    "            answer_index[i, j] = alphabet.index(prompts[i][2 * j - 9].lower())\n",
    "    return answer_index\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
