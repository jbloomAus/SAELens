{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "conda create -n sae-lens python=3.10\n",
    "conda activate sae-lens\n",
    "pip install -e .\n",
    "pip install ipywidgets\n",
    "\n",
    "ipython kernel install --name \"sae-lens\" --user\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='7'\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproducibility():\n",
    "    \"\"\"Apply various mechanisms to try to prevent nondeterminism in test runs.\"\"\"\n",
    "    # I have not in general attempted to verify that the below are necessary\n",
    "    # for reproducibility, only that they are likely to help and unlikely to\n",
    "    # hurt.\n",
    "    # https://pytorch.org/docs/stable/notes/randomness.html#reproducibility\n",
    "    seed = 0x1234_5678_9ABC_DEF0\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Python native RNG; docs don't give any limitations on seed range\n",
    "    random.seed(seed)\n",
    "    # this is a \"legacy\" method that operates on a global RandomState\n",
    "    # sounds like the argument must be in [0, 2**32)\n",
    "    np.random.seed(seed & 0xFFFF_FFFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code below to generate the ground truth (full training without interruption.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1M into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1213719da49c4f52ba29f4b691d05499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimating norm scaling factor:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78339dcfe00d434dbf798e6fcd10590d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22a7b0fe41145ba97c19a24434996a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d233d379679d4672b1225222ec16cf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12239a80641d4418a7f6a73d26a2bf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7c23d4b88348f488b1aea98ab94843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a1092662394b2b91189f71e102a2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c888c6f1044710ad487a5f3e420973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f579bd1c060644c2aa01bed76b14558a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744d2b8008204974a14d780e2b7e720d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0635f166773495aadde73f1b3123148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1444fb26d14d3181700db1fd079db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03022617791c4124be369a261626cd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049383355cfd4fb18b3da0e885c94047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8750efe4054342a6888508241ee34890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ef3752e2ce4c64b7dd182fcbf73f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bb9f94edc74f0eb3a34d73e6bca7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c235057bf4472ba50b293762cf792c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77fd399ced440e99c71ba9ced468404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training SAE:   0%|          | 0/4096000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ef14a6838641feb86870b0687caee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfaf9a40bf05466b8057bfa611f64061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e4d0dc3322410381f9e45e2e3866f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed026aa03604e19a5f0fd0596042e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f34e979b2b24555990991730aa4dcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacc4384322143bcab67e68cdcfdc050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a7f640d8f441ffa3c1eb4e8a2751f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580e243ca156472295edd77f70a8afbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efb1c2e45b34f9c93dc044b22865320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c080bbfb3e904421a9a1ad297a3d6984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eee2b92ab1c49b09a26af586af7ee76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1290e23c50dc410aa5ca8ab8f419339f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47715d7c6b14110a280c5e0b800b491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89af3a0d89447ea81e53f52b000dd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef30c8c2669d46518991a8155adce103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856bef7aca8648c088f71a5ec573d8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_training_steps = 1_000  # probably we should do more\n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=0,  # Only one layer in the model.\n",
    "    d_in=64,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=\"expected_average_only_in\",\n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=False,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=10, # (FOR CHECKPOINTING) set this\n",
    "    resume=True, # (FOR CHECKPOINTING) set this\n",
    "    wandb_id = \"fullrun\", # (FOR CHECKPOINTING) set this some value to report to same wandb experiment\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder = SAETrainingRunner(cfg).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code below to resume from checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/test/1232896'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "if os.path.exists(\"checkpoints/test/\"):\n",
    "    shutil.rmtree(\"checkpoints/test/\")\n",
    "os.makedirs(\"checkpoints/test/\")\n",
    "\n",
    "shutil.copytree(\"checkpoints/fullrun/1232896\", \"checkpoints/test/1232896\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1M into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e313a500ae947d7a9b8b1dad8dd77b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimating norm scaling factor:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30bb1936f224cc0af22dc81d6a3a1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e80c33a8754629932ce182e0fd1330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6537e44a893a426ea2ea9d6fefbcf1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa979853adf34f18ac8e4f202724bb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ceb6cec20d243f9970250e5a9f155cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95d588d28c84620b8bbde828504afbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2113079a7e8e4333badf692f2fafa367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab42911cf4846599d720201a856a1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8588df83287448a595e09b38dfe20159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcc80129d9e41c6b447228bdd413c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce469b2a8310455fb586ff256a99090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ad3695510046308951c384940f9178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4095600f8b4cae9120f0b5e3d99230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becb57ab436b4fd485633b118f9a2e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666e602f092845f5a50c8ce98b5bda08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0366b414a2a4a75887189c89cdb6134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404f43a42280438f8c8837fc12f969e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from checkpoints/test/1232896\n",
      "Replaying batches (next_batch() only)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98d422b6e7f41c2bf806d7f9f8f95fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b563c3a5e61f419ba2ad34cbf034037f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226cd714eba746639babf4c1ef638b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933a0a5438034e00b99613af7f14acee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c177aabb6604d6a8a4d4e9d0b42018d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15206a639b54b68b705ea19fcc49cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training SAE:  30%|###       | 1232896/4096000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96344aa98c154d87901201675a2472a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f54b29807ac4e6091cb32cdd32e072d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c5c7e2c82540b1adb17b61531e0301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef6b1babc87496d8bbaf66451cd0976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd91fb676b8148f8a5cc1855639d144a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8be217cf014576b38e311249659eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cd559e03de48f799cbbcbb9e9e00c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef5ce2c11c347c7a80c56970c007cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dfe8ef64f04c97814e4ac70b0278c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf8aa9b4d1d4e26a5f88f4a9363d46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6587439a14f44da3bc0edecbaf26d47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Refilling buffer:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_training_steps = 1_000  # probably we should do more\n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=0,  # Only one layer in the model.\n",
    "    d_in=64,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=\"expected_average_only_in\",\n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=False,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=10, # (FOR CHECKPOINTING) set this\n",
    "    resume=True, # (FOR CHECKPOINTING) set this\n",
    "    wandb_id = \"test\", # (FOR CHECKPOINTING) set this some value to report to same wandb experiment\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder = SAETrainingRunner(cfg).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the final checkpoints are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "sparsity_target = load_file(\"checkpoints/fullrun/final_4096000/sparsity.safetensors\")\n",
    "sparsity_test = load_file(\"checkpoints/test/final_4096000/sparsity.safetensors\")\n",
    "\n",
    "sae_weights_target = load_file(\"checkpoints/fullrun/final_4096000/sae_weights.safetensors\")\n",
    "sae_weights_test = load_file(\"checkpoints/test/final_4096000/sae_weights.safetensors\")\n",
    "\n",
    "activation_store_state_target = load_file(\"checkpoints/fullrun/final_4096000/activations_store_state.safetensors\")\n",
    "activation_store_state_test = load_file(\"checkpoints/test/final_4096000/activations_store_state.safetensors\")\n",
    "\n",
    "trainer_state_target = torch.load(\"checkpoints/fullrun/final_4096000/trainer_state.pt\", weights_only=False, map_location=\"cpu\")\n",
    "trainer_state_test = torch.load(\"checkpoints/test/final_4096000/trainer_state.pt\", weights_only=False, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_training_steps True\n",
      "1000\n",
      "1000\n",
      "n_training_tokens True\n",
      "4096000\n",
      "4096000\n",
      "act_freq_scores True\n",
      "tensor([  1.,   0., 615.,  ...,   0.,   1., 773.])\n",
      "tensor([  1.,   0., 615.,  ...,   0.,   1., 773.])\n",
      "n_forward_passes_since_fired True\n",
      "tensor([0., 4., 0.,  ..., 1., 0., 0.])\n",
      "tensor([0., 4., 0.,  ..., 1., 0., 0.])\n",
      "n_frac_active_tokens True\n",
      "4096\n",
      "4096\n",
      "optimizer True\n",
      "{'state': {0: {'step': tensor(1000.), 'exp_avg': tensor([6.2866e-06, 4.0250e-06, 3.4841e-03,  ..., 8.4443e-06, 2.0037e-05,\n",
      "        8.2403e-03]), 'exp_avg_sq': tensor([3.0301e-06, 1.7676e-06, 1.1245e-05,  ..., 8.2309e-06, 8.9528e-06,\n",
      "        7.2805e-05])}, 1: {'step': tensor(1000.), 'exp_avg': tensor([[ 6.1260e-07, -2.7279e-07,  5.0299e-07,  ..., -1.7481e-07,\n",
      "          1.3266e-07,  1.2698e-07],\n",
      "        [ 1.2333e-06, -4.1654e-09,  1.5437e-06,  ...,  1.8267e-07,\n",
      "         -1.8460e-07, -3.5199e-07],\n",
      "        [-1.0503e-05, -3.9118e-05, -4.3038e-04,  ...,  8.0830e-03,\n",
      "         -4.7457e-04, -9.0311e-04],\n",
      "        ...,\n",
      "        [ 2.8237e-07, -6.3987e-08, -1.9095e-07,  ..., -3.8666e-07,\n",
      "         -2.8857e-08, -2.0934e-09],\n",
      "        [ 3.5487e-08,  1.6451e-07,  4.8492e-07,  ..., -3.3344e-07,\n",
      "          5.9082e-08, -3.1119e-07],\n",
      "        [ 1.7970e-04,  3.6536e-05,  7.7013e-04,  ..., -4.8991e-04,\n",
      "          2.8682e-03,  1.5676e-03]]), 'exp_avg_sq': tensor([[1.9785e-10, 1.7426e-10, 2.9228e-10,  ..., 6.3152e-\n",
      "{'state': {0: {'step': tensor(1000.), 'exp_avg': tensor([6.2866e-06, 4.0250e-06, 3.4841e-03,  ..., 8.4443e-06, 2.0037e-05,\n",
      "        8.2403e-03]), 'exp_avg_sq': tensor([3.0301e-06, 1.7676e-06, 1.1245e-05,  ..., 8.2309e-06, 8.9528e-06,\n",
      "        7.2805e-05])}, 1: {'step': tensor(1000.), 'exp_avg': tensor([[ 6.1260e-07, -2.7279e-07,  5.0299e-07,  ..., -1.7481e-07,\n",
      "          1.3266e-07,  1.2698e-07],\n",
      "        [ 1.2333e-06, -4.1654e-09,  1.5437e-06,  ...,  1.8267e-07,\n",
      "         -1.8460e-07, -3.5199e-07],\n",
      "        [-1.0503e-05, -3.9118e-05, -4.3038e-04,  ...,  8.0830e-03,\n",
      "         -4.7457e-04, -9.0311e-04],\n",
      "        ...,\n",
      "        [ 2.8237e-07, -6.3987e-08, -1.9095e-07,  ..., -3.8666e-07,\n",
      "         -2.8857e-08, -2.0934e-09],\n",
      "        [ 3.5487e-08,  1.6451e-07,  4.8492e-07,  ..., -3.3344e-07,\n",
      "          5.9082e-08, -3.1119e-07],\n",
      "        [ 1.7970e-04,  3.6536e-05,  7.7013e-04,  ..., -4.8991e-04,\n",
      "          2.8682e-03,  1.5676e-03]]), 'exp_avg_sq': tensor([[1.9785e-10, 1.7426e-10, 2.9228e-10,  ..., 6.3152e-\n",
      "lr_scheduler_state True\n",
      "{'_milestones': [800], 'last_epoch': 1000, '_last_lr': [0.0], '_schedulers': [{'base_lrs': [5e-05], 'last_epoch': 799, 'verbose': False, '_step_count': 800, '_get_lr_called_within_step': False, '_last_lr': [5e-05], 'lr_lambdas': [None]}, {'start_factor': 1.0, 'end_factor': 0.0, 'total_iters': 200, 'base_lrs': [5e-05], 'last_epoch': 200, 'verbose': False, '_step_count': 202, '_get_lr_called_within_step': False, '_last_lr': [0.0]}]}\n",
      "{'_milestones': [800], 'last_epoch': 1000, '_last_lr': [0.0], '_schedulers': [{'base_lrs': [5e-05], 'last_epoch': 799, 'verbose': False, '_step_count': 800, '_get_lr_called_within_step': False, '_last_lr': [5e-05], 'lr_lambdas': [None]}, {'start_factor': 1.0, 'end_factor': 0.0, 'total_iters': 200, 'base_lrs': [5e-05], 'last_epoch': 200, 'verbose': False, '_step_count': 202, '_get_lr_called_within_step': False, '_last_lr': [0.0]}]}\n",
      "l1_scheduler_state True\n",
      "{'l1_warmup_steps': 50, 'total_steps': 1000, 'current_l1_coefficient': 5, 'final_l1_coefficient': 5, 'current_step': 1000}\n",
      "{'l1_warmup_steps': 50, 'total_steps': 1000, 'current_l1_coefficient': 5, 'final_l1_coefficient': 5, 'current_step': 1000}\n",
      "n_next_batch_called True\n",
      "1000\n",
      "1000\n",
      "python_rng_state True\n",
      "(3, (2147483648, 3823438522, 2111675373, 570329199, 3925524546, 1581482143, 3065109297, 1361397619, 2820783707, 532603918, 1393482140, 801225194, 2860594279, 2722279227, 363220295, 1407088478, 3467172440, 3557873650, 1084357411, 1411794404, 2213785884, 668548324, 2759160418, 999904907, 1103053932, 453058605, 2180502544, 2511163663, 3784542381, 3830661017, 2723181989, 1606717691, 3279370837, 3830486714, 2315333619, 390443781, 1245840324, 2478749356, 4079465034, 3525479386, 2812314658, 1779872754, 2915540460, 234604840, 2187107113, 3489447448, 324564136, 951103150, 1888130933, 1871354074, 3893569970, 3882305847, 2443851873, 1026957759, 2708314032, 1956735094, 2444996715, 3137474199, 2744949584, 2860102745, 3264289616, 2635821488, 3753984076, 22333695, 837531159, 2180977817, 3555899432, 3973649209, 492840950, 2067399239, 2359896814, 3503682872, 3105010677, 2546943058, 944574196, 2961808075, 892195845, 703306284, 2818720396, 3118958357, 2425332227, 1088985048, 968379098, 1898921015, 403911\n",
      "(3, (2147483648, 3823438522, 2111675373, 570329199, 3925524546, 1581482143, 3065109297, 1361397619, 2820783707, 532603918, 1393482140, 801225194, 2860594279, 2722279227, 363220295, 1407088478, 3467172440, 3557873650, 1084357411, 1411794404, 2213785884, 668548324, 2759160418, 999904907, 1103053932, 453058605, 2180502544, 2511163663, 3784542381, 3830661017, 2723181989, 1606717691, 3279370837, 3830486714, 2315333619, 390443781, 1245840324, 2478749356, 4079465034, 3525479386, 2812314658, 1779872754, 2915540460, 234604840, 2187107113, 3489447448, 324564136, 951103150, 1888130933, 1871354074, 3893569970, 3882305847, 2443851873, 1026957759, 2708314032, 1956735094, 2444996715, 3137474199, 2744949584, 2860102745, 3264289616, 2635821488, 3753984076, 22333695, 837531159, 2180977817, 3555899432, 3973649209, 492840950, 2067399239, 2359896814, 3503682872, 3105010677, 2546943058, 944574196, 2961808075, 892195845, 703306284, 2818720396, 3118958357, 2425332227, 1088985048, 968379098, 1898921015, 403911\n",
      "numpy_rng_state True\n",
      "('MT19937', array([2596069104, 1349613435,  839544100, 2122404663,  755481170,\n",
      "       2533385311, 3278396855, 1916685323, 3045808634, 1223177953,\n",
      "        152798826, 3081814493, 1905644551, 1388174443, 4274171872,\n",
      "       1176821662, 2576437451, 1544515678, 3151178893, 2836536190,\n",
      "       1967010816, 1667632506,  383198365, 1640265480, 3279275941,\n",
      "       2732169879, 3383146979, 1566586235, 1105814334,  837410552,\n",
      "       2455744502, 3029729123, 1820306021, 4182359445, 1202131536,\n",
      "       1508807448, 3112659457, 3560795732, 1420433273, 2985458303,\n",
      "        228735097, 3364358374, 3299938179, 3349585323,  515054452,\n",
      "       2793859313, 3364418317, 4118569653, 3856685054, 3833863170,\n",
      "        186815895, 2983449542, 4282544264, 4215130636,  183222049,\n",
      "       2654081340, 3584883630, 3182026874, 2154678162, 2685127691,\n",
      "       3575075017, 4193581551,  484042330, 1119095745, 4254229248,\n",
      "       1523755888, 4008975575,  596169703, 2108897639,  456604547,\n",
      "        809014773, 3292940016, 2153187623,  306079\n",
      "('MT19937', array([2596069104, 1349613435,  839544100, 2122404663,  755481170,\n",
      "       2533385311, 3278396855, 1916685323, 3045808634, 1223177953,\n",
      "        152798826, 3081814493, 1905644551, 1388174443, 4274171872,\n",
      "       1176821662, 2576437451, 1544515678, 3151178893, 2836536190,\n",
      "       1967010816, 1667632506,  383198365, 1640265480, 3279275941,\n",
      "       2732169879, 3383146979, 1566586235, 1105814334,  837410552,\n",
      "       2455744502, 3029729123, 1820306021, 4182359445, 1202131536,\n",
      "       1508807448, 3112659457, 3560795732, 1420433273, 2985458303,\n",
      "        228735097, 3364358374, 3299938179, 3349585323,  515054452,\n",
      "       2793859313, 3364418317, 4118569653, 3856685054, 3833863170,\n",
      "        186815895, 2983449542, 4282544264, 4215130636,  183222049,\n",
      "       2654081340, 3584883630, 3182026874, 2154678162, 2685127691,\n",
      "       3575075017, 4193581551,  484042330, 1119095745, 4254229248,\n",
      "       1523755888, 4008975575,  596169703, 2108897639,  456604547,\n",
      "        809014773, 3292940016, 2153187623,  306079\n",
      "torch_rng_state True\n",
      "tensor([240, 222, 188,  ...,   0,   0,   0], dtype=torch.uint8)\n",
      "tensor([240, 222, 188,  ...,   0,   0,   0], dtype=torch.uint8)\n",
      "cuda_rng_state True\n",
      "[tensor([240, 222, 188, 154, 120,  86,  52,  18,  12, 250,   0,   0,   0,   0,\n",
      "          0,   0], dtype=torch.uint8)]\n",
      "[tensor([240, 222, 188, 154, 120,  86,  52,  18,  12, 250,   0,   0,   0,   0,\n",
      "          0,   0], dtype=torch.uint8)]\n"
     ]
    }
   ],
   "source": [
    "for key in trainer_state_target.keys():\n",
    "    print(key, str(trainer_state_target[key])[:1000]==str(trainer_state_test[key])[:1000])\n",
    "    print(str(trainer_state_target[key])[:1000])\n",
    "    print(str(trainer_state_test[key])[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_dec True\n",
      "tensor([[ 4.5674e-04,  7.3088e-04,  1.4049e-03,  ...,  8.4608e-04,\n",
      "          1.3882e-03,  1.8400e-03],\n",
      "        [-3.4472e-04,  1.0334e-03,  1.0491e-04,  ...,  1.5954e-03,\n",
      "          9.7445e-04,  1.1271e-03],\n",
      "        [-1.4905e-03,  5.6403e-04, -1.2503e-03,  ..., -5.2135e-03,\n",
      "         -1.9765e-03, -3.2476e-03],\n",
      "        ...,\n",
      "        [ 1.2463e-03,  1.8405e-03,  1.5924e-03,  ...,  1.2724e-03,\n",
      "          3.1043e-05, -2.2264e-05],\n",
      "        [-3.3576e-04,  1.2644e-04,  9.0307e-04,  ...,  7.8625e-04,\n",
      "          1.2375e-03,  1.5447e-03],\n",
      "        [ 1.1262e-03, -1.5962e-03,  1.0016e-03,  ...,  2.8307e-03,\n",
      "         -4.0579e-03, -2.2712e-03]])\n",
      "tensor([[ 4.5674e-04,  7.3088e-04,  1.4049e-03,  ...,  8.4608e-04,\n",
      "          1.3882e-03,  1.8400e-03],\n",
      "        [-3.4472e-04,  1.0334e-03,  1.0491e-04,  ...,  1.5954e-03,\n",
      "          9.7445e-04,  1.1271e-03],\n",
      "        [-1.4905e-03,  5.6403e-04, -1.2503e-03,  ..., -5.2135e-03,\n",
      "         -1.9765e-03, -3.2476e-03],\n",
      "        ...,\n",
      "        [ 1.2463e-03,  1.8405e-03,  1.5924e-03,  ...,  1.2724e-03,\n",
      "          3.1043e-05, -2.2264e-05],\n",
      "        [-3.3576e-04,  1.2644e-04,  9.0307e-04,  ...,  7.8625e-04,\n",
      "          1.2375e-03,  1.5447e-03],\n",
      "        [ 1.1262e-03, -1.5962e-03,  1.0016e-03,  ...,  2.8307e-03,\n",
      "         -4.0579e-03, -2.2712e-03]])\n",
      "W_enc True\n",
      "tensor([[ 0.0726,  0.0338, -0.3251,  ...,  0.0981,  0.0523,  0.0302],\n",
      "        [ 0.0533,  0.1228, -0.0331,  ...,  0.1464, -0.0113,  0.0601],\n",
      "        [ 0.1231,  0.0798,  0.0189,  ...,  0.1694,  0.0876,  0.0542],\n",
      "        ...,\n",
      "        [ 0.1014,  0.2058, -0.2788,  ...,  0.1609,  0.1860,  0.5364],\n",
      "        [ 0.1570,  0.0959, -0.2531,  ...,  0.0855,  0.1225, -0.2194],\n",
      "        [ 0.1158,  0.1423, -0.2960,  ...,  0.1057,  0.1637, -0.1795]])\n",
      "tensor([[ 0.0726,  0.0338, -0.3251,  ...,  0.0981,  0.0523,  0.0302],\n",
      "        [ 0.0533,  0.1228, -0.0331,  ...,  0.1464, -0.0113,  0.0601],\n",
      "        [ 0.1231,  0.0798,  0.0189,  ...,  0.1694,  0.0876,  0.0542],\n",
      "        ...,\n",
      "        [ 0.1014,  0.2058, -0.2788,  ...,  0.1609,  0.1860,  0.5364],\n",
      "        [ 0.1570,  0.0959, -0.2531,  ...,  0.0855,  0.1225, -0.2194],\n",
      "        [ 0.1158,  0.1423, -0.2960,  ...,  0.1057,  0.1637, -0.1795]])\n",
      "b_dec True\n",
      "tensor([ 0.0040, -0.0047,  0.0040, -0.0022, -0.0041, -0.0042,  0.0044, -0.0038,\n",
      "         0.0046, -0.0037, -0.0044,  0.0046, -0.0047, -0.0044,  0.0043, -0.0037,\n",
      "        -0.0042,  0.0045,  0.0032, -0.0043, -0.0028, -0.0042, -0.0042,  0.0035,\n",
      "         0.0045,  0.0040,  0.0046,  0.0044,  0.0047,  0.0030, -0.0039, -0.0042,\n",
      "        -0.0040, -0.0036,  0.0044, -0.0041, -0.0023, -0.0045,  0.0015, -0.0032,\n",
      "        -0.0041,  0.0048, -0.0020,  0.0040, -0.0044, -0.0041,  0.0030, -0.0014,\n",
      "        -0.0039,  0.0027, -0.0043,  0.0043,  0.0039,  0.0045, -0.0043, -0.0044,\n",
      "         0.0046, -0.0041, -0.0029, -0.0034,  0.0041, -0.0045, -0.0043, -0.0044])\n",
      "tensor([ 0.0040, -0.0047,  0.0040, -0.0022, -0.0041, -0.0042,  0.0044, -0.0038,\n",
      "         0.0046, -0.0037, -0.0044,  0.0046, -0.0047, -0.0044,  0.0043, -0.0037,\n",
      "        -0.0042,  0.0045,  0.0032, -0.0043, -0.0028, -0.0042, -0.0042,  0.0035,\n",
      "         0.0045,  0.0040,  0.0046,  0.0044,  0.0047,  0.0030, -0.0039, -0.0042,\n",
      "        -0.0040, -0.0036,  0.0044, -0.0041, -0.0023, -0.0045,  0.0015, -0.0032,\n",
      "        -0.0041,  0.0048, -0.0020,  0.0040, -0.0044, -0.0041,  0.0030, -0.0014,\n",
      "        -0.0039,  0.0027, -0.0043,  0.0043,  0.0039,  0.0045, -0.0043, -0.0044,\n",
      "         0.0046, -0.0041, -0.0029, -0.0034,  0.0041, -0.0045, -0.0043, -0.0044])\n",
      "b_enc True\n",
      "tensor([-0.0034, -0.0038, -0.0211,  ..., -0.0036, -0.0044, -0.0294])\n",
      "tensor([-0.0034, -0.0038, -0.0211,  ..., -0.0036, -0.0044, -0.0294])\n"
     ]
    }
   ],
   "source": [
    "for key in sae_weights_target.keys():\n",
    "    print(key, str(sae_weights_target[key])[:1000]==str(sae_weights_test[key])[:1000])\n",
    "    print(str(sae_weights_target[key])[:1000])\n",
    "    print(str(sae_weights_test[key])[:1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae-lens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
