{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#saelens","title":"SAELens","text":"<p>The SAELens training codebase exists to help researchers:</p> <ul> <li>Train sparse autoencoders.</li> <li>Analyse sparse autoencoders and neural network internals.</li> <li>Generate insights which make it easier to create safe and aligned AI systems.</li> </ul> <p>Please note these docs are in beta. We intend to make them cleaner and more comprehensive over time.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sae-lens\n</code></pre>"},{"location":"#loading-sparse-autoencoders-from-huggingface","title":"Loading Sparse Autoencoders from Huggingface","text":"<p>To load a pretrained sparse autoencoder, you can use <code>SAE.from_pretrained()</code> as below. Note that we return the original cfg dict from the huggingface repo so that it's easy to debug older configs that are being handled when we import an SAE. We also return a sparsity tensor if it is present in the repo. For an example repo structure, see here.</p> <pre><code>from sae_lens import SAE\n\nsae, cfg_dict, sparsity = SAE.from_pretrained(\n    release = \"gpt2-small-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n    sae_id = \"blocks.8.hook_resid_pre\", # won't always be a hook point\n    device = \"cuda\"\n)\n</code></pre> <p>You can see other importable SAEs on this page.</p> <p>Any SAE on Huggingface that's trained using SAELens can also be loaded using <code>SAE.from_pretrained()</code>. In this case, <code>release</code> is the name of the Huggingface repo, and <code>sae_id</code> is the path to the SAE in the repo. You can see a list of SAEs listed on Huggingface with the saelens tag.</p>"},{"location":"#loading-sparse-autoencoders-from-disk","title":"Loading Sparse Autoencoders from Disk","text":"<p>To load a pretrained sparse autoencoder from disk that you've trained yourself, you can use <code>SAE.load_from_disk()</code> as below.</p> <pre><code>from sae_lens import SAE\n\nsae = SAE.load_from_disk(\"/path/to/your/sae\", device=\"cuda\")\n</code></pre>"},{"location":"#importing-saes-from-other-libraries","title":"Importing SAEs from other libraries","text":"<p>You can import an SAE created with another library by writing a custom <code>PretrainedSaeHuggingfaceLoader</code> or <code>PretrainedSaeDiskLoader</code> for use with <code>SAE.from_pretrained()</code> or <code>SAE.load_from_disk()</code>, respectively. See the pretrained_sae_loaders.py file for more details, or ask on the Open Source Mechanistic Interpretability Slack. If you write a good custom loader for another library, please consider contributing it back to SAELens!</p>"},{"location":"#background-and-further-readings","title":"Background and further Readings","text":"<p>We highly recommend this tutorial.</p> <p>For recent progress in SAEs, we recommend the LessWrong forum's Sparse Autoencoder tag</p>"},{"location":"#tutorials","title":"Tutorials","text":"<p>I wrote a tutorial to show users how to do some basic exploration of their SAE:</p> <ul> <li>Loading and Analysing Pre-Trained Sparse Autoencoders </li> <li>Understanding SAE Features with the Logit Lens </li> <li>Training a Sparse Autoencoder </li> </ul>"},{"location":"#example-wandb-dashboard","title":"Example WandB Dashboard","text":"<p>WandB Dashboards provide lots of useful insights while training SAEs. Here's a screenshot from one training run.</p> <p></p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@misc{bloom2024saetrainingcodebase,\n   title = {SAELens},\n   author = {Bloom, Joseph and Tigges, Curt and Duong, Anthony and Chanin, David},\n   year = {2024},\n   howpublished = {\\url{https://github.com/jbloomAus/SAELens}},\n}}\n</code></pre>"},{"location":"api/","title":"API","text":""},{"location":"api/#sae_lens.ActivationsStore","title":"<code>ActivationsStore</code>","text":"<p>Class for streaming tokens and generating and storing activations while training SAEs.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>class ActivationsStore:\n    \"\"\"\n    Class for streaming tokens and generating and storing activations\n    while training SAEs.\n    \"\"\"\n\n    model: HookedRootModule\n    dataset: HfDataset\n    cached_activations_path: str | None\n    cached_activation_dataset: Dataset | None = None\n    tokens_column: Literal[\"tokens\", \"input_ids\", \"text\", \"problem\"]\n    hook_name: str\n    hook_layer: int\n    hook_head_index: int | None\n    _dataloader: Iterator[Any] | None = None\n    _storage_buffer: torch.Tensor | None = None\n    exclude_special_tokens: torch.Tensor | None = None\n    device: torch.device\n\n    @classmethod\n    def from_cache_activations(\n        cls,\n        model: HookedRootModule,\n        cfg: CacheActivationsRunnerConfig,\n    ) -&gt; ActivationsStore:\n        \"\"\"\n        Public api to create an ActivationsStore from a cached activations dataset.\n        \"\"\"\n        return cls(\n            cached_activations_path=cfg.new_cached_activations_path,\n            dtype=cfg.dtype,\n            hook_name=cfg.hook_name,\n            hook_layer=cfg.hook_layer,\n            context_size=cfg.context_size,\n            d_in=cfg.d_in,\n            n_batches_in_buffer=cfg.n_batches_in_buffer,\n            total_training_tokens=cfg.training_tokens,\n            store_batch_size_prompts=cfg.model_batch_size,  # get_buffer\n            train_batch_size_tokens=cfg.model_batch_size,  # dataloader\n            seqpos_slice=(None,),\n            device=torch.device(cfg.device),  # since we're sending these to SAE\n            # NOOP\n            prepend_bos=False,\n            hook_head_index=None,\n            dataset=cfg.dataset_path,\n            streaming=False,\n            model=model,\n            normalize_activations=\"none\",\n            model_kwargs=None,\n            autocast_lm=False,\n            dataset_trust_remote_code=None,\n            exclude_special_tokens=None,\n        )\n\n    @classmethod\n    def from_config(\n        cls,\n        model: HookedRootModule,\n        cfg: LanguageModelSAERunnerConfig | CacheActivationsRunnerConfig,\n        override_dataset: HfDataset | None = None,\n    ) -&gt; ActivationsStore:\n        if isinstance(cfg, CacheActivationsRunnerConfig):\n            return cls.from_cache_activations(model, cfg)\n\n        cached_activations_path = cfg.cached_activations_path\n        # set cached_activations_path to None if we're not using cached activations\n        if (\n            isinstance(cfg, LanguageModelSAERunnerConfig)\n            and not cfg.use_cached_activations\n        ):\n            cached_activations_path = None\n\n        if override_dataset is None and cfg.dataset_path == \"\":\n            raise ValueError(\n                \"You must either pass in a dataset or specify a dataset_path in your configutation.\"\n            )\n\n        device = torch.device(cfg.act_store_device)\n        exclude_special_tokens = cfg.exclude_special_tokens\n        if exclude_special_tokens is False:\n            exclude_special_tokens = None\n        if exclude_special_tokens is True:\n            exclude_special_tokens = _get_special_token_ids(model.tokenizer)  # type: ignore\n        if exclude_special_tokens is not None:\n            exclude_special_tokens = torch.tensor(\n                exclude_special_tokens, dtype=torch.long, device=device\n            )\n        return cls(\n            model=model,\n            dataset=override_dataset or cfg.dataset_path,\n            streaming=cfg.streaming,\n            hook_name=cfg.hook_name,\n            hook_layer=cfg.hook_layer,\n            hook_head_index=cfg.hook_head_index,\n            context_size=cfg.context_size,\n            d_in=cfg.d_in,\n            n_batches_in_buffer=cfg.n_batches_in_buffer,\n            total_training_tokens=cfg.training_tokens,\n            store_batch_size_prompts=cfg.store_batch_size_prompts,\n            train_batch_size_tokens=cfg.train_batch_size_tokens,\n            prepend_bos=cfg.prepend_bos,\n            normalize_activations=cfg.normalize_activations,\n            device=device,\n            dtype=cfg.dtype,\n            cached_activations_path=cached_activations_path,\n            model_kwargs=cfg.model_kwargs,\n            autocast_lm=cfg.autocast_lm,\n            dataset_trust_remote_code=cfg.dataset_trust_remote_code,\n            seqpos_slice=cfg.seqpos_slice,\n            exclude_special_tokens=exclude_special_tokens,\n        )\n\n    @classmethod\n    def from_sae(\n        cls,\n        model: HookedRootModule,\n        sae: SAE,\n        context_size: int | None = None,\n        dataset: HfDataset | str | None = None,\n        streaming: bool = True,\n        store_batch_size_prompts: int = 8,\n        n_batches_in_buffer: int = 8,\n        train_batch_size_tokens: int = 4096,\n        total_tokens: int = 10**9,\n        device: str = \"cpu\",\n    ) -&gt; ActivationsStore:\n        return cls(\n            model=model,\n            dataset=sae.cfg.dataset_path if dataset is None else dataset,\n            d_in=sae.cfg.d_in,\n            hook_name=sae.cfg.hook_name,\n            hook_layer=sae.cfg.hook_layer,\n            hook_head_index=sae.cfg.hook_head_index,\n            context_size=sae.cfg.context_size if context_size is None else context_size,\n            prepend_bos=sae.cfg.prepend_bos,\n            streaming=streaming,\n            store_batch_size_prompts=store_batch_size_prompts,\n            train_batch_size_tokens=train_batch_size_tokens,\n            n_batches_in_buffer=n_batches_in_buffer,\n            total_training_tokens=total_tokens,\n            normalize_activations=sae.cfg.normalize_activations,\n            dataset_trust_remote_code=sae.cfg.dataset_trust_remote_code,\n            dtype=sae.cfg.dtype,\n            device=torch.device(device),\n            seqpos_slice=sae.cfg.seqpos_slice,\n        )\n\n    def __init__(\n        self,\n        model: HookedRootModule,\n        dataset: HfDataset | str,\n        streaming: bool,\n        hook_name: str,\n        hook_layer: int,\n        hook_head_index: int | None,\n        context_size: int,\n        d_in: int,\n        n_batches_in_buffer: int,\n        total_training_tokens: int,\n        store_batch_size_prompts: int,\n        train_batch_size_tokens: int,\n        prepend_bos: bool,\n        normalize_activations: str,\n        device: torch.device,\n        dtype: str,\n        cached_activations_path: str | None = None,\n        model_kwargs: dict[str, Any] | None = None,\n        autocast_lm: bool = False,\n        dataset_trust_remote_code: bool | None = None,\n        seqpos_slice: tuple[int | None, ...] = (None,),\n        exclude_special_tokens: torch.Tensor | None = None,\n    ):\n        self.model = model\n        if model_kwargs is None:\n            model_kwargs = {}\n        self.model_kwargs = model_kwargs\n        self.dataset = (\n            load_dataset(\n                dataset,\n                split=\"train\",\n                streaming=streaming,\n                trust_remote_code=dataset_trust_remote_code,  # type: ignore\n            )\n            if isinstance(dataset, str)\n            else dataset\n        )\n\n        if isinstance(dataset, (Dataset, DatasetDict)):\n            self.dataset = cast(Dataset | DatasetDict, self.dataset)\n            n_samples = len(self.dataset)\n\n            if n_samples &lt; total_training_tokens:\n                warnings.warn(\n                    f\"The training dataset contains fewer samples ({n_samples}) than the number of samples required by your training configuration ({total_training_tokens}). This will result in multiple training epochs and some samples being used more than once.\"\n                )\n\n        self.hook_name = hook_name\n        self.hook_layer = hook_layer\n        self.hook_head_index = hook_head_index\n        self.context_size = context_size\n        self.d_in = d_in\n        self.n_batches_in_buffer = n_batches_in_buffer\n        self.half_buffer_size = n_batches_in_buffer // 2\n        self.total_training_tokens = total_training_tokens\n        self.store_batch_size_prompts = store_batch_size_prompts\n        self.train_batch_size_tokens = train_batch_size_tokens\n        self.prepend_bos = prepend_bos\n        self.normalize_activations = normalize_activations\n        self.device = torch.device(device)\n        self.dtype = DTYPE_MAP[dtype]\n        self.cached_activations_path = cached_activations_path\n        self.autocast_lm = autocast_lm\n        self.seqpos_slice = seqpos_slice\n        self.exclude_special_tokens = exclude_special_tokens\n\n        self.n_dataset_processed = 0\n\n        self.estimated_norm_scaling_factor = None\n\n        # Check if dataset is tokenized\n        dataset_sample = next(iter(self.dataset))\n\n        # check if it's tokenized\n        if \"tokens\" in dataset_sample:\n            self.is_dataset_tokenized = True\n            self.tokens_column = \"tokens\"\n        elif \"input_ids\" in dataset_sample:\n            self.is_dataset_tokenized = True\n            self.tokens_column = \"input_ids\"\n        elif \"text\" in dataset_sample:\n            self.is_dataset_tokenized = False\n            self.tokens_column = \"text\"\n        elif \"problem\" in dataset_sample:\n            self.is_dataset_tokenized = False\n            self.tokens_column = \"problem\"\n        else:\n            raise ValueError(\n                \"Dataset must have a 'tokens', 'input_ids', 'text', or 'problem' column.\"\n            )\n        if self.is_dataset_tokenized:\n            ds_context_size = len(dataset_sample[self.tokens_column])\n            if ds_context_size &lt; self.context_size:\n                raise ValueError(\n                    f\"\"\"pretokenized dataset has context_size {ds_context_size}, but the provided context_size is {self.context_size}.\n                    The context_size {ds_context_size} is expected to be larger than or equal to the provided context size {self.context_size}.\"\"\"\n                )\n            if self.context_size != ds_context_size:\n                warnings.warn(\n                    f\"\"\"pretokenized dataset has context_size {ds_context_size}, but the provided context_size is {self.context_size}. Some data will be discarded in this case.\"\"\",\n                    RuntimeWarning,\n                )\n            # TODO: investigate if this can work for iterable datasets, or if this is even worthwhile as a perf improvement\n            if hasattr(self.dataset, \"set_format\"):\n                self.dataset.set_format(type=\"torch\", columns=[self.tokens_column])  # type: ignore\n\n            if (\n                isinstance(dataset, str)\n                and hasattr(model, \"tokenizer\")\n                and model.tokenizer is not None\n            ):\n                validate_pretokenized_dataset_tokenizer(\n                    dataset_path=dataset,\n                    model_tokenizer=model.tokenizer,  # type: ignore\n                )\n        else:\n            warnings.warn(\n                \"Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\"\n            )\n\n        self.iterable_sequences = self._iterate_tokenized_sequences()\n\n        self.cached_activation_dataset = self.load_cached_activation_dataset()\n\n        # TODO add support for \"mixed loading\" (ie use cache until you run out, then switch over to streaming from HF)\n\n    def _iterate_raw_dataset(\n        self,\n    ) -&gt; Generator[torch.Tensor | list[int] | str, None, None]:\n        \"\"\"\n        Helper to iterate over the dataset while incrementing n_dataset_processed\n        \"\"\"\n        for row in self.dataset:\n            # typing datasets is difficult\n            yield row[self.tokens_column]  # type: ignore\n            self.n_dataset_processed += 1\n\n    def _iterate_raw_dataset_tokens(self) -&gt; Generator[torch.Tensor, None, None]:\n        \"\"\"\n        Helper to create an iterator which tokenizes raw text from the dataset on the fly\n        \"\"\"\n        for row in self._iterate_raw_dataset():\n            tokens = (\n                self.model.to_tokens(\n                    row,\n                    truncate=False,\n                    move_to_device=False,  # we move to device below\n                    prepend_bos=False,\n                )  # type: ignore\n                .squeeze(0)\n                .to(self.device)\n            )\n            if len(tokens.shape) != 1:\n                raise ValueError(f\"tokens.shape should be 1D but was {tokens.shape}\")\n            yield tokens\n\n    def _iterate_tokenized_sequences(self) -&gt; Generator[torch.Tensor, None, None]:\n        \"\"\"\n        Generator which iterates over full sequence of context_size tokens\n        \"\"\"\n        # If the datset is pretokenized, we will slice the dataset to the length of the context window if needed. Otherwise, no further processing is needed.\n        # We assume that all necessary BOS/EOS/SEP tokens have been added during pretokenization.\n        if self.is_dataset_tokenized:\n            for row in self._iterate_raw_dataset():\n                yield torch.tensor(\n                    row[\n                        : self.context_size\n                    ],  # If self.context_size = None, this line simply returns the whole row\n                    dtype=torch.long,\n                    device=self.device,\n                    requires_grad=False,\n                )\n        # If the dataset isn't tokenized, we'll tokenize, concat, and batch on the fly\n        else:\n            tokenizer = getattr(self.model, \"tokenizer\", None)\n            bos_token_id = None if tokenizer is None else tokenizer.bos_token_id\n            yield from concat_and_batch_sequences(\n                tokens_iterator=self._iterate_raw_dataset_tokens(),\n                context_size=self.context_size,\n                begin_batch_token_id=(bos_token_id if self.prepend_bos else None),\n                begin_sequence_token_id=None,\n                sequence_separator_token_id=(\n                    bos_token_id if self.prepend_bos else None\n                ),\n            )\n\n    def load_cached_activation_dataset(self) -&gt; Dataset | None:\n        \"\"\"\n        Load the cached activation dataset from disk.\n\n        - If cached_activations_path is set, returns Huggingface Dataset else None\n        - Checks that the loaded dataset has current has activations for hooks in config and that shapes match.\n        \"\"\"\n        if self.cached_activations_path is None:\n            return None\n\n        assert self.cached_activations_path is not None  # keep pyright happy\n        # Sanity check: does the cache directory exist?\n        if not os.path.exists(self.cached_activations_path):\n            raise FileNotFoundError(\n                f\"Cache directory {self.cached_activations_path} does not exist. \"\n                \"Consider double-checking your dataset, model, and hook names.\"\n            )\n\n        # ---\n        # Actual code\n        activations_dataset = datasets.load_from_disk(self.cached_activations_path)\n        columns = [self.hook_name]\n        if \"token_ids\" in activations_dataset.column_names:\n            columns.append(\"token_ids\")\n        activations_dataset.set_format(\n            type=\"torch\", columns=columns, device=self.device, dtype=self.dtype\n        )\n        self.current_row_idx = 0  # idx to load next batch from\n        # ---\n\n        assert isinstance(activations_dataset, Dataset)\n\n        # multiple in hooks future\n        if not set([self.hook_name]).issubset(activations_dataset.column_names):\n            raise ValueError(\n                f\"loaded dataset does not include hook activations, got {activations_dataset.column_names}\"\n            )\n\n        if activations_dataset.features[self.hook_name].shape != (\n            self.context_size,\n            self.d_in,\n        ):\n            raise ValueError(\n                f\"Given dataset of shape {activations_dataset.features[self.hook_name].shape} does not match context_size ({self.context_size}) and d_in ({self.d_in})\"\n            )\n\n        return activations_dataset\n\n    def set_norm_scaling_factor_if_needed(self):\n        if (\n            self.normalize_activations == \"expected_average_only_in\"\n            and self.estimated_norm_scaling_factor is None\n        ):\n            self.estimated_norm_scaling_factor = self.estimate_norm_scaling_factor()\n\n    def apply_norm_scaling_factor(self, activations: torch.Tensor) -&gt; torch.Tensor:\n        if self.estimated_norm_scaling_factor is None:\n            raise ValueError(\n                \"estimated_norm_scaling_factor is not set, call set_norm_scaling_factor_if_needed() first\"\n            )\n        return activations * self.estimated_norm_scaling_factor\n\n    def unscale(self, activations: torch.Tensor) -&gt; torch.Tensor:\n        if self.estimated_norm_scaling_factor is None:\n            raise ValueError(\n                \"estimated_norm_scaling_factor is not set, call set_norm_scaling_factor_if_needed() first\"\n            )\n        return activations / self.estimated_norm_scaling_factor\n\n    def get_norm_scaling_factor(self, activations: torch.Tensor) -&gt; torch.Tensor:\n        return (self.d_in**0.5) / activations.norm(dim=-1).mean()\n\n    @torch.no_grad()\n    def estimate_norm_scaling_factor(self, n_batches_for_norm_estimate: int = int(1e3)):\n        norms_per_batch = []\n        for _ in tqdm(\n            range(n_batches_for_norm_estimate), desc=\"Estimating norm scaling factor\"\n        ):\n            # temporalily set estimated_norm_scaling_factor to 1.0 so the dataloader works\n            self.estimated_norm_scaling_factor = 1.0\n            acts = self.next_batch()[:, 0]\n            self.estimated_norm_scaling_factor = None\n            norms_per_batch.append(acts.norm(dim=-1).mean().item())\n        mean_norm = np.mean(norms_per_batch)\n        return np.sqrt(self.d_in) / mean_norm\n\n    def shuffle_input_dataset(self, seed: int, buffer_size: int = 1):\n        \"\"\"\n        This applies a shuffle to the huggingface dataset that is the input to the activations store. This\n        also shuffles the shards of the dataset, which is especially useful for evaluating on different\n        sections of very large streaming datasets. Buffer size is only relevant for streaming datasets.\n        The default buffer_size of 1 means that only the shard will be shuffled; larger buffer sizes will\n        additionally shuffle individual elements within the shard.\n        \"\"\"\n        if isinstance(self.dataset, IterableDataset):\n            self.dataset = self.dataset.shuffle(seed=seed, buffer_size=buffer_size)\n        else:\n            self.dataset = self.dataset.shuffle(seed=seed)\n        self.iterable_dataset = iter(self.dataset)\n\n    def reset_input_dataset(self):\n        \"\"\"\n        Resets the input dataset iterator to the beginning.\n        \"\"\"\n        self.iterable_dataset = iter(self.dataset)\n\n    @property\n    def storage_buffer(self) -&gt; torch.Tensor:\n        if self._storage_buffer is None:\n            self._storage_buffer = _filter_buffer_acts(\n                self.get_buffer(self.half_buffer_size), self.exclude_special_tokens\n            )\n\n        return self._storage_buffer\n\n    @property\n    def dataloader(self) -&gt; Iterator[Any]:\n        if self._dataloader is None:\n            self._dataloader = self.get_data_loader()\n        return self._dataloader\n\n    def get_batch_tokens(\n        self, batch_size: int | None = None, raise_at_epoch_end: bool = False\n    ):\n        \"\"\"\n        Streams a batch of tokens from a dataset.\n\n        If raise_at_epoch_end is true we will reset the dataset at the end of each epoch and raise a StopIteration. Otherwise we will reset silently.\n        \"\"\"\n        if not batch_size:\n            batch_size = self.store_batch_size_prompts\n        sequences = []\n        # the sequences iterator yields fully formed tokens of size context_size, so we just need to cat these into a batch\n        for _ in range(batch_size):\n            try:\n                sequences.append(next(self.iterable_sequences))\n            except StopIteration:\n                self.iterable_sequences = self._iterate_tokenized_sequences()\n                if raise_at_epoch_end:\n                    raise StopIteration(\n                        f\"Ran out of tokens in dataset after {self.n_dataset_processed} samples, beginning the next epoch.\"\n                    )\n                sequences.append(next(self.iterable_sequences))\n\n        return torch.stack(sequences, dim=0).to(_get_model_device(self.model))\n\n    @torch.no_grad()\n    def get_activations(self, batch_tokens: torch.Tensor):\n        \"\"\"\n        Returns activations of shape (batches, context, num_layers, d_in)\n\n        d_in may result from a concatenated head dimension.\n        \"\"\"\n\n        # Setup autocast if using\n        if self.autocast_lm:\n            autocast_if_enabled = torch.autocast(\n                device_type=\"cuda\",\n                dtype=torch.bfloat16,\n                enabled=self.autocast_lm,\n            )\n        else:\n            autocast_if_enabled = contextlib.nullcontext()\n\n        with autocast_if_enabled:\n            layerwise_activations_cache = self.model.run_with_cache(\n                batch_tokens,\n                names_filter=[self.hook_name],\n                stop_at_layer=self.hook_layer + 1,\n                prepend_bos=False,\n                **self.model_kwargs,\n            )[1]\n\n        layerwise_activations = layerwise_activations_cache[self.hook_name][\n            :, slice(*self.seqpos_slice)\n        ]\n\n        n_batches, n_context = layerwise_activations.shape[:2]\n\n        stacked_activations = torch.zeros((n_batches, n_context, 1, self.d_in))\n\n        if self.hook_head_index is not None:\n            stacked_activations[:, :, 0] = layerwise_activations[\n                :, :, self.hook_head_index\n            ]\n        elif layerwise_activations.ndim &gt; 3:  # if we have a head dimension\n            try:\n                stacked_activations[:, :, 0] = layerwise_activations.view(\n                    n_batches, n_context, -1\n                )\n            except RuntimeError as e:\n                logger.error(f\"Error during view operation: {e}\")\n                logger.info(\"Attempting to use reshape instead...\")\n                stacked_activations[:, :, 0] = layerwise_activations.reshape(\n                    n_batches, n_context, -1\n                )\n        else:\n            stacked_activations[:, :, 0] = layerwise_activations\n\n        return stacked_activations\n\n    def _load_buffer_from_cached(\n        self,\n        total_size: int,\n        context_size: int,\n        num_layers: int,\n        d_in: int,\n        raise_on_epoch_end: bool,\n    ) -&gt; tuple[\n        Float[torch.Tensor, \"(total_size context_size) num_layers d_in\"],\n        Int[torch.Tensor, \"(total_size context_size)\"] | None,\n    ]:\n        \"\"\"\n        Loads `total_size` activations from `cached_activation_dataset`\n\n        The dataset has columns for each hook_name,\n        each containing activations of shape (context_size, d_in).\n\n        raises StopIteration\n        \"\"\"\n        assert self.cached_activation_dataset is not None\n        # In future, could be a list of multiple hook names\n        hook_names = [self.hook_name]\n        if not set(hook_names).issubset(self.cached_activation_dataset.column_names):\n            raise ValueError(\n                f\"Missing columns in dataset. Expected {hook_names}, \"\n                f\"got {self.cached_activation_dataset.column_names}.\"\n            )\n\n        if self.current_row_idx &gt; len(self.cached_activation_dataset) - total_size:\n            self.current_row_idx = 0\n            if raise_on_epoch_end:\n                raise StopIteration\n\n        new_buffer = []\n        ds_slice = self.cached_activation_dataset[\n            self.current_row_idx : self.current_row_idx + total_size\n        ]\n        for hook_name in hook_names:\n            # Load activations for each hook.\n            # Usually faster to first slice dataset then pick column\n            _hook_buffer = ds_slice[hook_name]\n            if _hook_buffer.shape != (total_size, context_size, d_in):\n                raise ValueError(\n                    f\"_hook_buffer has shape {_hook_buffer.shape}, \"\n                    f\"but expected ({total_size}, {context_size}, {d_in}).\"\n                )\n            new_buffer.append(_hook_buffer)\n\n        # Stack across num_layers dimension\n        # list of num_layers; shape: (total_size, context_size, d_in) -&gt; (total_size, context_size, num_layers, d_in)\n        new_buffer = torch.stack(new_buffer, dim=2)\n        if new_buffer.shape != (total_size, context_size, num_layers, d_in):\n            raise ValueError(\n                f\"new_buffer has shape {new_buffer.shape}, \"\n                f\"but expected ({total_size}, {context_size}, {num_layers}, {d_in}).\"\n            )\n\n        self.current_row_idx += total_size\n        acts_buffer = new_buffer.reshape(total_size * context_size, num_layers, d_in)\n\n        if \"token_ids\" not in self.cached_activation_dataset.column_names:\n            return acts_buffer, None\n\n        token_ids_buffer = ds_slice[\"token_ids\"]\n        if token_ids_buffer.shape != (total_size, context_size):\n            raise ValueError(\n                f\"token_ids_buffer has shape {token_ids_buffer.shape}, \"\n                f\"but expected ({total_size}, {context_size}).\"\n            )\n        token_ids_buffer = token_ids_buffer.reshape(total_size * context_size)\n        return acts_buffer, token_ids_buffer\n\n    @torch.no_grad()\n    def get_buffer(\n        self,\n        n_batches_in_buffer: int,\n        raise_on_epoch_end: bool = False,\n        shuffle: bool = True,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor | None]:\n        \"\"\"\n        Loads the next n_batches_in_buffer batches of activations into a tensor and returns it.\n\n        The primary purpose here is maintaining a shuffling buffer.\n\n        If raise_on_epoch_end is True, when the dataset it exhausted it will automatically refill the dataset and then raise a StopIteration so that the caller has a chance to react.\n        \"\"\"\n        context_size = self.context_size\n        training_context_size = len(range(context_size)[slice(*self.seqpos_slice)])\n        batch_size = self.store_batch_size_prompts\n        d_in = self.d_in\n        total_size = batch_size * n_batches_in_buffer\n        num_layers = 1\n\n        if self.cached_activation_dataset is not None:\n            return self._load_buffer_from_cached(\n                total_size, context_size, num_layers, d_in, raise_on_epoch_end\n            )\n\n        refill_iterator = range(0, total_size, batch_size)\n        # Initialize empty tensor buffer of the maximum required size with an additional dimension for layers\n        new_buffer_activations = torch.zeros(\n            (total_size, training_context_size, num_layers, d_in),\n            dtype=self.dtype,  # type: ignore\n            device=self.device,\n        )\n        new_buffer_token_ids = torch.zeros(\n            (total_size, training_context_size),\n            dtype=torch.long,\n            device=self.device,\n        )\n\n        for refill_batch_idx_start in tqdm(\n            refill_iterator, leave=False, desc=\"Refilling buffer\"\n        ):\n            # move batch toks to gpu for model\n            refill_batch_tokens = self.get_batch_tokens(\n                raise_at_epoch_end=raise_on_epoch_end\n            ).to(_get_model_device(self.model))\n            refill_activations = self.get_activations(refill_batch_tokens)\n            # move acts back to cpu\n            refill_activations.to(self.device)\n            new_buffer_activations[\n                refill_batch_idx_start : refill_batch_idx_start + batch_size, ...\n            ] = refill_activations\n\n            # handle seqpos_slice, this is done for activations in get_activations\n            refill_batch_tokens = refill_batch_tokens[:, slice(*self.seqpos_slice)]\n            new_buffer_token_ids[\n                refill_batch_idx_start : refill_batch_idx_start + batch_size, ...\n            ] = refill_batch_tokens\n\n        new_buffer_activations = new_buffer_activations.reshape(-1, num_layers, d_in)\n        new_buffer_token_ids = new_buffer_token_ids.reshape(-1)\n        if shuffle:\n            new_buffer_activations, new_buffer_token_ids = permute_together(\n                [new_buffer_activations, new_buffer_token_ids]\n            )\n\n        # every buffer should be normalized:\n        if self.normalize_activations == \"expected_average_only_in\":\n            new_buffer_activations = self.apply_norm_scaling_factor(\n                new_buffer_activations\n            )\n\n        return (\n            new_buffer_activations,\n            new_buffer_token_ids,\n        )\n\n    def get_data_loader(\n        self,\n    ) -&gt; Iterator[Any]:\n        \"\"\"\n        Return a torch.utils.dataloader which you can get batches from.\n\n        Should automatically refill the buffer when it gets to n % full.\n        (better mixing if you refill and shuffle regularly).\n\n        \"\"\"\n\n        batch_size = self.train_batch_size_tokens\n\n        try:\n            new_samples = _filter_buffer_acts(\n                self.get_buffer(self.half_buffer_size, raise_on_epoch_end=True),\n                self.exclude_special_tokens,\n            )\n        except StopIteration:\n            warnings.warn(\n                \"All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\"\n            )\n            self._storage_buffer = (\n                None  # dump the current buffer so samples do not leak between epochs\n            )\n            try:\n                new_samples = _filter_buffer_acts(\n                    self.get_buffer(self.half_buffer_size),\n                    self.exclude_special_tokens,\n                )\n            except StopIteration:\n                raise ValueError(\n                    \"We were unable to fill up the buffer directly after starting a new epoch. This could indicate that there are less samples in the dataset than are required to fill up the buffer. Consider reducing batch_size or n_batches_in_buffer. \"\n                )\n\n        # 1. # create new buffer by mixing stored and new buffer\n        mixing_buffer = torch.cat(\n            [new_samples, self.storage_buffer],\n            dim=0,\n        )\n\n        mixing_buffer = mixing_buffer[torch.randperm(mixing_buffer.shape[0])]\n\n        # 2.  put 50 % in storage\n        self._storage_buffer = mixing_buffer[: mixing_buffer.shape[0] // 2]\n\n        # 3. put other 50 % in a dataloader\n        return iter(\n            DataLoader(\n                # TODO: seems like a typing bug?\n                cast(Any, mixing_buffer[mixing_buffer.shape[0] // 2 :]),\n                batch_size=batch_size,\n                shuffle=True,\n            )\n        )\n\n    def next_batch(self) -&gt; torch.Tensor:\n        \"\"\"\n        Get the next batch from the current DataLoader.\n        If the DataLoader is exhausted, refill the buffer and create a new DataLoader.\n        \"\"\"\n        try:\n            # Try to get the next batch\n            return next(self.dataloader)\n        except StopIteration:\n            # If the DataLoader is exhausted, create a new one\n            self._dataloader = self.get_data_loader()\n            return next(self.dataloader)\n\n    def state_dict(self) -&gt; dict[str, torch.Tensor]:\n        result = {\n            \"n_dataset_processed\": torch.tensor(self.n_dataset_processed),\n        }\n        if self._storage_buffer is not None:  # first time might be None\n            result[\"storage_buffer_activations\"] = self._storage_buffer[0]\n            if self._storage_buffer[1] is not None:\n                result[\"storage_buffer_tokens\"] = self._storage_buffer[1]\n        if self.estimated_norm_scaling_factor is not None:\n            result[\"estimated_norm_scaling_factor\"] = torch.tensor(\n                self.estimated_norm_scaling_factor\n            )\n        return result\n\n    def save(self, file_path: str):\n        \"\"\"save the state dict to a file in safetensors format\"\"\"\n        save_file(self.state_dict(), file_path)\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.from_cache_activations","title":"<code>from_cache_activations(model, cfg)</code>  <code>classmethod</code>","text":"<p>Public api to create an ActivationsStore from a cached activations dataset.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>@classmethod\ndef from_cache_activations(\n    cls,\n    model: HookedRootModule,\n    cfg: CacheActivationsRunnerConfig,\n) -&gt; ActivationsStore:\n    \"\"\"\n    Public api to create an ActivationsStore from a cached activations dataset.\n    \"\"\"\n    return cls(\n        cached_activations_path=cfg.new_cached_activations_path,\n        dtype=cfg.dtype,\n        hook_name=cfg.hook_name,\n        hook_layer=cfg.hook_layer,\n        context_size=cfg.context_size,\n        d_in=cfg.d_in,\n        n_batches_in_buffer=cfg.n_batches_in_buffer,\n        total_training_tokens=cfg.training_tokens,\n        store_batch_size_prompts=cfg.model_batch_size,  # get_buffer\n        train_batch_size_tokens=cfg.model_batch_size,  # dataloader\n        seqpos_slice=(None,),\n        device=torch.device(cfg.device),  # since we're sending these to SAE\n        # NOOP\n        prepend_bos=False,\n        hook_head_index=None,\n        dataset=cfg.dataset_path,\n        streaming=False,\n        model=model,\n        normalize_activations=\"none\",\n        model_kwargs=None,\n        autocast_lm=False,\n        dataset_trust_remote_code=None,\n        exclude_special_tokens=None,\n    )\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.get_activations","title":"<code>get_activations(batch_tokens)</code>","text":"<p>Returns activations of shape (batches, context, num_layers, d_in)</p> <p>d_in may result from a concatenated head dimension.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>@torch.no_grad()\ndef get_activations(self, batch_tokens: torch.Tensor):\n    \"\"\"\n    Returns activations of shape (batches, context, num_layers, d_in)\n\n    d_in may result from a concatenated head dimension.\n    \"\"\"\n\n    # Setup autocast if using\n    if self.autocast_lm:\n        autocast_if_enabled = torch.autocast(\n            device_type=\"cuda\",\n            dtype=torch.bfloat16,\n            enabled=self.autocast_lm,\n        )\n    else:\n        autocast_if_enabled = contextlib.nullcontext()\n\n    with autocast_if_enabled:\n        layerwise_activations_cache = self.model.run_with_cache(\n            batch_tokens,\n            names_filter=[self.hook_name],\n            stop_at_layer=self.hook_layer + 1,\n            prepend_bos=False,\n            **self.model_kwargs,\n        )[1]\n\n    layerwise_activations = layerwise_activations_cache[self.hook_name][\n        :, slice(*self.seqpos_slice)\n    ]\n\n    n_batches, n_context = layerwise_activations.shape[:2]\n\n    stacked_activations = torch.zeros((n_batches, n_context, 1, self.d_in))\n\n    if self.hook_head_index is not None:\n        stacked_activations[:, :, 0] = layerwise_activations[\n            :, :, self.hook_head_index\n        ]\n    elif layerwise_activations.ndim &gt; 3:  # if we have a head dimension\n        try:\n            stacked_activations[:, :, 0] = layerwise_activations.view(\n                n_batches, n_context, -1\n            )\n        except RuntimeError as e:\n            logger.error(f\"Error during view operation: {e}\")\n            logger.info(\"Attempting to use reshape instead...\")\n            stacked_activations[:, :, 0] = layerwise_activations.reshape(\n                n_batches, n_context, -1\n            )\n    else:\n        stacked_activations[:, :, 0] = layerwise_activations\n\n    return stacked_activations\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.get_batch_tokens","title":"<code>get_batch_tokens(batch_size=None, raise_at_epoch_end=False)</code>","text":"<p>Streams a batch of tokens from a dataset.</p> <p>If raise_at_epoch_end is true we will reset the dataset at the end of each epoch and raise a StopIteration. Otherwise we will reset silently.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>def get_batch_tokens(\n    self, batch_size: int | None = None, raise_at_epoch_end: bool = False\n):\n    \"\"\"\n    Streams a batch of tokens from a dataset.\n\n    If raise_at_epoch_end is true we will reset the dataset at the end of each epoch and raise a StopIteration. Otherwise we will reset silently.\n    \"\"\"\n    if not batch_size:\n        batch_size = self.store_batch_size_prompts\n    sequences = []\n    # the sequences iterator yields fully formed tokens of size context_size, so we just need to cat these into a batch\n    for _ in range(batch_size):\n        try:\n            sequences.append(next(self.iterable_sequences))\n        except StopIteration:\n            self.iterable_sequences = self._iterate_tokenized_sequences()\n            if raise_at_epoch_end:\n                raise StopIteration(\n                    f\"Ran out of tokens in dataset after {self.n_dataset_processed} samples, beginning the next epoch.\"\n                )\n            sequences.append(next(self.iterable_sequences))\n\n    return torch.stack(sequences, dim=0).to(_get_model_device(self.model))\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.get_buffer","title":"<code>get_buffer(n_batches_in_buffer, raise_on_epoch_end=False, shuffle=True)</code>","text":"<p>Loads the next n_batches_in_buffer batches of activations into a tensor and returns it.</p> <p>The primary purpose here is maintaining a shuffling buffer.</p> <p>If raise_on_epoch_end is True, when the dataset it exhausted it will automatically refill the dataset and then raise a StopIteration so that the caller has a chance to react.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>@torch.no_grad()\ndef get_buffer(\n    self,\n    n_batches_in_buffer: int,\n    raise_on_epoch_end: bool = False,\n    shuffle: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor | None]:\n    \"\"\"\n    Loads the next n_batches_in_buffer batches of activations into a tensor and returns it.\n\n    The primary purpose here is maintaining a shuffling buffer.\n\n    If raise_on_epoch_end is True, when the dataset it exhausted it will automatically refill the dataset and then raise a StopIteration so that the caller has a chance to react.\n    \"\"\"\n    context_size = self.context_size\n    training_context_size = len(range(context_size)[slice(*self.seqpos_slice)])\n    batch_size = self.store_batch_size_prompts\n    d_in = self.d_in\n    total_size = batch_size * n_batches_in_buffer\n    num_layers = 1\n\n    if self.cached_activation_dataset is not None:\n        return self._load_buffer_from_cached(\n            total_size, context_size, num_layers, d_in, raise_on_epoch_end\n        )\n\n    refill_iterator = range(0, total_size, batch_size)\n    # Initialize empty tensor buffer of the maximum required size with an additional dimension for layers\n    new_buffer_activations = torch.zeros(\n        (total_size, training_context_size, num_layers, d_in),\n        dtype=self.dtype,  # type: ignore\n        device=self.device,\n    )\n    new_buffer_token_ids = torch.zeros(\n        (total_size, training_context_size),\n        dtype=torch.long,\n        device=self.device,\n    )\n\n    for refill_batch_idx_start in tqdm(\n        refill_iterator, leave=False, desc=\"Refilling buffer\"\n    ):\n        # move batch toks to gpu for model\n        refill_batch_tokens = self.get_batch_tokens(\n            raise_at_epoch_end=raise_on_epoch_end\n        ).to(_get_model_device(self.model))\n        refill_activations = self.get_activations(refill_batch_tokens)\n        # move acts back to cpu\n        refill_activations.to(self.device)\n        new_buffer_activations[\n            refill_batch_idx_start : refill_batch_idx_start + batch_size, ...\n        ] = refill_activations\n\n        # handle seqpos_slice, this is done for activations in get_activations\n        refill_batch_tokens = refill_batch_tokens[:, slice(*self.seqpos_slice)]\n        new_buffer_token_ids[\n            refill_batch_idx_start : refill_batch_idx_start + batch_size, ...\n        ] = refill_batch_tokens\n\n    new_buffer_activations = new_buffer_activations.reshape(-1, num_layers, d_in)\n    new_buffer_token_ids = new_buffer_token_ids.reshape(-1)\n    if shuffle:\n        new_buffer_activations, new_buffer_token_ids = permute_together(\n            [new_buffer_activations, new_buffer_token_ids]\n        )\n\n    # every buffer should be normalized:\n    if self.normalize_activations == \"expected_average_only_in\":\n        new_buffer_activations = self.apply_norm_scaling_factor(\n            new_buffer_activations\n        )\n\n    return (\n        new_buffer_activations,\n        new_buffer_token_ids,\n    )\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.get_data_loader","title":"<code>get_data_loader()</code>","text":"<p>Return a torch.utils.dataloader which you can get batches from.</p> <p>Should automatically refill the buffer when it gets to n % full. (better mixing if you refill and shuffle regularly).</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>def get_data_loader(\n    self,\n) -&gt; Iterator[Any]:\n    \"\"\"\n    Return a torch.utils.dataloader which you can get batches from.\n\n    Should automatically refill the buffer when it gets to n % full.\n    (better mixing if you refill and shuffle regularly).\n\n    \"\"\"\n\n    batch_size = self.train_batch_size_tokens\n\n    try:\n        new_samples = _filter_buffer_acts(\n            self.get_buffer(self.half_buffer_size, raise_on_epoch_end=True),\n            self.exclude_special_tokens,\n        )\n    except StopIteration:\n        warnings.warn(\n            \"All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\"\n        )\n        self._storage_buffer = (\n            None  # dump the current buffer so samples do not leak between epochs\n        )\n        try:\n            new_samples = _filter_buffer_acts(\n                self.get_buffer(self.half_buffer_size),\n                self.exclude_special_tokens,\n            )\n        except StopIteration:\n            raise ValueError(\n                \"We were unable to fill up the buffer directly after starting a new epoch. This could indicate that there are less samples in the dataset than are required to fill up the buffer. Consider reducing batch_size or n_batches_in_buffer. \"\n            )\n\n    # 1. # create new buffer by mixing stored and new buffer\n    mixing_buffer = torch.cat(\n        [new_samples, self.storage_buffer],\n        dim=0,\n    )\n\n    mixing_buffer = mixing_buffer[torch.randperm(mixing_buffer.shape[0])]\n\n    # 2.  put 50 % in storage\n    self._storage_buffer = mixing_buffer[: mixing_buffer.shape[0] // 2]\n\n    # 3. put other 50 % in a dataloader\n    return iter(\n        DataLoader(\n            # TODO: seems like a typing bug?\n            cast(Any, mixing_buffer[mixing_buffer.shape[0] // 2 :]),\n            batch_size=batch_size,\n            shuffle=True,\n        )\n    )\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.load_cached_activation_dataset","title":"<code>load_cached_activation_dataset()</code>","text":"<p>Load the cached activation dataset from disk.</p> <ul> <li>If cached_activations_path is set, returns Huggingface Dataset else None</li> <li>Checks that the loaded dataset has current has activations for hooks in config and that shapes match.</li> </ul> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>def load_cached_activation_dataset(self) -&gt; Dataset | None:\n    \"\"\"\n    Load the cached activation dataset from disk.\n\n    - If cached_activations_path is set, returns Huggingface Dataset else None\n    - Checks that the loaded dataset has current has activations for hooks in config and that shapes match.\n    \"\"\"\n    if self.cached_activations_path is None:\n        return None\n\n    assert self.cached_activations_path is not None  # keep pyright happy\n    # Sanity check: does the cache directory exist?\n    if not os.path.exists(self.cached_activations_path):\n        raise FileNotFoundError(\n            f\"Cache directory {self.cached_activations_path} does not exist. \"\n            \"Consider double-checking your dataset, model, and hook names.\"\n        )\n\n    # ---\n    # Actual code\n    activations_dataset = datasets.load_from_disk(self.cached_activations_path)\n    columns = [self.hook_name]\n    if \"token_ids\" in activations_dataset.column_names:\n        columns.append(\"token_ids\")\n    activations_dataset.set_format(\n        type=\"torch\", columns=columns, device=self.device, dtype=self.dtype\n    )\n    self.current_row_idx = 0  # idx to load next batch from\n    # ---\n\n    assert isinstance(activations_dataset, Dataset)\n\n    # multiple in hooks future\n    if not set([self.hook_name]).issubset(activations_dataset.column_names):\n        raise ValueError(\n            f\"loaded dataset does not include hook activations, got {activations_dataset.column_names}\"\n        )\n\n    if activations_dataset.features[self.hook_name].shape != (\n        self.context_size,\n        self.d_in,\n    ):\n        raise ValueError(\n            f\"Given dataset of shape {activations_dataset.features[self.hook_name].shape} does not match context_size ({self.context_size}) and d_in ({self.d_in})\"\n        )\n\n    return activations_dataset\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.next_batch","title":"<code>next_batch()</code>","text":"<p>Get the next batch from the current DataLoader. If the DataLoader is exhausted, refill the buffer and create a new DataLoader.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>def next_batch(self) -&gt; torch.Tensor:\n    \"\"\"\n    Get the next batch from the current DataLoader.\n    If the DataLoader is exhausted, refill the buffer and create a new DataLoader.\n    \"\"\"\n    try:\n        # Try to get the next batch\n        return next(self.dataloader)\n    except StopIteration:\n        # If the DataLoader is exhausted, create a new one\n        self._dataloader = self.get_data_loader()\n        return next(self.dataloader)\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.reset_input_dataset","title":"<code>reset_input_dataset()</code>","text":"<p>Resets the input dataset iterator to the beginning.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>def reset_input_dataset(self):\n    \"\"\"\n    Resets the input dataset iterator to the beginning.\n    \"\"\"\n    self.iterable_dataset = iter(self.dataset)\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.save","title":"<code>save(file_path)</code>","text":"<p>save the state dict to a file in safetensors format</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>def save(self, file_path: str):\n    \"\"\"save the state dict to a file in safetensors format\"\"\"\n    save_file(self.state_dict(), file_path)\n</code></pre>"},{"location":"api/#sae_lens.ActivationsStore.shuffle_input_dataset","title":"<code>shuffle_input_dataset(seed, buffer_size=1)</code>","text":"<p>This applies a shuffle to the huggingface dataset that is the input to the activations store. This also shuffles the shards of the dataset, which is especially useful for evaluating on different sections of very large streaming datasets. Buffer size is only relevant for streaming datasets. The default buffer_size of 1 means that only the shard will be shuffled; larger buffer sizes will additionally shuffle individual elements within the shard.</p> Source code in <code>sae_lens/training/activations_store.py</code> <pre><code>def shuffle_input_dataset(self, seed: int, buffer_size: int = 1):\n    \"\"\"\n    This applies a shuffle to the huggingface dataset that is the input to the activations store. This\n    also shuffles the shards of the dataset, which is especially useful for evaluating on different\n    sections of very large streaming datasets. Buffer size is only relevant for streaming datasets.\n    The default buffer_size of 1 means that only the shard will be shuffled; larger buffer sizes will\n    additionally shuffle individual elements within the shard.\n    \"\"\"\n    if isinstance(self.dataset, IterableDataset):\n        self.dataset = self.dataset.shuffle(seed=seed, buffer_size=buffer_size)\n    else:\n        self.dataset = self.dataset.shuffle(seed=seed)\n    self.iterable_dataset = iter(self.dataset)\n</code></pre>"},{"location":"api/#sae_lens.CacheActivationsRunner","title":"<code>CacheActivationsRunner</code>","text":"Source code in <code>sae_lens/cache_activations_runner.py</code> <pre><code>class CacheActivationsRunner:\n    def __init__(\n        self,\n        cfg: CacheActivationsRunnerConfig,\n        override_dataset: Dataset | None = None,\n    ):\n        self.cfg = cfg\n        self.model: HookedRootModule = load_model(\n            model_class_name=self.cfg.model_class_name,\n            model_name=self.cfg.model_name,\n            device=self.cfg.device,\n            model_from_pretrained_kwargs=self.cfg.model_from_pretrained_kwargs,\n        )\n        if self.cfg.compile_llm:\n            self.model = torch.compile(self.model, mode=self.cfg.llm_compilation_mode)  # type: ignore\n        self.activations_store = _mk_activations_store(\n            self.model,\n            self.cfg,\n            override_dataset=override_dataset,\n        )\n        self.context_size = self._get_sliced_context_size(\n            self.cfg.context_size, self.cfg.seqpos_slice\n        )\n        features_dict: dict[str, Array2D | Sequence] = {\n            hook_name: Array2D(\n                shape=(self.context_size, self.cfg.d_in), dtype=self.cfg.dtype\n            )\n            for hook_name in [self.cfg.hook_name]\n        }\n        features_dict[\"token_ids\"] = Sequence(\n            Value(dtype=\"int32\"), length=self.context_size\n        )\n        self.features = Features(features_dict)\n\n    def __str__(self):\n        \"\"\"\n        Print the number of tokens to be cached.\n        Print the number of buffers, and the number of tokens per buffer.\n        Print the disk space required to store the activations.\n\n        \"\"\"\n\n        bytes_per_token = (\n            self.cfg.d_in * self.cfg.dtype.itemsize\n            if isinstance(self.cfg.dtype, torch.dtype)\n            else DTYPE_MAP[self.cfg.dtype].itemsize\n        )\n        total_training_tokens = self.cfg.n_seq_in_dataset * self.context_size\n        total_disk_space_gb = total_training_tokens * bytes_per_token / 10**9\n\n        return (\n            f\"Activation Cache Runner:\\n\"\n            f\"Total training tokens: {total_training_tokens}\\n\"\n            f\"Number of buffers: {self.cfg.n_buffers}\\n\"\n            f\"Tokens per buffer: {self.cfg.n_tokens_in_buffer}\\n\"\n            f\"Disk space required: {total_disk_space_gb:.2f} GB\\n\"\n            f\"Configuration:\\n\"\n            f\"{self.cfg}\"\n        )\n\n    @staticmethod\n    def _consolidate_shards(\n        source_dir: Path, output_dir: Path, copy_files: bool = True\n    ) -&gt; Dataset:\n        \"\"\"Consolidate sharded datasets into a single directory without rewriting data.\n\n        Each of the shards must be of the same format, aka the full dataset must be able to\n        be recreated like so:\n\n        ```\n        ds = concatenate_datasets(\n            [Dataset.load_from_disk(str(shard_dir)) for shard_dir in sorted(source_dir.iterdir())]\n        )\n\n        ```\n\n        Sharded dataset format:\n        ```\n        source_dir/\n            shard_00000/\n                dataset_info.json\n                state.json\n                data-00000-of-00002.arrow\n                data-00001-of-00002.arrow\n            shard_00001/\n                dataset_info.json\n                state.json\n                data-00000-of-00001.arrow\n        ```\n\n        And flattens them into the format:\n\n        ```\n        output_dir/\n            dataset_info.json\n            state.json\n            data-00000-of-00003.arrow\n            data-00001-of-00003.arrow\n            data-00002-of-00003.arrow\n        ```\n\n        allowing the dataset to be loaded like so:\n\n        ```\n        ds = datasets.load_from_disk(output_dir)\n        ```\n\n        Args:\n            source_dir: Directory containing the sharded datasets\n            output_dir: Directory to consolidate the shards into\n            copy_files: If True, copy files; if False, move them and delete source_dir\n        \"\"\"\n        first_shard_dir_name = \"shard_00000\"  # shard_{i:05d}\n\n        if not source_dir.exists() or not source_dir.is_dir():\n            raise NotADirectoryError(\n                f\"source_dir is not an existing directory: {source_dir}\"\n            )\n\n        if not output_dir.exists() or not output_dir.is_dir():\n            raise NotADirectoryError(\n                f\"output_dir is not an existing directory: {output_dir}\"\n            )\n\n        other_items = [p for p in output_dir.iterdir() if p.name != \".tmp_shards\"]\n        if other_items:\n            raise FileExistsError(\n                f\"output_dir must be empty (besides .tmp_shards). Found: {other_items}\"\n            )\n\n        if not (source_dir / first_shard_dir_name).exists():\n            raise Exception(f\"No shards in {source_dir} exist!\")\n\n        transfer_fn = shutil.copy2 if copy_files else shutil.move\n\n        # Move dataset_info.json from any shard (all the same)\n        transfer_fn(\n            source_dir / first_shard_dir_name / \"dataset_info.json\",\n            output_dir / \"dataset_info.json\",\n        )\n\n        arrow_files = []\n        file_count = 0\n\n        for shard_dir in sorted(source_dir.iterdir()):\n            if not shard_dir.name.startswith(\"shard_\"):\n                continue\n\n            # state.json contains arrow filenames\n            state = json.loads((shard_dir / \"state.json\").read_text())\n\n            for data_file in state[\"_data_files\"]:\n                src = shard_dir / data_file[\"filename\"]\n                new_name = f\"data-{file_count:05d}-of-{len(list(source_dir.iterdir())):05d}.arrow\"\n                dst = output_dir / new_name\n                transfer_fn(src, dst)\n                arrow_files.append({\"filename\": new_name})\n                file_count += 1\n\n        new_state = {\n            \"_data_files\": arrow_files,\n            \"_fingerprint\": None,  # temporary\n            \"_format_columns\": None,\n            \"_format_kwargs\": {},\n            \"_format_type\": None,\n            \"_output_all_columns\": False,\n            \"_split\": None,\n        }\n\n        # fingerprint is generated from dataset.__getstate__ (not includeing _fingerprint)\n        with open(output_dir / \"state.json\", \"w\") as f:\n            json.dump(new_state, f, indent=2)\n\n        ds = Dataset.load_from_disk(str(output_dir))\n        fingerprint = generate_fingerprint(ds)\n        del ds\n\n        with open(output_dir / \"state.json\", \"r+\") as f:\n            state = json.loads(f.read())\n            state[\"_fingerprint\"] = fingerprint\n            f.seek(0)\n            json.dump(state, f, indent=2)\n            f.truncate()\n\n        if not copy_files:  # cleanup source dir\n            shutil.rmtree(source_dir)\n\n        return Dataset.load_from_disk(output_dir)\n\n    @torch.no_grad()\n    def run(self) -&gt; Dataset:\n        activation_save_path = self.cfg.new_cached_activations_path\n        assert activation_save_path is not None\n\n        ### Paths setup\n        final_cached_activation_path = Path(activation_save_path)\n        final_cached_activation_path.mkdir(exist_ok=True, parents=True)\n        if any(final_cached_activation_path.iterdir()):\n            raise Exception(\n                f\"Activations directory ({final_cached_activation_path}) is not empty. Please delete it or specify a different path. Exiting the script to prevent accidental deletion of files.\"\n            )\n\n        tmp_cached_activation_path = final_cached_activation_path / \".tmp_shards/\"\n        tmp_cached_activation_path.mkdir(exist_ok=False, parents=False)\n\n        ### Create temporary sharded datasets\n\n        logger.info(f\"Started caching activations for {self.cfg.dataset_path}\")\n\n        for i in tqdm(range(self.cfg.n_buffers), desc=\"Caching activations\"):\n            try:\n                buffer = self.activations_store.get_buffer(\n                    self.cfg.n_batches_in_buffer, shuffle=False\n                )\n                shard = self._create_shard(buffer)\n                shard.save_to_disk(\n                    f\"{tmp_cached_activation_path}/shard_{i:05d}\", num_shards=1\n                )\n                del buffer, shard\n            except StopIteration:\n                logger.warning(\n                    f\"Warning: Ran out of samples while filling the buffer at batch {i} before reaching {self.cfg.n_buffers} batches.\"\n                )\n                break\n\n        ### Concatenate shards and push to Huggingface Hub\n\n        dataset = self._consolidate_shards(\n            tmp_cached_activation_path, final_cached_activation_path, copy_files=False\n        )\n\n        if self.cfg.shuffle:\n            logger.info(\"Shuffling...\")\n            dataset = dataset.shuffle(seed=self.cfg.seed)\n\n        if self.cfg.hf_repo_id:\n            logger.info(\"Pushing to Huggingface Hub...\")\n            dataset.push_to_hub(\n                repo_id=self.cfg.hf_repo_id,\n                num_shards=self.cfg.hf_num_shards,\n                private=self.cfg.hf_is_private_repo,\n                revision=self.cfg.hf_revision,\n            )\n\n            meta_io = io.BytesIO()\n            meta_contents = json.dumps(\n                asdict(self.cfg), indent=2, ensure_ascii=False\n            ).encode(\"utf-8\")\n            meta_io.write(meta_contents)\n            meta_io.seek(0)\n\n            api = HfApi()\n            api.upload_file(\n                path_or_fileobj=meta_io,\n                path_in_repo=\"cache_activations_runner_cfg.json\",\n                repo_id=self.cfg.hf_repo_id,\n                repo_type=\"dataset\",\n                commit_message=\"Add cache_activations_runner metadata\",\n            )\n\n        return dataset\n\n    def _create_shard(\n        self,\n        buffer: tuple[\n            Float[torch.Tensor, \"(bs context_size) num_layers d_in\"],\n            Int[torch.Tensor, \"(bs context_size)\"] | None,\n        ],\n    ) -&gt; Dataset:\n        hook_names = [self.cfg.hook_name]\n        acts, token_ids = buffer\n        acts = einops.rearrange(\n            acts,\n            \"(bs context_size) num_layers d_in -&gt; num_layers bs context_size d_in\",\n            bs=self.cfg.n_seq_in_buffer,\n            context_size=self.context_size,\n            d_in=self.cfg.d_in,\n            num_layers=len(hook_names),\n        )\n        shard_dict = {hook_name: act for hook_name, act in zip(hook_names, acts)}\n\n        if token_ids is not None:\n            token_ids = einops.rearrange(\n                token_ids,\n                \"(bs context_size) -&gt; bs context_size\",\n                bs=self.cfg.n_seq_in_buffer,\n                context_size=self.context_size,\n            )\n            shard_dict[\"token_ids\"] = token_ids.to(torch.int32)\n        return Dataset.from_dict(\n            shard_dict,\n            features=self.features,\n        )\n\n    @staticmethod\n    def _get_sliced_context_size(\n        context_size: int, seqpos_slice: tuple[int | None, ...] | None\n    ) -&gt; int:\n        if seqpos_slice is not None:\n            context_size = len(range(context_size)[slice(*seqpos_slice)])\n        return context_size\n</code></pre>"},{"location":"api/#sae_lens.CacheActivationsRunner.__str__","title":"<code>__str__()</code>","text":"<p>Print the number of tokens to be cached. Print the number of buffers, and the number of tokens per buffer. Print the disk space required to store the activations.</p> Source code in <code>sae_lens/cache_activations_runner.py</code> <pre><code>def __str__(self):\n    \"\"\"\n    Print the number of tokens to be cached.\n    Print the number of buffers, and the number of tokens per buffer.\n    Print the disk space required to store the activations.\n\n    \"\"\"\n\n    bytes_per_token = (\n        self.cfg.d_in * self.cfg.dtype.itemsize\n        if isinstance(self.cfg.dtype, torch.dtype)\n        else DTYPE_MAP[self.cfg.dtype].itemsize\n    )\n    total_training_tokens = self.cfg.n_seq_in_dataset * self.context_size\n    total_disk_space_gb = total_training_tokens * bytes_per_token / 10**9\n\n    return (\n        f\"Activation Cache Runner:\\n\"\n        f\"Total training tokens: {total_training_tokens}\\n\"\n        f\"Number of buffers: {self.cfg.n_buffers}\\n\"\n        f\"Tokens per buffer: {self.cfg.n_tokens_in_buffer}\\n\"\n        f\"Disk space required: {total_disk_space_gb:.2f} GB\\n\"\n        f\"Configuration:\\n\"\n        f\"{self.cfg}\"\n    )\n</code></pre>"},{"location":"api/#sae_lens.CacheActivationsRunnerConfig","title":"<code>CacheActivationsRunnerConfig</code>  <code>dataclass</code>","text":"<p>Configuration for creating and caching activations of an LLM.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>The path to the Hugging Face dataset. This may be tokenized or not.</p> required <code>model_name</code> <code>str</code> <p>The name of the model to use.</p> required <code>model_batch_size</code> <code>int</code> <p>How many prompts are in the batch of the language model when generating activations.</p> required <code>hook_name</code> <code>str</code> <p>The name of the hook to use.</p> required <code>hook_layer</code> <code>int</code> <p>The layer of the final hook. Currently only support a single hook, so this should be the same as hook_name.</p> required <code>d_in</code> <code>int</code> <p>Dimension of the model.</p> required <code>total_training_tokens</code> <code>int</code> <p>Total number of tokens to process.</p> required <code>context_size</code> <code>int</code> <p>Context size to process. Can be left as -1 if the dataset is tokenized.</p> <code>-1</code> <code>model_class_name</code> <code>str</code> <p>The name of the class of the model to use. This should be either <code>HookedTransformer</code> or <code>HookedMamba</code>.</p> <code>'HookedTransformer'</code> <code>new_cached_activations_path</code> <code>str</code> <p>The path to save the activations.</p> <code>None</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the dataset.</p> <code>True</code> <code>seed</code> <code>int</code> <p>The seed to use for shuffling.</p> <code>42</code> <code>dtype</code> <code>str</code> <p>Datatype of activations to be stored.</p> <code>'float32'</code> <code>device</code> <code>str</code> <p>The device for the model.</p> <code>'cuda' if is_available() else 'cpu'</code> <code>buffer_size_gb</code> <code>float</code> <p>The buffer size in GB. This should be &lt; 2GB.</p> <code>2.0</code> <code>hf_repo_id</code> <code>str</code> <p>The Hugging Face repository id to save the activations to.</p> <code>None</code> <code>hf_num_shards</code> <code>int</code> <p>The number of shards to save the activations to.</p> <code>None</code> <code>hf_revision</code> <code>str</code> <p>The revision to save the activations to.</p> <code>'main'</code> <code>hf_is_private_repo</code> <code>bool</code> <p>Whether the Hugging Face repository is private.</p> <code>False</code> <code>model_kwargs</code> <code>dict</code> <p>Keyword arguments for <code>model.run_with_cache</code>.</p> <code>dict()</code> <code>model_from_pretrained_kwargs</code> <code>dict</code> <p>Keyword arguments for the <code>from_pretrained</code> method of the model.</p> <code>dict()</code> <code>compile_llm</code> <code>bool</code> <p>Whether to compile the LLM.</p> <code>False</code> <code>llm_compilation_mode</code> <code>str</code> <p>The torch.compile mode to use.</p> <code>None</code> <code>prepend_bos</code> <code>bool</code> <p>Whether to prepend the beginning of sequence token. You should use whatever the model was trained with.</p> <code>True</code> <code>seqpos_slice</code> <code>tuple</code> <p>Determines slicing of activations when constructing batches during training. The slice should be (start_pos, end_pos, optional[step_size]), e.g. for Othello we sometimes use (5, -5). Note, step_size &gt; 0.</p> <code>(None,)</code> <code>streaming</code> <code>bool</code> <p>Whether to stream the dataset. Streaming large datasets is usually practical.</p> <code>True</code> <code>autocast_lm</code> <code>bool</code> <p>Whether to use autocast during activation fetching.</p> <code>False</code> <code>dataset_trust_remote_code</code> <code>bool</code> <p>Whether to trust remote code when loading datasets from Huggingface.</p> <code>None</code> Source code in <code>sae_lens/config.py</code> <pre><code>@dataclass\nclass CacheActivationsRunnerConfig:\n    \"\"\"\n    Configuration for creating and caching activations of an LLM.\n\n    Args:\n        dataset_path (str): The path to the Hugging Face dataset. This may be tokenized or not.\n        model_name (str): The name of the model to use.\n        model_batch_size (int): How many prompts are in the batch of the language model when generating activations.\n        hook_name (str): The name of the hook to use.\n        hook_layer (int): The layer of the final hook. Currently only support a single hook, so this should be the same as hook_name.\n        d_in (int): Dimension of the model.\n        total_training_tokens (int): Total number of tokens to process.\n        context_size (int): Context size to process. Can be left as -1 if the dataset is tokenized.\n        model_class_name (str): The name of the class of the model to use. This should be either `HookedTransformer` or `HookedMamba`.\n        new_cached_activations_path (str, optional): The path to save the activations.\n        shuffle (bool): Whether to shuffle the dataset.\n        seed (int): The seed to use for shuffling.\n        dtype (str): Datatype of activations to be stored.\n        device (str): The device for the model.\n        buffer_size_gb (float): The buffer size in GB. This should be &lt; 2GB.\n        hf_repo_id (str, optional): The Hugging Face repository id to save the activations to.\n        hf_num_shards (int, optional): The number of shards to save the activations to.\n        hf_revision (str): The revision to save the activations to.\n        hf_is_private_repo (bool): Whether the Hugging Face repository is private.\n        model_kwargs (dict): Keyword arguments for `model.run_with_cache`.\n        model_from_pretrained_kwargs (dict): Keyword arguments for the `from_pretrained` method of the model.\n        compile_llm (bool): Whether to compile the LLM.\n        llm_compilation_mode (str): The torch.compile mode to use.\n        prepend_bos (bool): Whether to prepend the beginning of sequence token. You should use whatever the model was trained with.\n        seqpos_slice (tuple): Determines slicing of activations when constructing batches during training. The slice should be (start_pos, end_pos, optional[step_size]), e.g. for Othello we sometimes use (5, -5). Note, step_size &gt; 0.\n        streaming (bool): Whether to stream the dataset. Streaming large datasets is usually practical.\n        autocast_lm (bool): Whether to use autocast during activation fetching.\n        dataset_trust_remote_code (bool): Whether to trust remote code when loading datasets from Huggingface.\n    \"\"\"\n\n    dataset_path: str\n    model_name: str\n    model_batch_size: int\n    hook_name: str\n    hook_layer: int\n    d_in: int\n    training_tokens: int\n\n    context_size: int = -1  # Required if dataset is not tokenized\n    model_class_name: str = \"HookedTransformer\"\n    # defaults to \"activations/{dataset}/{model}/{hook_name}\n    new_cached_activations_path: str | None = None\n    shuffle: bool = True\n    seed: int = 42\n    dtype: str = \"float32\"\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    buffer_size_gb: float = 2.0  # HF datasets writer have problems with shards &gt; 2GB\n\n    # Huggingface Integration\n    hf_repo_id: str | None = None\n    hf_num_shards: int | None = None\n    hf_revision: str = \"main\"\n    hf_is_private_repo: bool = False\n\n    # Model\n    model_kwargs: dict[str, Any] = field(default_factory=dict)\n    model_from_pretrained_kwargs: dict[str, Any] = field(default_factory=dict)\n    compile_llm: bool = False\n    llm_compilation_mode: str | None = None  # which torch.compile mode to use\n\n    # Activation Store\n    prepend_bos: bool = True\n    seqpos_slice: tuple[int | None, ...] = (None,)\n    streaming: bool = True\n    autocast_lm: bool = False\n    dataset_trust_remote_code: bool | None = None\n\n    def __post_init__(self):\n        # Automatically determine context_size if dataset is tokenized\n        if self.context_size == -1:\n            ds = load_dataset(self.dataset_path, split=\"train\", streaming=True)\n            assert isinstance(ds, IterableDataset)\n            first_sample = next(iter(ds))\n            toks = first_sample.get(\"tokens\") or first_sample.get(\"input_ids\") or None\n            if toks is None:\n                raise ValueError(\n                    \"Dataset is not tokenized. Please specify context_size.\"\n                )\n            token_length = len(toks)\n            self.context_size = token_length\n\n        if self.context_size == -1:\n            raise ValueError(\"context_size is still -1 after dataset inspection.\")\n\n        if self.seqpos_slice is not None:\n            _validate_seqpos(\n                seqpos=self.seqpos_slice,\n                context_size=self.context_size,\n            )\n\n        if self.new_cached_activations_path is None:\n            self.new_cached_activations_path = _default_cached_activations_path(  # type: ignore\n                self.dataset_path, self.model_name, self.hook_name, None\n            )\n\n    @property\n    def sliced_context_size(self) -&gt; int:\n        if self.seqpos_slice is not None:\n            return len(range(self.context_size)[slice(*self.seqpos_slice)])\n        return self.context_size\n\n    @property\n    def bytes_per_token(self) -&gt; int:\n        return self.d_in * DTYPE_MAP[self.dtype].itemsize\n\n    @property\n    def n_tokens_in_buffer(self) -&gt; int:\n        # Calculate raw tokens per buffer based on memory constraints\n        _tokens_per_buffer = int(self.buffer_size_gb * 1e9) // self.bytes_per_token\n        # Round down to nearest multiple of batch_token_size\n        return _tokens_per_buffer - (_tokens_per_buffer % self.n_tokens_in_batch)\n\n    @property\n    def n_tokens_in_batch(self) -&gt; int:\n        return self.model_batch_size * self.sliced_context_size\n\n    @property\n    def n_batches_in_buffer(self) -&gt; int:\n        return self.n_tokens_in_buffer // self.n_tokens_in_batch\n\n    @property\n    def n_seq_in_dataset(self) -&gt; int:\n        return self.training_tokens // self.sliced_context_size\n\n    @property\n    def n_seq_in_buffer(self) -&gt; int:\n        return self.n_tokens_in_buffer // self.sliced_context_size\n\n    @property\n    def n_buffers(self) -&gt; int:\n        return math.ceil(self.training_tokens / self.n_tokens_in_buffer)\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer","title":"<code>HookedSAETransformer</code>","text":"<p>               Bases: <code>HookedTransformer</code></p> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>class HookedSAETransformer(HookedTransformer):\n    def __init__(\n        self,\n        *model_args: Any,\n        **model_kwargs: Any,\n    ):\n        \"\"\"Model initialization. Just HookedTransformer init, but adds a dictionary to keep track of attached SAEs.\n\n        Note that if you want to load the model from pretrained weights, you should use\n        :meth:`from_pretrained` instead.\n\n        Args:\n            *model_args: Positional arguments for HookedTransformer initialization\n            **model_kwargs: Keyword arguments for HookedTransformer initialization\n        \"\"\"\n        super().__init__(*model_args, **model_kwargs)\n        self.acts_to_saes: dict[str, SAE] = {}  # type: ignore\n\n    def add_sae(self, sae: SAE, use_error_term: bool | None = None):\n        \"\"\"Attaches an SAE to the model\n\n        WARNING: This sae will be permanantly attached until you remove it with reset_saes. This function will also overwrite any existing SAE attached to the same hook point.\n\n        Args:\n            sae: SparseAutoencoderBase. The SAE to attach to the model\n            use_error_term: (bool | None) If provided, will set the use_error_term attribute of the SAE to this value. Determines whether the SAE returns input or reconstruction. Defaults to None.\n        \"\"\"\n        act_name = sae.cfg.hook_name\n        if (act_name not in self.acts_to_saes) and (act_name not in self.hook_dict):\n            logging.warning(\n                f\"No hook found for {act_name}. Skipping. Check model.hook_dict for available hooks.\"\n            )\n            return\n\n        if use_error_term is not None:\n            if not hasattr(sae, \"_original_use_error_term\"):\n                sae._original_use_error_term = sae.use_error_term  # type: ignore\n            sae.use_error_term = use_error_term\n        self.acts_to_saes[act_name] = sae\n        set_deep_attr(self, act_name, sae)\n        self.setup()\n\n    def _reset_sae(self, act_name: str, prev_sae: SAE | None = None):\n        \"\"\"Resets an SAE that was attached to the model\n\n        By default will remove the SAE from that hook_point.\n        If prev_sae is provided, will replace the current SAE with the provided one.\n        This is mainly used to restore previously attached SAEs after temporarily running with different SAEs (eg with run_with_saes)\n\n        Args:\n            act_name: str. The hook_name of the SAE to reset\n            prev_sae: SAE | None. The SAE to replace the current one with. If None, will just remove the SAE from this hook point. Defaults to None\n        \"\"\"\n        if act_name not in self.acts_to_saes:\n            logging.warning(\n                f\"No SAE is attached to {act_name}. There's nothing to reset.\"\n            )\n            return\n\n        current_sae = self.acts_to_saes[act_name]\n        if hasattr(current_sae, \"_original_use_error_term\"):\n            current_sae.use_error_term = current_sae._original_use_error_term  # type: ignore\n            delattr(current_sae, \"_original_use_error_term\")\n\n        if prev_sae:\n            set_deep_attr(self, act_name, prev_sae)\n            self.acts_to_saes[act_name] = prev_sae\n        else:\n            set_deep_attr(self, act_name, HookPoint())\n            del self.acts_to_saes[act_name]\n\n    def reset_saes(\n        self,\n        act_names: str | list[str] | None = None,\n        prev_saes: list[SAE | None] | None = None,\n    ):\n        \"\"\"Reset the SAEs attached to the model\n\n        If act_names are provided will just reset SAEs attached to those hooks. Otherwise will reset all SAEs attached to the model.\n        Optionally can provide a list of prev_saes to reset to. This is mainly used to restore previously attached SAEs after temporarily running with different SAEs (eg with run_with_saes).\n\n        Args:\n            act_names (str | list[str] | None): The act_names of the SAEs to reset. If None, will reset all SAEs attached to the model. Defaults to None.\n            prev_saes (list[SAE | None] | None): List of SAEs to replace the current ones with. If None, will just remove the SAEs. Defaults to None.\n        \"\"\"\n        if isinstance(act_names, str):\n            act_names = [act_names]\n        elif act_names is None:\n            act_names = list(self.acts_to_saes.keys())\n\n        if prev_saes:\n            if len(act_names) != len(prev_saes):\n                raise ValueError(\"act_names and prev_saes must have the same length\")\n        else:\n            prev_saes = [None] * len(act_names)  # type: ignore\n\n        for act_name, prev_sae in zip(act_names, prev_saes):  # type: ignore\n            self._reset_sae(act_name, prev_sae)\n\n        self.setup()\n\n    def run_with_saes(\n        self,\n        *model_args: Any,\n        saes: SAE | list[SAE] = [],\n        reset_saes_end: bool = True,\n        use_error_term: bool | None = None,\n        **model_kwargs: Any,\n    ) -&gt; (\n        None\n        | Float[torch.Tensor, \"batch pos d_vocab\"]\n        | Loss\n        | tuple[Float[torch.Tensor, \"batch pos d_vocab\"], Loss]\n    ):\n        \"\"\"Wrapper around HookedTransformer forward pass.\n\n        Runs the model with the given SAEs attached for one forward pass, then removes them. By default, will reset all SAEs to original state after.\n\n        Args:\n            *model_args: Positional arguments for the model forward pass\n            saes: (SAE | list[SAE]) The SAEs to be attached for this forward pass\n            reset_saes_end (bool): If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. Default is True.\n            use_error_term: (bool | None) If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Defaults to None.\n            **model_kwargs: Keyword arguments for the model forward pass\n        \"\"\"\n        with self.saes(\n            saes=saes, reset_saes_end=reset_saes_end, use_error_term=use_error_term\n        ):\n            return self(*model_args, **model_kwargs)\n\n    def run_with_cache_with_saes(\n        self,\n        *model_args: Any,\n        saes: SAE | list[SAE] = [],\n        reset_saes_end: bool = True,\n        use_error_term: bool | None = None,\n        return_cache_object: bool = True,\n        remove_batch_dim: bool = False,\n        **kwargs: Any,\n    ) -&gt; tuple[\n        None\n        | Float[torch.Tensor, \"batch pos d_vocab\"]\n        | Loss\n        | tuple[Float[torch.Tensor, \"batch pos d_vocab\"], Loss],\n        ActivationCache | dict[str, torch.Tensor],\n    ]:\n        \"\"\"Wrapper around 'run_with_cache' in HookedTransformer.\n\n        Attaches given SAEs before running the model with cache and then removes them.\n        By default, will reset all SAEs to original state after.\n\n        Args:\n            *model_args: Positional arguments for the model forward pass\n            saes: (SAE | list[SAE]) The SAEs to be attached for this forward pass\n            reset_saes_end: (bool) If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. Default is True.\n            use_error_term: (bool | None) If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Determines whether the SAE returns input or reconstruction. Defaults to None.\n            return_cache_object: (bool) if True, this will return an ActivationCache object, with a bunch of\n                useful HookedTransformer specific methods, otherwise it will return a dictionary of\n                activations as in HookedRootModule.\n            remove_batch_dim: (bool) Whether to remove the batch dimension (only works for batch_size==1). Defaults to False.\n            **kwargs: Keyword arguments for the model forward pass\n        \"\"\"\n        with self.saes(\n            saes=saes, reset_saes_end=reset_saes_end, use_error_term=use_error_term\n        ):\n            return self.run_with_cache(  # type: ignore\n                *model_args,\n                return_cache_object=return_cache_object,  # type: ignore\n                remove_batch_dim=remove_batch_dim,\n                **kwargs,\n            )\n\n    def run_with_hooks_with_saes(\n        self,\n        *model_args: Any,\n        saes: SAE | list[SAE] = [],\n        reset_saes_end: bool = True,\n        fwd_hooks: list[tuple[str | Callable, Callable]] = [],  # type: ignore\n        bwd_hooks: list[tuple[str | Callable, Callable]] = [],  # type: ignore\n        reset_hooks_end: bool = True,\n        clear_contexts: bool = False,\n        **model_kwargs: Any,\n    ):\n        \"\"\"Wrapper around 'run_with_hooks' in HookedTransformer.\n\n        Attaches the given SAEs to the model before running the model with hooks and then removes them.\n        By default, will reset all SAEs to original state after.\n\n        Args:\n            *model_args: Positional arguments for the model forward pass\n            saes: (SAE | list[SAE]) The SAEs to be attached for this forward pass\n            reset_saes_end: (bool) If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. (default: True)\n            fwd_hooks: (list[tuple[str | Callable, Callable]]) List of forward hooks to apply\n            bwd_hooks: (list[tuple[str | Callable, Callable]]) List of backward hooks to apply\n            reset_hooks_end: (bool) Whether to reset the hooks at the end of the forward pass (default: True)\n            clear_contexts: (bool) Whether to clear the contexts at the end of the forward pass (default: False)\n            **model_kwargs: Keyword arguments for the model forward pass\n        \"\"\"\n        with self.saes(saes=saes, reset_saes_end=reset_saes_end):\n            return self.run_with_hooks(\n                *model_args,\n                fwd_hooks=fwd_hooks,\n                bwd_hooks=bwd_hooks,\n                reset_hooks_end=reset_hooks_end,\n                clear_contexts=clear_contexts,\n                **model_kwargs,\n            )\n\n    @contextmanager\n    def saes(\n        self,\n        saes: SAE | list[SAE] = [],\n        reset_saes_end: bool = True,\n        use_error_term: bool | None = None,\n    ):\n        \"\"\"\n        A context manager for adding temporary SAEs to the model.\n        See HookedTransformer.hooks for a similar context manager for hooks.\n        By default will keep track of previously attached SAEs, and restore them when the context manager exits.\n\n        Example:\n\n        .. code-block:: python\n\n            from transformer_lens import HookedSAETransformer\n            from sae_lens.sae import SAE\n\n            model = HookedSAETransformer.from_pretrained('gpt2-small')\n            sae_cfg = SAEConfig(...)\n            sae = SAE(sae_cfg)\n            with model.saes(saes=[sae]):\n                spliced_logits = model(text)\n\n\n        Args:\n            saes (SAE | list[SAE]): SAEs to be attached.\n            reset_saes_end (bool): If True, removes all SAEs added by this context manager when the context manager exits, returning previously attached SAEs to their original state.\n            use_error_term (bool | None): If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Defaults to None.\n        \"\"\"\n        act_names_to_reset = []\n        prev_saes = []\n        if isinstance(saes, SAE):\n            saes = [saes]\n        try:\n            for sae in saes:\n                act_names_to_reset.append(sae.cfg.hook_name)\n                prev_sae = self.acts_to_saes.get(sae.cfg.hook_name, None)\n                prev_saes.append(prev_sae)\n                self.add_sae(sae, use_error_term=use_error_term)\n            yield self\n        finally:\n            if reset_saes_end:\n                self.reset_saes(act_names_to_reset, prev_saes)\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer.__init__","title":"<code>__init__(*model_args, **model_kwargs)</code>","text":"<p>Model initialization. Just HookedTransformer init, but adds a dictionary to keep track of attached SAEs.</p> <p>Note that if you want to load the model from pretrained weights, you should use :meth:<code>from_pretrained</code> instead.</p> <p>Parameters:</p> Name Type Description Default <code>*model_args</code> <code>Any</code> <p>Positional arguments for HookedTransformer initialization</p> <code>()</code> <code>**model_kwargs</code> <code>Any</code> <p>Keyword arguments for HookedTransformer initialization</p> <code>{}</code> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>def __init__(\n    self,\n    *model_args: Any,\n    **model_kwargs: Any,\n):\n    \"\"\"Model initialization. Just HookedTransformer init, but adds a dictionary to keep track of attached SAEs.\n\n    Note that if you want to load the model from pretrained weights, you should use\n    :meth:`from_pretrained` instead.\n\n    Args:\n        *model_args: Positional arguments for HookedTransformer initialization\n        **model_kwargs: Keyword arguments for HookedTransformer initialization\n    \"\"\"\n    super().__init__(*model_args, **model_kwargs)\n    self.acts_to_saes: dict[str, SAE] = {}  # type: ignore\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer.add_sae","title":"<code>add_sae(sae, use_error_term=None)</code>","text":"<p>Attaches an SAE to the model</p> <p>WARNING: This sae will be permanantly attached until you remove it with reset_saes. This function will also overwrite any existing SAE attached to the same hook point.</p> <p>Parameters:</p> Name Type Description Default <code>sae</code> <code>SAE</code> <p>SparseAutoencoderBase. The SAE to attach to the model</p> required <code>use_error_term</code> <code>bool | None</code> <p>(bool | None) If provided, will set the use_error_term attribute of the SAE to this value. Determines whether the SAE returns input or reconstruction. Defaults to None.</p> <code>None</code> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>def add_sae(self, sae: SAE, use_error_term: bool | None = None):\n    \"\"\"Attaches an SAE to the model\n\n    WARNING: This sae will be permanantly attached until you remove it with reset_saes. This function will also overwrite any existing SAE attached to the same hook point.\n\n    Args:\n        sae: SparseAutoencoderBase. The SAE to attach to the model\n        use_error_term: (bool | None) If provided, will set the use_error_term attribute of the SAE to this value. Determines whether the SAE returns input or reconstruction. Defaults to None.\n    \"\"\"\n    act_name = sae.cfg.hook_name\n    if (act_name not in self.acts_to_saes) and (act_name not in self.hook_dict):\n        logging.warning(\n            f\"No hook found for {act_name}. Skipping. Check model.hook_dict for available hooks.\"\n        )\n        return\n\n    if use_error_term is not None:\n        if not hasattr(sae, \"_original_use_error_term\"):\n            sae._original_use_error_term = sae.use_error_term  # type: ignore\n        sae.use_error_term = use_error_term\n    self.acts_to_saes[act_name] = sae\n    set_deep_attr(self, act_name, sae)\n    self.setup()\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer.reset_saes","title":"<code>reset_saes(act_names=None, prev_saes=None)</code>","text":"<p>Reset the SAEs attached to the model</p> <p>If act_names are provided will just reset SAEs attached to those hooks. Otherwise will reset all SAEs attached to the model. Optionally can provide a list of prev_saes to reset to. This is mainly used to restore previously attached SAEs after temporarily running with different SAEs (eg with run_with_saes).</p> <p>Parameters:</p> Name Type Description Default <code>act_names</code> <code>str | list[str] | None</code> <p>The act_names of the SAEs to reset. If None, will reset all SAEs attached to the model. Defaults to None.</p> <code>None</code> <code>prev_saes</code> <code>list[SAE | None] | None</code> <p>List of SAEs to replace the current ones with. If None, will just remove the SAEs. Defaults to None.</p> <code>None</code> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>def reset_saes(\n    self,\n    act_names: str | list[str] | None = None,\n    prev_saes: list[SAE | None] | None = None,\n):\n    \"\"\"Reset the SAEs attached to the model\n\n    If act_names are provided will just reset SAEs attached to those hooks. Otherwise will reset all SAEs attached to the model.\n    Optionally can provide a list of prev_saes to reset to. This is mainly used to restore previously attached SAEs after temporarily running with different SAEs (eg with run_with_saes).\n\n    Args:\n        act_names (str | list[str] | None): The act_names of the SAEs to reset. If None, will reset all SAEs attached to the model. Defaults to None.\n        prev_saes (list[SAE | None] | None): List of SAEs to replace the current ones with. If None, will just remove the SAEs. Defaults to None.\n    \"\"\"\n    if isinstance(act_names, str):\n        act_names = [act_names]\n    elif act_names is None:\n        act_names = list(self.acts_to_saes.keys())\n\n    if prev_saes:\n        if len(act_names) != len(prev_saes):\n            raise ValueError(\"act_names and prev_saes must have the same length\")\n    else:\n        prev_saes = [None] * len(act_names)  # type: ignore\n\n    for act_name, prev_sae in zip(act_names, prev_saes):  # type: ignore\n        self._reset_sae(act_name, prev_sae)\n\n    self.setup()\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer.run_with_cache_with_saes","title":"<code>run_with_cache_with_saes(*model_args, saes=[], reset_saes_end=True, use_error_term=None, return_cache_object=True, remove_batch_dim=False, **kwargs)</code>","text":"<p>Wrapper around 'run_with_cache' in HookedTransformer.</p> <p>Attaches given SAEs before running the model with cache and then removes them. By default, will reset all SAEs to original state after.</p> <p>Parameters:</p> Name Type Description Default <code>*model_args</code> <code>Any</code> <p>Positional arguments for the model forward pass</p> <code>()</code> <code>saes</code> <code>SAE | list[SAE]</code> <p>(SAE | list[SAE]) The SAEs to be attached for this forward pass</p> <code>[]</code> <code>reset_saes_end</code> <code>bool</code> <p>(bool) If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. Default is True.</p> <code>True</code> <code>use_error_term</code> <code>bool | None</code> <p>(bool | None) If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Determines whether the SAE returns input or reconstruction. Defaults to None.</p> <code>None</code> <code>return_cache_object</code> <code>bool</code> <p>(bool) if True, this will return an ActivationCache object, with a bunch of useful HookedTransformer specific methods, otherwise it will return a dictionary of activations as in HookedRootModule.</p> <code>True</code> <code>remove_batch_dim</code> <code>bool</code> <p>(bool) Whether to remove the batch dimension (only works for batch_size==1). Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments for the model forward pass</p> <code>{}</code> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>def run_with_cache_with_saes(\n    self,\n    *model_args: Any,\n    saes: SAE | list[SAE] = [],\n    reset_saes_end: bool = True,\n    use_error_term: bool | None = None,\n    return_cache_object: bool = True,\n    remove_batch_dim: bool = False,\n    **kwargs: Any,\n) -&gt; tuple[\n    None\n    | Float[torch.Tensor, \"batch pos d_vocab\"]\n    | Loss\n    | tuple[Float[torch.Tensor, \"batch pos d_vocab\"], Loss],\n    ActivationCache | dict[str, torch.Tensor],\n]:\n    \"\"\"Wrapper around 'run_with_cache' in HookedTransformer.\n\n    Attaches given SAEs before running the model with cache and then removes them.\n    By default, will reset all SAEs to original state after.\n\n    Args:\n        *model_args: Positional arguments for the model forward pass\n        saes: (SAE | list[SAE]) The SAEs to be attached for this forward pass\n        reset_saes_end: (bool) If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. Default is True.\n        use_error_term: (bool | None) If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Determines whether the SAE returns input or reconstruction. Defaults to None.\n        return_cache_object: (bool) if True, this will return an ActivationCache object, with a bunch of\n            useful HookedTransformer specific methods, otherwise it will return a dictionary of\n            activations as in HookedRootModule.\n        remove_batch_dim: (bool) Whether to remove the batch dimension (only works for batch_size==1). Defaults to False.\n        **kwargs: Keyword arguments for the model forward pass\n    \"\"\"\n    with self.saes(\n        saes=saes, reset_saes_end=reset_saes_end, use_error_term=use_error_term\n    ):\n        return self.run_with_cache(  # type: ignore\n            *model_args,\n            return_cache_object=return_cache_object,  # type: ignore\n            remove_batch_dim=remove_batch_dim,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer.run_with_hooks_with_saes","title":"<code>run_with_hooks_with_saes(*model_args, saes=[], reset_saes_end=True, fwd_hooks=[], bwd_hooks=[], reset_hooks_end=True, clear_contexts=False, **model_kwargs)</code>","text":"<p>Wrapper around 'run_with_hooks' in HookedTransformer.</p> <p>Attaches the given SAEs to the model before running the model with hooks and then removes them. By default, will reset all SAEs to original state after.</p> <p>Parameters:</p> Name Type Description Default <code>*model_args</code> <code>Any</code> <p>Positional arguments for the model forward pass</p> <code>()</code> <code>saes</code> <code>SAE | list[SAE]</code> <p>(SAE | list[SAE]) The SAEs to be attached for this forward pass</p> <code>[]</code> <code>reset_saes_end</code> <code>bool</code> <p>(bool) If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. (default: True)</p> <code>True</code> <code>fwd_hooks</code> <code>list[tuple[str | Callable, Callable]]</code> <p>(list[tuple[str | Callable, Callable]]) List of forward hooks to apply</p> <code>[]</code> <code>bwd_hooks</code> <code>list[tuple[str | Callable, Callable]]</code> <p>(list[tuple[str | Callable, Callable]]) List of backward hooks to apply</p> <code>[]</code> <code>reset_hooks_end</code> <code>bool</code> <p>(bool) Whether to reset the hooks at the end of the forward pass (default: True)</p> <code>True</code> <code>clear_contexts</code> <code>bool</code> <p>(bool) Whether to clear the contexts at the end of the forward pass (default: False)</p> <code>False</code> <code>**model_kwargs</code> <code>Any</code> <p>Keyword arguments for the model forward pass</p> <code>{}</code> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>def run_with_hooks_with_saes(\n    self,\n    *model_args: Any,\n    saes: SAE | list[SAE] = [],\n    reset_saes_end: bool = True,\n    fwd_hooks: list[tuple[str | Callable, Callable]] = [],  # type: ignore\n    bwd_hooks: list[tuple[str | Callable, Callable]] = [],  # type: ignore\n    reset_hooks_end: bool = True,\n    clear_contexts: bool = False,\n    **model_kwargs: Any,\n):\n    \"\"\"Wrapper around 'run_with_hooks' in HookedTransformer.\n\n    Attaches the given SAEs to the model before running the model with hooks and then removes them.\n    By default, will reset all SAEs to original state after.\n\n    Args:\n        *model_args: Positional arguments for the model forward pass\n        saes: (SAE | list[SAE]) The SAEs to be attached for this forward pass\n        reset_saes_end: (bool) If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. (default: True)\n        fwd_hooks: (list[tuple[str | Callable, Callable]]) List of forward hooks to apply\n        bwd_hooks: (list[tuple[str | Callable, Callable]]) List of backward hooks to apply\n        reset_hooks_end: (bool) Whether to reset the hooks at the end of the forward pass (default: True)\n        clear_contexts: (bool) Whether to clear the contexts at the end of the forward pass (default: False)\n        **model_kwargs: Keyword arguments for the model forward pass\n    \"\"\"\n    with self.saes(saes=saes, reset_saes_end=reset_saes_end):\n        return self.run_with_hooks(\n            *model_args,\n            fwd_hooks=fwd_hooks,\n            bwd_hooks=bwd_hooks,\n            reset_hooks_end=reset_hooks_end,\n            clear_contexts=clear_contexts,\n            **model_kwargs,\n        )\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer.run_with_saes","title":"<code>run_with_saes(*model_args, saes=[], reset_saes_end=True, use_error_term=None, **model_kwargs)</code>","text":"<p>Wrapper around HookedTransformer forward pass.</p> <p>Runs the model with the given SAEs attached for one forward pass, then removes them. By default, will reset all SAEs to original state after.</p> <p>Parameters:</p> Name Type Description Default <code>*model_args</code> <code>Any</code> <p>Positional arguments for the model forward pass</p> <code>()</code> <code>saes</code> <code>SAE | list[SAE]</code> <p>(SAE | list[SAE]) The SAEs to be attached for this forward pass</p> <code>[]</code> <code>reset_saes_end</code> <code>bool</code> <p>If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. Default is True.</p> <code>True</code> <code>use_error_term</code> <code>bool | None</code> <p>(bool | None) If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Defaults to None.</p> <code>None</code> <code>**model_kwargs</code> <code>Any</code> <p>Keyword arguments for the model forward pass</p> <code>{}</code> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>def run_with_saes(\n    self,\n    *model_args: Any,\n    saes: SAE | list[SAE] = [],\n    reset_saes_end: bool = True,\n    use_error_term: bool | None = None,\n    **model_kwargs: Any,\n) -&gt; (\n    None\n    | Float[torch.Tensor, \"batch pos d_vocab\"]\n    | Loss\n    | tuple[Float[torch.Tensor, \"batch pos d_vocab\"], Loss]\n):\n    \"\"\"Wrapper around HookedTransformer forward pass.\n\n    Runs the model with the given SAEs attached for one forward pass, then removes them. By default, will reset all SAEs to original state after.\n\n    Args:\n        *model_args: Positional arguments for the model forward pass\n        saes: (SAE | list[SAE]) The SAEs to be attached for this forward pass\n        reset_saes_end (bool): If True, all SAEs added during this run are removed at the end, and previously attached SAEs are restored to their original state. Default is True.\n        use_error_term: (bool | None) If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Defaults to None.\n        **model_kwargs: Keyword arguments for the model forward pass\n    \"\"\"\n    with self.saes(\n        saes=saes, reset_saes_end=reset_saes_end, use_error_term=use_error_term\n    ):\n        return self(*model_args, **model_kwargs)\n</code></pre>"},{"location":"api/#sae_lens.HookedSAETransformer.saes","title":"<code>saes(saes=[], reset_saes_end=True, use_error_term=None)</code>","text":"<p>A context manager for adding temporary SAEs to the model. See HookedTransformer.hooks for a similar context manager for hooks. By default will keep track of previously attached SAEs, and restore them when the context manager exits.</p> <p>Example:</p> <p>.. code-block:: python</p> <pre><code>from transformer_lens import HookedSAETransformer\nfrom sae_lens.sae import SAE\n\nmodel = HookedSAETransformer.from_pretrained('gpt2-small')\nsae_cfg = SAEConfig(...)\nsae = SAE(sae_cfg)\nwith model.saes(saes=[sae]):\n    spliced_logits = model(text)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>saes</code> <code>SAE | list[SAE]</code> <p>SAEs to be attached.</p> <code>[]</code> <code>reset_saes_end</code> <code>bool</code> <p>If True, removes all SAEs added by this context manager when the context manager exits, returning previously attached SAEs to their original state.</p> <code>True</code> <code>use_error_term</code> <code>bool | None</code> <p>If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Defaults to None.</p> <code>None</code> Source code in <code>sae_lens/analysis/hooked_sae_transformer.py</code> <pre><code>@contextmanager\ndef saes(\n    self,\n    saes: SAE | list[SAE] = [],\n    reset_saes_end: bool = True,\n    use_error_term: bool | None = None,\n):\n    \"\"\"\n    A context manager for adding temporary SAEs to the model.\n    See HookedTransformer.hooks for a similar context manager for hooks.\n    By default will keep track of previously attached SAEs, and restore them when the context manager exits.\n\n    Example:\n\n    .. code-block:: python\n\n        from transformer_lens import HookedSAETransformer\n        from sae_lens.sae import SAE\n\n        model = HookedSAETransformer.from_pretrained('gpt2-small')\n        sae_cfg = SAEConfig(...)\n        sae = SAE(sae_cfg)\n        with model.saes(saes=[sae]):\n            spliced_logits = model(text)\n\n\n    Args:\n        saes (SAE | list[SAE]): SAEs to be attached.\n        reset_saes_end (bool): If True, removes all SAEs added by this context manager when the context manager exits, returning previously attached SAEs to their original state.\n        use_error_term (bool | None): If provided, will set the use_error_term attribute of all SAEs attached during this run to this value. Defaults to None.\n    \"\"\"\n    act_names_to_reset = []\n    prev_saes = []\n    if isinstance(saes, SAE):\n        saes = [saes]\n    try:\n        for sae in saes:\n            act_names_to_reset.append(sae.cfg.hook_name)\n            prev_sae = self.acts_to_saes.get(sae.cfg.hook_name, None)\n            prev_saes.append(prev_sae)\n            self.add_sae(sae, use_error_term=use_error_term)\n        yield self\n    finally:\n        if reset_saes_end:\n            self.reset_saes(act_names_to_reset, prev_saes)\n</code></pre>"},{"location":"api/#sae_lens.LanguageModelSAERunnerConfig","title":"<code>LanguageModelSAERunnerConfig</code>  <code>dataclass</code>","text":"<p>Configuration for training a sparse autoencoder on a language model.</p> <p>Parameters:</p> Name Type Description Default <code>architecture</code> <code>str</code> <p>The architecture to use, either \"standard\", \"gated\", \"topk\", or \"jumprelu\".</p> <code>'standard'</code> <code>model_name</code> <code>str</code> <p>The name of the model to use. This should be the name of the model in the Hugging Face model hub.</p> <code>'gelu-2l'</code> <code>model_class_name</code> <code>str</code> <p>The name of the class of the model to use. This should be either <code>HookedTransformer</code> or <code>HookedMamba</code>.</p> <code>'HookedTransformer'</code> <code>hook_name</code> <code>str</code> <p>The name of the hook to use. This should be a valid TransformerLens hook.</p> <code>'blocks.0.hook_mlp_out'</code> <code>hook_eval</code> <code>str</code> <p>NOT CURRENTLY IN USE. The name of the hook to use for evaluation.</p> <code>'NOT_IN_USE'</code> <code>hook_layer</code> <code>int</code> <p>The index of the layer to hook. Used to stop forward passes early and speed up processing.</p> <code>0</code> <code>hook_head_index</code> <code>int</code> <p>When the hook if for an activatio with a head index, we can specify a specific head to use here.</p> <code>None</code> <code>dataset_path</code> <code>str</code> <p>A Hugging Face dataset path.</p> <code>''</code> <code>dataset_trust_remote_code</code> <code>bool</code> <p>Whether to trust remote code when loading datasets from Huggingface.</p> <code>True</code> <code>streaming</code> <code>bool</code> <p>Whether to stream the dataset. Streaming large datasets is usually practical.</p> <code>True</code> <code>is_dataset_tokenized</code> <code>bool</code> <p>NOT IN USE. We used to use this but now automatically detect if the dataset is tokenized.</p> <code>True</code> <code>context_size</code> <code>int</code> <p>The context size to use when generating activations on which to train the SAE.</p> <code>128</code> <code>use_cached_activations</code> <code>bool</code> <p>Whether to use cached activations. This is useful when doing sweeps over the same activations.</p> <code>False</code> <code>cached_activations_path</code> <code>str</code> <p>The path to the cached activations.</p> <code>None</code> <code>d_in</code> <code>int</code> <p>The input dimension of the SAE.</p> <code>512</code> <code>d_sae</code> <code>int</code> <p>The output dimension of the SAE. If None, defaults to <code>d_in * expansion_factor</code>.</p> <code>None</code> <code>b_dec_init_method</code> <code>str</code> <p>The method to use to initialize the decoder bias. Zeros is likely fine.</p> <code>'geometric_median'</code> <code>expansion_factor</code> <code>int</code> <p>The expansion factor. Larger is better but more computationally expensive. Default is 4.</p> <code>None</code> <code>activation_fn</code> <code>str</code> <p>The activation function to use. Relu is standard.</p> <code>None</code> <code>normalize_sae_decoder</code> <code>bool</code> <p>Whether to normalize the SAE decoder. Unit normed decoder weights used to be preferred.</p> <code>True</code> <code>noise_scale</code> <code>float</code> <p>Using noise to induce sparsity is supported but not recommended.</p> <code>0.0</code> <code>from_pretrained_path</code> <code>str</code> <p>The path to a pretrained SAE. We can finetune an existing SAE if needed.</p> <code>None</code> <code>apply_b_dec_to_input</code> <code>bool</code> <p>Whether to apply the decoder bias to the input. Not currently advised.</p> <code>True</code> <code>decoder_orthogonal_init</code> <code>bool</code> <p>Whether to use orthogonal initialization for the decoder. Not currently advised.</p> <code>False</code> <code>decoder_heuristic_init</code> <code>bool</code> <p>Whether to use heuristic initialization for the decoder. See Anthropic April Update.</p> <code>False</code> <code>init_encoder_as_decoder_transpose</code> <code>bool</code> <p>Whether to initialize the encoder as the transpose of the decoder. See Anthropic April Update.</p> <code>False</code> <code>n_batches_in_buffer</code> <code>int</code> <p>The number of batches in the buffer. When not using cached activations, a buffer in ram is used. The larger it is, the better shuffled the activations will be.</p> <code>20</code> <code>training_tokens</code> <code>int</code> <p>The number of training tokens.</p> <code>2000000</code> <code>finetuning_tokens</code> <code>int</code> <p>The number of finetuning tokens. See here</p> <code>0</code> <code>store_batch_size_prompts</code> <code>int</code> <p>The batch size for storing activations. This controls how many prompts are in the batch of the language model when generating actiations.</p> <code>32</code> <code>train_batch_size_tokens</code> <code>int</code> <p>The batch size for training. This controls the batch size of the SAE Training loop.</p> <code>4096</code> <code>normalize_activations</code> <code>str</code> <p>Activation Normalization Strategy. Either none, expected_average_only_in (estimate the average activation norm and divide activations by it following Antrhopic April update -&gt; this can be folded post training and set to None), or constant_norm_rescale (at runtime set activation norm to sqrt(d_in) and then scale up the SAE output).</p> <code>'none'</code> <code>seqpos_slice</code> <code>tuple</code> <p>Determines slicing of activations when constructing batches during training. The slice should be (start_pos, end_pos, optional[step_size]), e.g. for Othello we sometimes use (5, -5). Note, step_size &gt; 0.</p> <code>(None,)</code> <code>device</code> <code>str</code> <p>The device to use. Usually cuda.</p> <code>'cpu'</code> <code>act_store_device</code> <code>str</code> <p>The device to use for the activation store. CPU is advised in order to save vram.</p> <code>'with_model'</code> <code>seed</code> <code>int</code> <p>The seed to use.</p> <code>42</code> <code>dtype</code> <code>str</code> <p>The data type to use.</p> <code>'float32'</code> <code>prepend_bos</code> <code>bool</code> <p>Whether to prepend the beginning of sequence token. You should use whatever the model was trained with.</p> <code>True</code> <code>jumprelu_init_threshold</code> <code>float</code> <p>The threshold to initialize for training JumpReLU SAEs.</p> <code>0.001</code> <code>jumprelu_bandwidth</code> <code>float</code> <p>Bandwidth for training JumpReLU SAEs.</p> <code>0.001</code> <code>autocast</code> <code>bool</code> <p>Whether to use autocast during training. Saves vram.</p> <code>False</code> <code>autocast_lm</code> <code>bool</code> <p>Whether to use autocast during activation fetching.</p> <code>False</code> <code>compile_llm</code> <code>bool</code> <p>Whether to compile the LLM.</p> <code>False</code> <code>llm_compilation_mode</code> <code>str</code> <p>The compilation mode to use for the LLM.</p> <code>None</code> <code>compile_sae</code> <code>bool</code> <p>Whether to compile the SAE.</p> <code>False</code> <code>sae_compilation_mode</code> <code>str</code> <p>The compilation mode to use for the SAE.</p> <code>None</code> <code>adam_beta1</code> <code>float</code> <p>The beta1 parameter for Adam.</p> <code>0.0</code> <code>adam_beta2</code> <code>float</code> <p>The beta2 parameter for Adam.</p> <code>0.999</code> <code>mse_loss_normalization</code> <code>str</code> <p>The normalization to use for the MSE loss.</p> <code>None</code> <code>l1_coefficient</code> <code>float</code> <p>The L1 coefficient.</p> <code>0.001</code> <code>lp_norm</code> <code>float</code> <p>The Lp norm.</p> <code>1</code> <code>scale_sparsity_penalty_by_decoder_norm</code> <code>bool</code> <p>Whether to scale the sparsity penalty by the decoder norm.</p> <code>False</code> <code>l1_warm_up_steps</code> <code>int</code> <p>The number of warm-up steps for the L1 loss.</p> <code>0</code> <code>lr</code> <code>float</code> <p>The learning rate.</p> <code>0.0003</code> <code>lr_scheduler_name</code> <code>str</code> <p>The name of the learning rate scheduler to use.</p> <code>'constant'</code> <code>lr_warm_up_steps</code> <code>int</code> <p>The number of warm-up steps for the learning rate.</p> <code>0</code> <code>lr_end</code> <code>float</code> <p>The end learning rate if lr_decay_steps is set. Default is lr / 10.</p> <code>None</code> <code>lr_decay_steps</code> <code>int</code> <p>The number of decay steps for the learning rate.</p> <code>0</code> <code>n_restart_cycles</code> <code>int</code> <p>The number of restart cycles for the cosine annealing warm restarts scheduler.</p> <code>1</code> <code>finetuning_method</code> <code>str</code> <p>The method to use for finetuning.</p> <code>None</code> <code>use_ghost_grads</code> <code>bool</code> <p>Whether to use ghost gradients.</p> <code>False</code> <code>feature_sampling_window</code> <code>int</code> <p>The feature sampling window.</p> <code>2000</code> <code>dead_feature_window</code> <code>int</code> <p>The dead feature window.</p> <code>1000</code> <code>dead_feature_threshold</code> <code>float</code> <p>The dead feature threshold.</p> <code>1e-08</code> <code>n_eval_batches</code> <code>int</code> <p>The number of evaluation batches.</p> <code>10</code> <code>eval_batch_size_prompts</code> <code>int</code> <p>The batch size for evaluation.</p> <code>None</code> <code>log_to_wandb</code> <code>bool</code> <p>Whether to log to Weights &amp; Biases.</p> <code>True</code> <code>log_activations_store_to_wandb</code> <code>bool</code> <p>NOT CURRENTLY USED. Whether to log the activations store to Weights &amp; Biases.</p> <code>False</code> <code>log_optimizer_state_to_wandb</code> <code>bool</code> <p>NOT CURRENTLY USED. Whether to log the optimizer state to Weights &amp; Biases.</p> <code>False</code> <code>wandb_project</code> <code>str</code> <p>The Weights &amp; Biases project to log to.</p> <code>'mats_sae_training_language_model'</code> <code>wandb_id</code> <code>str</code> <p>The Weights &amp; Biases ID.</p> <code>None</code> <code>run_name</code> <code>str</code> <p>The name of the run.</p> <code>None</code> <code>wandb_entity</code> <code>str</code> <p>The Weights &amp; Biases entity.</p> <code>None</code> <code>wandb_log_frequency</code> <code>int</code> <p>The frequency to log to Weights &amp; Biases.</p> <code>10</code> <code>eval_every_n_wandb_logs</code> <code>int</code> <p>The frequency to evaluate.</p> <code>100</code> <code>resume</code> <code>bool</code> <p>Whether to resume training.</p> <code>False</code> <code>n_checkpoints</code> <code>int</code> <p>The number of checkpoints.</p> <code>0</code> <code>checkpoint_path</code> <code>str</code> <p>The path to save checkpoints.</p> <code>'checkpoints'</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose output.</p> <code>True</code> <code>model_kwargs</code> <code>dict[str, Any]</code> <p>Additional keyword arguments for the model.</p> <code>dict_field(default={})</code> <code>model_from_pretrained_kwargs</code> <code>dict[str, Any]</code> <p>Additional keyword arguments for the model from pretrained.</p> <code>dict_field(default=None)</code> <code>exclude_special_tokens</code> <code>bool | list[int]</code> <p>Whether to exclude special tokens from the activations.</p> <code>False</code> Source code in <code>sae_lens/config.py</code> <pre><code>@dataclass\nclass LanguageModelSAERunnerConfig:\n    \"\"\"\n    Configuration for training a sparse autoencoder on a language model.\n\n    Args:\n        architecture (str): The architecture to use, either \"standard\", \"gated\", \"topk\", or \"jumprelu\".\n        model_name (str): The name of the model to use. This should be the name of the model in the Hugging Face model hub.\n        model_class_name (str): The name of the class of the model to use. This should be either `HookedTransformer` or `HookedMamba`.\n        hook_name (str): The name of the hook to use. This should be a valid TransformerLens hook.\n        hook_eval (str): NOT CURRENTLY IN USE. The name of the hook to use for evaluation.\n        hook_layer (int): The index of the layer to hook. Used to stop forward passes early and speed up processing.\n        hook_head_index (int, optional): When the hook if for an activatio with a head index, we can specify a specific head to use here.\n        dataset_path (str): A Hugging Face dataset path.\n        dataset_trust_remote_code (bool): Whether to trust remote code when loading datasets from Huggingface.\n        streaming (bool): Whether to stream the dataset. Streaming large datasets is usually practical.\n        is_dataset_tokenized (bool): NOT IN USE. We used to use this but now automatically detect if the dataset is tokenized.\n        context_size (int): The context size to use when generating activations on which to train the SAE.\n        use_cached_activations (bool): Whether to use cached activations. This is useful when doing sweeps over the same activations.\n        cached_activations_path (str, optional): The path to the cached activations.\n        d_in (int): The input dimension of the SAE.\n        d_sae (int, optional): The output dimension of the SAE. If None, defaults to `d_in * expansion_factor`.\n        b_dec_init_method (str): The method to use to initialize the decoder bias. Zeros is likely fine.\n        expansion_factor (int): The expansion factor. Larger is better but more computationally expensive. Default is 4.\n        activation_fn (str): The activation function to use. Relu is standard.\n        normalize_sae_decoder (bool): Whether to normalize the SAE decoder. Unit normed decoder weights used to be preferred.\n        noise_scale (float): Using noise to induce sparsity is supported but not recommended.\n        from_pretrained_path (str, optional): The path to a pretrained SAE. We can finetune an existing SAE if needed.\n        apply_b_dec_to_input (bool): Whether to apply the decoder bias to the input. Not currently advised.\n        decoder_orthogonal_init (bool): Whether to use orthogonal initialization for the decoder. Not currently advised.\n        decoder_heuristic_init (bool): Whether to use heuristic initialization for the decoder. See Anthropic April Update.\n        init_encoder_as_decoder_transpose (bool): Whether to initialize the encoder as the transpose of the decoder. See Anthropic April Update.\n        n_batches_in_buffer (int): The number of batches in the buffer. When not using cached activations, a buffer in ram is used. The larger it is, the better shuffled the activations will be.\n        training_tokens (int): The number of training tokens.\n        finetuning_tokens (int): The number of finetuning tokens. See [here](https://www.lesswrong.com/posts/3JuSjTZyMzaSeTxKk/addressing-feature-suppression-in-saes)\n        store_batch_size_prompts (int): The batch size for storing activations. This controls how many prompts are in the batch of the language model when generating actiations.\n        train_batch_size_tokens (int): The batch size for training. This controls the batch size of the SAE Training loop.\n        normalize_activations (str): Activation Normalization Strategy. Either none, expected_average_only_in (estimate the average activation norm and divide activations by it following Antrhopic April update -&gt; this can be folded post training and set to None), or constant_norm_rescale (at runtime set activation norm to sqrt(d_in) and then scale up the SAE output).\n        seqpos_slice (tuple): Determines slicing of activations when constructing batches during training. The slice should be (start_pos, end_pos, optional[step_size]), e.g. for Othello we sometimes use (5, -5). Note, step_size &gt; 0.\n        device (str): The device to use. Usually cuda.\n        act_store_device (str): The device to use for the activation store. CPU is advised in order to save vram.\n        seed (int): The seed to use.\n        dtype (str): The data type to use.\n        prepend_bos (bool): Whether to prepend the beginning of sequence token. You should use whatever the model was trained with.\n        jumprelu_init_threshold (float): The threshold to initialize for training JumpReLU SAEs.\n        jumprelu_bandwidth (float): Bandwidth for training JumpReLU SAEs.\n        autocast (bool): Whether to use autocast during training. Saves vram.\n        autocast_lm (bool): Whether to use autocast during activation fetching.\n        compile_llm (bool): Whether to compile the LLM.\n        llm_compilation_mode (str): The compilation mode to use for the LLM.\n        compile_sae (bool): Whether to compile the SAE.\n        sae_compilation_mode (str): The compilation mode to use for the SAE.\n        adam_beta1 (float): The beta1 parameter for Adam.\n        adam_beta2 (float): The beta2 parameter for Adam.\n        mse_loss_normalization (str): The normalization to use for the MSE loss.\n        l1_coefficient (float): The L1 coefficient.\n        lp_norm (float): The Lp norm.\n        scale_sparsity_penalty_by_decoder_norm (bool): Whether to scale the sparsity penalty by the decoder norm.\n        l1_warm_up_steps (int): The number of warm-up steps for the L1 loss.\n        lr (float): The learning rate.\n        lr_scheduler_name (str): The name of the learning rate scheduler to use.\n        lr_warm_up_steps (int): The number of warm-up steps for the learning rate.\n        lr_end (float): The end learning rate if lr_decay_steps is set. Default is lr / 10.\n        lr_decay_steps (int): The number of decay steps for the learning rate.\n        n_restart_cycles (int): The number of restart cycles for the cosine annealing warm restarts scheduler.\n        finetuning_method (str): The method to use for finetuning.\n        use_ghost_grads (bool): Whether to use ghost gradients.\n        feature_sampling_window (int): The feature sampling window.\n        dead_feature_window (int): The dead feature window.\n        dead_feature_threshold (float): The dead feature threshold.\n        n_eval_batches (int): The number of evaluation batches.\n        eval_batch_size_prompts (int): The batch size for evaluation.\n        log_to_wandb (bool): Whether to log to Weights &amp; Biases.\n        log_activations_store_to_wandb (bool): NOT CURRENTLY USED. Whether to log the activations store to Weights &amp; Biases.\n        log_optimizer_state_to_wandb (bool): NOT CURRENTLY USED. Whether to log the optimizer state to Weights &amp; Biases.\n        wandb_project (str): The Weights &amp; Biases project to log to.\n        wandb_id (str): The Weights &amp; Biases ID.\n        run_name (str): The name of the run.\n        wandb_entity (str): The Weights &amp; Biases entity.\n        wandb_log_frequency (int): The frequency to log to Weights &amp; Biases.\n        eval_every_n_wandb_logs (int): The frequency to evaluate.\n        resume (bool): Whether to resume training.\n        n_checkpoints (int): The number of checkpoints.\n        checkpoint_path (str): The path to save checkpoints.\n        verbose (bool): Whether to print verbose output.\n        model_kwargs (dict[str, Any]): Additional keyword arguments for the model.\n        model_from_pretrained_kwargs (dict[str, Any]): Additional keyword arguments for the model from pretrained.\n        exclude_special_tokens (bool | list[int]): Whether to exclude special tokens from the activations.\n    \"\"\"\n\n    # Data Generating Function (Model + Training Distibuion)\n    model_name: str = \"gelu-2l\"\n    model_class_name: str = \"HookedTransformer\"\n    hook_name: str = \"blocks.0.hook_mlp_out\"\n    hook_eval: str = \"NOT_IN_USE\"\n    hook_layer: int = 0\n    hook_head_index: int | None = None\n    dataset_path: str = \"\"\n    dataset_trust_remote_code: bool = True\n    streaming: bool = True\n    is_dataset_tokenized: bool = True\n    context_size: int = 128\n    use_cached_activations: bool = False\n    cached_activations_path: str | None = (\n        None  # Defaults to \"activations/{dataset}/{model}/{full_hook_name}_{hook_head_index}\"\n    )\n\n    # SAE Parameters\n    architecture: Literal[\"standard\", \"gated\", \"jumprelu\", \"topk\"] = \"standard\"\n    d_in: int = 512\n    d_sae: int | None = None\n    b_dec_init_method: str = \"geometric_median\"\n    expansion_factor: int | None = (\n        None  # defaults to 4 if d_sae and expansion_factor is None\n    )\n    activation_fn: str = None  # relu, tanh-relu, topk. Default is relu. # type: ignore\n    activation_fn_kwargs: dict[str, int] = dict_field(default=None)  # for topk\n    normalize_sae_decoder: bool = True\n    noise_scale: float = 0.0\n    from_pretrained_path: str | None = None\n    apply_b_dec_to_input: bool = True\n    decoder_orthogonal_init: bool = False\n    decoder_heuristic_init: bool = False\n    decoder_heuristic_init_norm: float = 0.1\n    init_encoder_as_decoder_transpose: bool = False\n\n    # Activation Store Parameters\n    n_batches_in_buffer: int = 20\n    training_tokens: int = 2_000_000\n    finetuning_tokens: int = 0\n    store_batch_size_prompts: int = 32\n    normalize_activations: str = \"none\"  # none, expected_average_only_in (Anthropic April Update), constant_norm_rescale (Anthropic Feb Update)\n    seqpos_slice: tuple[int | None, ...] = (None,)\n\n    # Misc\n    device: str = \"cpu\"\n    act_store_device: str = \"with_model\"  # will be set by post init if with_model\n    seed: int = 42\n    dtype: str = \"float32\"  # type: ignore #\n    prepend_bos: bool = True\n\n    # JumpReLU Parameters\n    jumprelu_init_threshold: float = 0.001\n    jumprelu_bandwidth: float = 0.001\n\n    # Performance - see compilation section of lm_runner.py for info\n    autocast: bool = False  # autocast to autocast_dtype during training\n    autocast_lm: bool = False  # autocast lm during activation fetching\n    compile_llm: bool = False  # use torch.compile on the LLM\n    llm_compilation_mode: str | None = None  # which torch.compile mode to use\n    compile_sae: bool = False  # use torch.compile on the SAE\n    sae_compilation_mode: str | None = None\n\n    # Training Parameters\n\n    ## Batch size\n    train_batch_size_tokens: int = 4096\n\n    ## Adam\n    adam_beta1: float = 0.0\n    adam_beta2: float = 0.999\n\n    ## Loss Function\n    mse_loss_normalization: str | None = None\n    l1_coefficient: float = 1e-3\n    lp_norm: float = 1\n    scale_sparsity_penalty_by_decoder_norm: bool = False\n    l1_warm_up_steps: int = 0\n\n    ## Learning Rate Schedule\n    lr: float = 3e-4\n    lr_scheduler_name: str = (\n        \"constant\"  # constant, cosineannealing, cosineannealingwarmrestarts\n    )\n    lr_warm_up_steps: int = 0\n    lr_end: float | None = None  # only used for cosine annealing, default is lr / 10\n    lr_decay_steps: int = 0\n    n_restart_cycles: int = 1  # used only for cosineannealingwarmrestarts\n\n    ## FineTuning\n    finetuning_method: str | None = None  # scale, decoder or unrotated_decoder\n\n    # Resampling protocol args\n    use_ghost_grads: bool = False  # want to change this to true on some timeline.\n    feature_sampling_window: int = 2000\n    dead_feature_window: int = 1000  # unless this window is larger feature sampling,\n\n    dead_feature_threshold: float = 1e-8\n\n    # Evals\n    n_eval_batches: int = 10\n    eval_batch_size_prompts: int | None = None  # useful if evals cause OOM\n\n    # WANDB\n    log_to_wandb: bool = True\n    log_activations_store_to_wandb: bool = False\n    log_optimizer_state_to_wandb: bool = False\n    wandb_project: str = \"mats_sae_training_language_model\"\n    wandb_id: str | None = None\n    run_name: str | None = None\n    wandb_entity: str | None = None\n    wandb_log_frequency: int = 10\n    eval_every_n_wandb_logs: int = 100  # logs every 1000 steps.\n\n    # Misc\n    resume: bool = False\n    n_checkpoints: int = 0\n    checkpoint_path: str = \"checkpoints\"\n    verbose: bool = True\n    model_kwargs: dict[str, Any] = dict_field(default={})\n    model_from_pretrained_kwargs: dict[str, Any] | None = dict_field(default=None)\n    sae_lens_version: str = field(default_factory=lambda: __version__)\n    sae_lens_training_version: str = field(default_factory=lambda: __version__)\n    exclude_special_tokens: bool | list[int] = False\n\n    def __post_init__(self):\n        if self.resume:\n            raise ValueError(\n                \"Resuming is no longer supported. You can finetune a trained SAE using cfg.from_pretrained path.\"\n                + \"If you want to load an SAE with resume=True in the config, please manually set resume=False in that config.\"\n            )\n\n        if self.use_cached_activations and self.cached_activations_path is None:\n            self.cached_activations_path = _default_cached_activations_path(\n                self.dataset_path,\n                self.model_name,\n                self.hook_name,\n                self.hook_head_index,\n            )\n\n        if self.activation_fn is None:\n            self.activation_fn = \"topk\" if self.architecture == \"topk\" else \"relu\"\n\n        if self.architecture == \"topk\" and self.activation_fn != \"topk\":\n            raise ValueError(\"If using topk architecture, activation_fn must be topk.\")\n\n        if self.activation_fn_kwargs is None:\n            self.activation_fn_kwargs = (\n                {\"k\": 100} if self.activation_fn == \"topk\" else {}\n            )\n\n        if self.architecture == \"topk\" and self.activation_fn_kwargs.get(\"k\") is None:\n            raise ValueError(\n                \"activation_fn_kwargs.k must be provided for topk architecture.\"\n            )\n\n        if self.d_sae is not None and self.expansion_factor is not None:\n            raise ValueError(\"You can't set both d_sae and expansion_factor.\")\n\n        if self.d_sae is None and self.expansion_factor is None:\n            self.expansion_factor = 4\n\n        if self.d_sae is None and self.expansion_factor is not None:\n            self.d_sae = self.d_in * self.expansion_factor\n        self.tokens_per_buffer = (\n            self.train_batch_size_tokens * self.context_size * self.n_batches_in_buffer\n        )\n\n        if self.run_name is None:\n            self.run_name = f\"{self.d_sae}-L1-{self.l1_coefficient}-LR-{self.lr}-Tokens-{self.training_tokens:3.3e}\"\n\n        if self.model_from_pretrained_kwargs is None:\n            if self.model_class_name == \"HookedTransformer\":\n                self.model_from_pretrained_kwargs = {\"center_writing_weights\": False}\n            else:\n                self.model_from_pretrained_kwargs = {}\n\n        if self.b_dec_init_method not in [\"geometric_median\", \"mean\", \"zeros\"]:\n            raise ValueError(\n                f\"b_dec_init_method must be geometric_median, mean, or zeros. Got {self.b_dec_init_method}\"\n            )\n\n        if self.normalize_sae_decoder and self.decoder_heuristic_init:\n            raise ValueError(\n                \"You can't normalize the decoder and use heuristic initialization.\"\n            )\n\n        if self.normalize_sae_decoder and self.scale_sparsity_penalty_by_decoder_norm:\n            raise ValueError(\n                \"Weighting loss by decoder norm makes no sense if you are normalizing the decoder weight norms to 1\"\n            )\n\n        # if we use decoder fine tuning, we can't be applying b_dec to the input\n        if (self.finetuning_method == \"decoder\") and (self.apply_b_dec_to_input):\n            raise ValueError(\n                \"If we are fine tuning the decoder, we can't be applying b_dec to the input.\\nSet apply_b_dec_to_input to False.\"\n            )\n\n        if self.normalize_activations not in [\n            \"none\",\n            \"expected_average_only_in\",\n            \"constant_norm_rescale\",\n            \"layer_norm\",\n        ]:\n            raise ValueError(\n                f\"normalize_activations must be none, layer_norm, expected_average_only_in, or constant_norm_rescale. Got {self.normalize_activations}\"\n            )\n\n        if self.act_store_device == \"with_model\":\n            self.act_store_device = self.device\n\n        if self.lr_end is None:\n            self.lr_end = self.lr / 10\n\n        unique_id = self.wandb_id\n        if unique_id is None:\n            unique_id = cast(\n                Any, wandb\n            ).util.generate_id()  # not sure why this type is erroring\n        self.checkpoint_path = f\"{self.checkpoint_path}/{unique_id}\"\n\n        if self.verbose:\n            logger.info(\n                f\"Run name: {self.d_sae}-L1-{self.l1_coefficient}-LR-{self.lr}-Tokens-{self.training_tokens:3.3e}\"\n            )\n            # Print out some useful info:\n            n_tokens_per_buffer = (\n                self.store_batch_size_prompts\n                * self.context_size\n                * self.n_batches_in_buffer\n            )\n            logger.info(\n                f\"n_tokens_per_buffer (millions): {n_tokens_per_buffer / 10**6}\"\n            )\n            n_contexts_per_buffer = (\n                self.store_batch_size_prompts * self.n_batches_in_buffer\n            )\n            logger.info(\n                f\"Lower bound: n_contexts_per_buffer (millions): {n_contexts_per_buffer / 10**6}\"\n            )\n\n            total_training_steps = (\n                self.training_tokens + self.finetuning_tokens\n            ) // self.train_batch_size_tokens\n            logger.info(f\"Total training steps: {total_training_steps}\")\n\n            total_wandb_updates = total_training_steps // self.wandb_log_frequency\n            logger.info(f\"Total wandb updates: {total_wandb_updates}\")\n\n            # how many times will we sample dead neurons?\n            # assert self.dead_feature_window &lt;= self.feature_sampling_window, \"dead_feature_window must be smaller than feature_sampling_window\"\n            n_feature_window_samples = (\n                total_training_steps // self.feature_sampling_window\n            )\n            logger.info(\n                f\"n_tokens_per_feature_sampling_window (millions): {(self.feature_sampling_window * self.context_size * self.train_batch_size_tokens) / 10**6}\"\n            )\n            logger.info(\n                f\"n_tokens_per_dead_feature_window (millions): {(self.dead_feature_window * self.context_size * self.train_batch_size_tokens) / 10**6}\"\n            )\n            logger.info(\n                f\"We will reset the sparsity calculation {n_feature_window_samples} times.\"\n            )\n            # logger.info(\"Number tokens in dead feature calculation window: \", self.dead_feature_window * self.train_batch_size_tokens)\n            logger.info(\n                f\"Number tokens in sparsity calculation window: {self.feature_sampling_window * self.train_batch_size_tokens:.2e}\"\n            )\n\n        if self.use_ghost_grads:\n            logger.info(\"Using Ghost Grads.\")\n\n        if self.context_size &lt; 0:\n            raise ValueError(\n                f\"The provided context_size is {self.context_size} is negative. Expecting positive context_size.\"\n            )\n\n        _validate_seqpos(seqpos=self.seqpos_slice, context_size=self.context_size)\n\n        if isinstance(self.exclude_special_tokens, list) and not all(\n            isinstance(x, int) for x in self.exclude_special_tokens\n        ):\n            raise ValueError(\"exclude_special_tokens list must contain only integers\")\n\n    @property\n    def total_training_tokens(self) -&gt; int:\n        return self.training_tokens + self.finetuning_tokens\n\n    @property\n    def total_training_steps(self) -&gt; int:\n        return self.total_training_tokens // self.train_batch_size_tokens\n\n    def get_base_sae_cfg_dict(self) -&gt; dict[str, Any]:\n        return {\n            # TEMP\n            \"architecture\": self.architecture,\n            \"d_in\": self.d_in,\n            \"d_sae\": self.d_sae,\n            \"dtype\": self.dtype,\n            \"device\": self.device,\n            \"model_name\": self.model_name,\n            \"hook_name\": self.hook_name,\n            \"hook_layer\": self.hook_layer,\n            \"hook_head_index\": self.hook_head_index,\n            \"activation_fn_str\": self.activation_fn,\n            \"apply_b_dec_to_input\": self.apply_b_dec_to_input,\n            \"context_size\": self.context_size,\n            \"prepend_bos\": self.prepend_bos,\n            \"dataset_path\": self.dataset_path,\n            \"dataset_trust_remote_code\": self.dataset_trust_remote_code,\n            \"finetuning_scaling_factor\": self.finetuning_method is not None,\n            \"sae_lens_training_version\": self.sae_lens_training_version,\n            \"normalize_activations\": self.normalize_activations,\n            \"activation_fn_kwargs\": self.activation_fn_kwargs,\n            \"model_from_pretrained_kwargs\": self.model_from_pretrained_kwargs,\n            \"seqpos_slice\": self.seqpos_slice,\n        }\n\n    def get_training_sae_cfg_dict(self) -&gt; dict[str, Any]:\n        return {\n            **self.get_base_sae_cfg_dict(),\n            \"l1_coefficient\": self.l1_coefficient,\n            \"lp_norm\": self.lp_norm,\n            \"use_ghost_grads\": self.use_ghost_grads,\n            \"normalize_sae_decoder\": self.normalize_sae_decoder,\n            \"noise_scale\": self.noise_scale,\n            \"decoder_orthogonal_init\": self.decoder_orthogonal_init,\n            \"mse_loss_normalization\": self.mse_loss_normalization,\n            \"decoder_heuristic_init\": self.decoder_heuristic_init,\n            \"decoder_heuristic_init_norm\": self.decoder_heuristic_init_norm,\n            \"init_encoder_as_decoder_transpose\": self.init_encoder_as_decoder_transpose,\n            \"normalize_activations\": self.normalize_activations,\n            \"jumprelu_init_threshold\": self.jumprelu_init_threshold,\n            \"jumprelu_bandwidth\": self.jumprelu_bandwidth,\n            \"scale_sparsity_penalty_by_decoder_norm\": self.scale_sparsity_penalty_by_decoder_norm,\n        }\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        return {\n            **self.__dict__,\n            # some args may not be serializable by default\n            \"dtype\": str(self.dtype),\n            \"device\": str(self.device),\n            \"act_store_device\": str(self.act_store_device),\n        }\n\n    def to_json(self, path: str) -&gt; None:\n        if not os.path.exists(os.path.dirname(path)):\n            os.makedirs(os.path.dirname(path))\n\n        with open(path + \"cfg.json\", \"w\") as f:\n            json.dump(self.to_dict(), f, indent=2)\n\n    @classmethod\n    def from_json(cls, path: str) -&gt; \"LanguageModelSAERunnerConfig\":\n        with open(path + \"cfg.json\") as f:\n            cfg = json.load(f)\n\n        # ensure that seqpos slices is a tuple\n        # Ensure seqpos_slice is a tuple\n        if \"seqpos_slice\" in cfg:\n            if isinstance(cfg[\"seqpos_slice\"], list):\n                cfg[\"seqpos_slice\"] = tuple(cfg[\"seqpos_slice\"])\n            elif not isinstance(cfg[\"seqpos_slice\"], tuple):\n                cfg[\"seqpos_slice\"] = (cfg[\"seqpos_slice\"],)\n\n        return cls(**cfg)\n</code></pre>"},{"location":"api/#sae_lens.PretokenizeRunner","title":"<code>PretokenizeRunner</code>","text":"<p>Runner to pretokenize a dataset using a given tokenizer, and optionally upload to Huggingface.</p> Source code in <code>sae_lens/pretokenize_runner.py</code> <pre><code>class PretokenizeRunner:\n    \"\"\"\n    Runner to pretokenize a dataset using a given tokenizer, and optionally upload to Huggingface.\n    \"\"\"\n\n    def __init__(self, cfg: PretokenizeRunnerConfig):\n        self.cfg = cfg\n\n    def run(self):\n        \"\"\"\n        Load the dataset, tokenize it, and save it to disk and/or upload to Huggingface.\n        \"\"\"\n        dataset = load_dataset(\n            self.cfg.dataset_path,\n            name=self.cfg.dataset_name,\n            data_dir=self.cfg.data_dir,\n            data_files=self.cfg.data_files,\n            split=self.cfg.split,\n            streaming=self.cfg.streaming,\n        )\n        if isinstance(dataset, DatasetDict):\n            raise ValueError(\n                \"Dataset has multiple splits. Must provide a 'split' param.\"\n            )\n        tokenizer = AutoTokenizer.from_pretrained(self.cfg.tokenizer_name)\n        tokenizer.model_max_length = sys.maxsize\n        tokenized_dataset = pretokenize_dataset(\n            cast(Dataset, dataset), tokenizer, self.cfg\n        )\n\n        if self.cfg.save_path is not None:\n            tokenized_dataset.save_to_disk(self.cfg.save_path)\n            metadata = metadata_from_config(self.cfg)\n            metadata_path = Path(self.cfg.save_path) / \"sae_lens.json\"\n            with open(metadata_path, \"w\") as f:\n                json.dump(metadata.__dict__, f, indent=2, ensure_ascii=False)\n\n        if self.cfg.hf_repo_id is not None:\n            push_to_hugging_face_hub(tokenized_dataset, self.cfg)\n\n        return tokenized_dataset\n</code></pre>"},{"location":"api/#sae_lens.PretokenizeRunner.run","title":"<code>run()</code>","text":"<p>Load the dataset, tokenize it, and save it to disk and/or upload to Huggingface.</p> Source code in <code>sae_lens/pretokenize_runner.py</code> <pre><code>def run(self):\n    \"\"\"\n    Load the dataset, tokenize it, and save it to disk and/or upload to Huggingface.\n    \"\"\"\n    dataset = load_dataset(\n        self.cfg.dataset_path,\n        name=self.cfg.dataset_name,\n        data_dir=self.cfg.data_dir,\n        data_files=self.cfg.data_files,\n        split=self.cfg.split,\n        streaming=self.cfg.streaming,\n    )\n    if isinstance(dataset, DatasetDict):\n        raise ValueError(\n            \"Dataset has multiple splits. Must provide a 'split' param.\"\n        )\n    tokenizer = AutoTokenizer.from_pretrained(self.cfg.tokenizer_name)\n    tokenizer.model_max_length = sys.maxsize\n    tokenized_dataset = pretokenize_dataset(\n        cast(Dataset, dataset), tokenizer, self.cfg\n    )\n\n    if self.cfg.save_path is not None:\n        tokenized_dataset.save_to_disk(self.cfg.save_path)\n        metadata = metadata_from_config(self.cfg)\n        metadata_path = Path(self.cfg.save_path) / \"sae_lens.json\"\n        with open(metadata_path, \"w\") as f:\n            json.dump(metadata.__dict__, f, indent=2, ensure_ascii=False)\n\n    if self.cfg.hf_repo_id is not None:\n        push_to_hugging_face_hub(tokenized_dataset, self.cfg)\n\n    return tokenized_dataset\n</code></pre>"},{"location":"api/#sae_lens.SAE","title":"<code>SAE</code>","text":"<p>               Bases: <code>HookedRootModule</code></p> <p>Core Sparse Autoencoder (SAE) class used for inference. For training, see <code>TrainingSAE</code>.</p> Source code in <code>sae_lens/sae.py</code> <pre><code>class SAE(HookedRootModule):\n    \"\"\"\n    Core Sparse Autoencoder (SAE) class used for inference. For training, see `TrainingSAE`.\n    \"\"\"\n\n    cfg: SAEConfig\n    dtype: torch.dtype\n    device: torch.device\n    x_norm_coeff: torch.Tensor\n\n    # analysis\n    use_error_term: bool\n\n    def __init__(\n        self,\n        cfg: SAEConfig,\n        use_error_term: bool = False,\n    ):\n        super().__init__()\n\n        self.cfg = cfg\n\n        if cfg.model_from_pretrained_kwargs:\n            warnings.warn(\n                \"\\nThis SAE has non-empty model_from_pretrained_kwargs. \"\n                \"\\nFor optimal performance, load the model like so:\\n\"\n                \"model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\",\n                category=UserWarning,\n                stacklevel=1,\n            )\n\n        self.activation_fn = get_activation_fn(\n            cfg.activation_fn_str, **cfg.activation_fn_kwargs or {}\n        )\n        self.dtype = DTYPE_MAP[cfg.dtype]\n        self.device = torch.device(cfg.device)\n        self.use_error_term = use_error_term\n\n        if self.cfg.architecture == \"standard\" or self.cfg.architecture == \"topk\":\n            self.initialize_weights_basic()\n            self.encode = self.encode_standard\n        elif self.cfg.architecture == \"gated\":\n            self.initialize_weights_gated()\n            self.encode = self.encode_gated\n        elif self.cfg.architecture == \"jumprelu\":\n            self.initialize_weights_jumprelu()\n            self.encode = self.encode_jumprelu\n        else:\n            raise ValueError(f\"Invalid architecture: {self.cfg.architecture}\")\n\n        # handle presence / absence of scaling factor.\n        if self.cfg.finetuning_scaling_factor:\n            self.apply_finetuning_scaling_factor = (\n                lambda x: x * self.finetuning_scaling_factor\n            )\n        else:\n            self.apply_finetuning_scaling_factor = lambda x: x\n\n        # set up hooks\n        self.hook_sae_input = HookPoint()\n        self.hook_sae_acts_pre = HookPoint()\n        self.hook_sae_acts_post = HookPoint()\n        self.hook_sae_output = HookPoint()\n        self.hook_sae_recons = HookPoint()\n        self.hook_sae_error = HookPoint()\n\n        # handle hook_z reshaping if needed.\n        # this is very cursed and should be refactored. it exists so that we can reshape out\n        # the z activations for hook_z SAEs. but don't know d_head if we split up the forward pass\n        # into a separate encode and decode function.\n        # this will cause errors if we call decode before encode.\n        if self.cfg.hook_name.endswith(\"_z\"):\n            self.turn_on_forward_pass_hook_z_reshaping()\n        else:\n            # need to default the reshape fns\n            self.turn_off_forward_pass_hook_z_reshaping()\n\n        # handle run time activation normalization if needed:\n        if self.cfg.normalize_activations == \"constant_norm_rescale\":\n            #  we need to scale the norm of the input and store the scaling factor\n            def run_time_activation_norm_fn_in(x: torch.Tensor) -&gt; torch.Tensor:\n                self.x_norm_coeff = (self.cfg.d_in**0.5) / x.norm(dim=-1, keepdim=True)\n                return x * self.x_norm_coeff\n\n            def run_time_activation_norm_fn_out(x: torch.Tensor) -&gt; torch.Tensor:  #\n                x = x / self.x_norm_coeff\n                del self.x_norm_coeff  # prevents reusing\n                return x\n\n            self.run_time_activation_norm_fn_in = run_time_activation_norm_fn_in\n            self.run_time_activation_norm_fn_out = run_time_activation_norm_fn_out\n\n        elif self.cfg.normalize_activations == \"layer_norm\":\n            #  we need to scale the norm of the input and store the scaling factor\n            def run_time_activation_ln_in(\n                x: torch.Tensor, eps: float = 1e-5\n            ) -&gt; torch.Tensor:\n                mu = x.mean(dim=-1, keepdim=True)\n                x = x - mu\n                std = x.std(dim=-1, keepdim=True)\n                x = x / (std + eps)\n                self.ln_mu = mu\n                self.ln_std = std\n                return x\n\n            def run_time_activation_ln_out(\n                x: torch.Tensor,\n                eps: float = 1e-5,  # noqa: ARG001\n            ) -&gt; torch.Tensor:\n                return x * self.ln_std + self.ln_mu  # type: ignore\n\n            self.run_time_activation_norm_fn_in = run_time_activation_ln_in\n            self.run_time_activation_norm_fn_out = run_time_activation_ln_out\n        else:\n            self.run_time_activation_norm_fn_in = lambda x: x\n            self.run_time_activation_norm_fn_out = lambda x: x\n\n        self.setup()  # Required for `HookedRootModule`s\n\n    def initialize_weights_basic(self):\n        # no config changes encoder bias init for now.\n        self.b_enc = nn.Parameter(\n            torch.zeros(self.cfg.d_sae, dtype=self.dtype, device=self.device)\n        )\n\n        # Start with the default init strategy:\n        self.W_dec = nn.Parameter(\n            torch.nn.init.kaiming_uniform_(\n                torch.empty(\n                    self.cfg.d_sae, self.cfg.d_in, dtype=self.dtype, device=self.device\n                )\n            )\n        )\n\n        self.W_enc = nn.Parameter(\n            torch.nn.init.kaiming_uniform_(\n                torch.empty(\n                    self.cfg.d_in, self.cfg.d_sae, dtype=self.dtype, device=self.device\n                )\n            )\n        )\n\n        # methdods which change b_dec as a function of the dataset are implemented after init.\n        self.b_dec = nn.Parameter(\n            torch.zeros(self.cfg.d_in, dtype=self.dtype, device=self.device)\n        )\n\n        # scaling factor for fine-tuning (not to be used in initial training)\n        # TODO: Make this optional and not included with all SAEs by default (but maintain backwards compatibility)\n        if self.cfg.finetuning_scaling_factor:\n            self.finetuning_scaling_factor = nn.Parameter(\n                torch.ones(self.cfg.d_sae, dtype=self.dtype, device=self.device)\n            )\n\n    def initialize_weights_gated(self):\n        # Initialize the weights and biases for the gated encoder\n        self.W_enc = nn.Parameter(\n            torch.nn.init.kaiming_uniform_(\n                torch.empty(\n                    self.cfg.d_in, self.cfg.d_sae, dtype=self.dtype, device=self.device\n                )\n            )\n        )\n\n        self.b_gate = nn.Parameter(\n            torch.zeros(self.cfg.d_sae, dtype=self.dtype, device=self.device)\n        )\n\n        self.r_mag = nn.Parameter(\n            torch.zeros(self.cfg.d_sae, dtype=self.dtype, device=self.device)\n        )\n\n        self.b_mag = nn.Parameter(\n            torch.zeros(self.cfg.d_sae, dtype=self.dtype, device=self.device)\n        )\n\n        self.W_dec = nn.Parameter(\n            torch.nn.init.kaiming_uniform_(\n                torch.empty(\n                    self.cfg.d_sae, self.cfg.d_in, dtype=self.dtype, device=self.device\n                )\n            )\n        )\n\n        self.b_dec = nn.Parameter(\n            torch.zeros(self.cfg.d_in, dtype=self.dtype, device=self.device)\n        )\n\n    def initialize_weights_jumprelu(self):\n        # The params are identical to the standard SAE\n        # except we use a threshold parameter too\n        self.threshold = nn.Parameter(\n            torch.zeros(self.cfg.d_sae, dtype=self.dtype, device=self.device)\n        )\n        self.initialize_weights_basic()\n\n    @overload\n    def to(\n        self: T,\n        device: torch.device | str | None = ...,\n        dtype: torch.dtype | None = ...,\n        non_blocking: bool = ...,\n    ) -&gt; T: ...\n\n    @overload\n    def to(self: T, dtype: torch.dtype, non_blocking: bool = ...) -&gt; T: ...\n\n    @overload\n    def to(self: T, tensor: torch.Tensor, non_blocking: bool = ...) -&gt; T: ...\n\n    def to(self, *args: Any, **kwargs: Any) -&gt; \"SAE\":  # type: ignore\n        device_arg = None\n        dtype_arg = None\n\n        # Check args\n        for arg in args:\n            if isinstance(arg, (torch.device, str)):\n                device_arg = arg\n            elif isinstance(arg, torch.dtype):\n                dtype_arg = arg\n            elif isinstance(arg, torch.Tensor):\n                device_arg = arg.device\n                dtype_arg = arg.dtype\n\n        # Check kwargs\n        device_arg = kwargs.get(\"device\", device_arg)\n        dtype_arg = kwargs.get(\"dtype\", dtype_arg)\n\n        if device_arg is not None:\n            # Convert device to torch.device if it's a string\n            device = (\n                torch.device(device_arg) if isinstance(device_arg, str) else device_arg\n            )\n\n            # Update the cfg.device\n            self.cfg.device = str(device)\n\n            # Update the .device property\n            self.device = device\n\n        if dtype_arg is not None:\n            # Update the cfg.dtype\n            self.cfg.dtype = str(dtype_arg)\n\n            # Update the .dtype property\n            self.dtype = dtype_arg\n\n        # Call the parent class's to() method to handle all cases (device, dtype, tensor)\n        return super().to(*args, **kwargs)\n\n    # Basic Forward Pass Functionality.\n    def forward(\n        self,\n        x: torch.Tensor,\n    ) -&gt; torch.Tensor:\n        feature_acts = self.encode(x)\n        sae_out = self.decode(feature_acts)\n\n        # TEMP\n        if self.use_error_term:\n            with torch.no_grad():\n                # Recompute everything without hooks to get true error term\n                # Otherwise, the output with error term will always equal input, even for causal interventions that affect x_reconstruct\n                # This is in a no_grad context to detach the error, so we can compute SAE feature gradients (eg for attribution patching). See A.3 in https://arxiv.org/pdf/2403.19647.pdf for more detail\n                # NOTE: we can't just use `sae_error = input - x_reconstruct.detach()` or something simpler, since this would mean intervening on features would mean ablating features still results in perfect reconstruction.\n                with _disable_hooks(self):\n                    feature_acts_clean = self.encode(x)\n                    x_reconstruct_clean = self.decode(feature_acts_clean)\n                sae_error = self.hook_sae_error(x - x_reconstruct_clean)\n            sae_out = sae_out + sae_error\n        return self.hook_sae_output(sae_out)\n\n    def encode_gated(\n        self, x: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n        sae_in = self.process_sae_in(x)\n\n        # Gating path\n        gating_pre_activation = sae_in @ self.W_enc + self.b_gate\n        active_features = (gating_pre_activation &gt; 0).to(self.dtype)\n\n        # Magnitude path with weight sharing\n        magnitude_pre_activation = self.hook_sae_acts_pre(\n            sae_in @ (self.W_enc * self.r_mag.exp()) + self.b_mag\n        )\n        feature_magnitudes = self.activation_fn(magnitude_pre_activation)\n\n        return self.hook_sae_acts_post(active_features * feature_magnitudes)\n\n    def encode_jumprelu(\n        self, x: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n        \"\"\"\n        Calculate SAE features from inputs\n        \"\"\"\n        sae_in = self.process_sae_in(x)\n\n        # \"... d_in, d_in d_sae -&gt; ... d_sae\",\n        hidden_pre = self.hook_sae_acts_pre(sae_in @ self.W_enc + self.b_enc)\n\n        return self.hook_sae_acts_post(\n            self.activation_fn(hidden_pre) * (hidden_pre &gt; self.threshold)\n        )\n\n    def encode_standard(\n        self, x: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n        \"\"\"\n        Calculate SAE features from inputs\n        \"\"\"\n        sae_in = self.process_sae_in(x)\n\n        # \"... d_in, d_in d_sae -&gt; ... d_sae\",\n        hidden_pre = self.hook_sae_acts_pre(sae_in @ self.W_enc + self.b_enc)\n        return self.hook_sae_acts_post(self.activation_fn(hidden_pre))\n\n    def process_sae_in(\n        self, sae_in: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n        sae_in = sae_in.to(self.dtype)\n        sae_in = self.reshape_fn_in(sae_in)\n        sae_in = self.hook_sae_input(sae_in)\n        sae_in = self.run_time_activation_norm_fn_in(sae_in)\n        return sae_in - (self.b_dec * self.cfg.apply_b_dec_to_input)\n\n    def decode(\n        self, feature_acts: Float[torch.Tensor, \"... d_sae\"]\n    ) -&gt; Float[torch.Tensor, \"... d_in\"]:\n        \"\"\"Decodes SAE feature activation tensor into a reconstructed input activation tensor.\"\"\"\n        # \"... d_sae, d_sae d_in -&gt; ... d_in\",\n        sae_out = self.hook_sae_recons(\n            self.apply_finetuning_scaling_factor(feature_acts) @ self.W_dec + self.b_dec\n        )\n\n        # handle run time activation normalization if needed\n        # will fail if you call this twice without calling encode in between.\n        sae_out = self.run_time_activation_norm_fn_out(sae_out)\n\n        # handle hook z reshaping if needed.\n        return self.reshape_fn_out(sae_out, self.d_head)  # type: ignore\n\n    @torch.no_grad()\n    def fold_W_dec_norm(self):\n        W_dec_norms = self.W_dec.norm(dim=-1).unsqueeze(1)\n        self.W_dec.data = self.W_dec.data / W_dec_norms\n        self.W_enc.data = self.W_enc.data * W_dec_norms.T\n        if self.cfg.architecture == \"gated\":\n            self.r_mag.data = self.r_mag.data * W_dec_norms.squeeze()\n            self.b_gate.data = self.b_gate.data * W_dec_norms.squeeze()\n            self.b_mag.data = self.b_mag.data * W_dec_norms.squeeze()\n        elif self.cfg.architecture == \"jumprelu\":\n            self.threshold.data = self.threshold.data * W_dec_norms.squeeze()\n            self.b_enc.data = self.b_enc.data * W_dec_norms.squeeze()\n        else:\n            self.b_enc.data = self.b_enc.data * W_dec_norms.squeeze()\n\n    @torch.no_grad()\n    def fold_activation_norm_scaling_factor(\n        self, activation_norm_scaling_factor: float\n    ):\n        self.W_enc.data = self.W_enc.data * activation_norm_scaling_factor\n        # previously weren't doing this.\n        self.W_dec.data = self.W_dec.data / activation_norm_scaling_factor\n        self.b_dec.data = self.b_dec.data / activation_norm_scaling_factor\n\n        # once we normalize, we shouldn't need to scale activations.\n        self.cfg.normalize_activations = \"none\"\n\n    @overload\n    def save_model(self, path: str | Path) -&gt; tuple[Path, Path]: ...\n\n    @overload\n    def save_model(\n        self, path: str | Path, sparsity: torch.Tensor\n    ) -&gt; tuple[Path, Path, Path]: ...\n\n    def save_model(self, path: str | Path, sparsity: torch.Tensor | None = None):\n        path = Path(path)\n\n        if not path.exists():\n            path.mkdir(parents=True)\n\n        # generate the weights\n        state_dict = self.state_dict()\n        self.process_state_dict_for_saving(state_dict)\n        model_weights_path = path / SAE_WEIGHTS_FILENAME\n        save_file(state_dict, model_weights_path)\n\n        # save the config\n        config = self.cfg.to_dict()\n\n        cfg_path = path / SAE_CFG_FILENAME\n        with open(cfg_path, \"w\") as f:\n            json.dump(config, f)\n\n        if sparsity is not None:\n            sparsity_in_dict = {\"sparsity\": sparsity}\n            sparsity_path = path / SPARSITY_FILENAME\n            save_file(sparsity_in_dict, sparsity_path)\n            return model_weights_path, cfg_path, sparsity_path\n\n        return model_weights_path, cfg_path\n\n    # overwrite this in subclasses to modify the state_dict in-place before saving\n    def process_state_dict_for_saving(self, state_dict: dict[str, Any]) -&gt; None:\n        pass\n\n    # overwrite this in subclasses to modify the state_dict in-place after loading\n    def process_state_dict_for_loading(self, state_dict: dict[str, Any]) -&gt; None:\n        pass\n\n    @classmethod\n    @deprecated(\"Use load_from_disk instead\")\n    def load_from_pretrained(\n        cls, path: str, device: str = \"cpu\", dtype: str | None = None\n    ) -&gt; \"SAE\":\n        sae = cls.load_from_disk(path, device)\n        if dtype is not None:\n            sae.cfg.dtype = dtype\n            sae = sae.to(dtype)\n        return sae\n\n    @classmethod\n    def load_from_disk(\n        cls,\n        path: str,\n        device: str = \"cpu\",\n        dtype: str | None = None,\n        converter: PretrainedSaeDiskLoader = sae_lens_disk_loader,\n    ) -&gt; \"SAE\":\n        overrides = {\"dtype\": dtype} if dtype is not None else None\n        cfg_dict, state_dict = converter(path, device, cfg_overrides=overrides)\n        cfg_dict = handle_config_defaulting(cfg_dict)\n        sae_cfg = SAEConfig.from_dict(cfg_dict)\n        sae = cls(sae_cfg)\n        sae.process_state_dict_for_loading(state_dict)\n        sae.load_state_dict(state_dict)\n        return sae\n\n    @classmethod\n    def from_pretrained(\n        cls,\n        release: str,\n        sae_id: str,\n        device: str = \"cpu\",\n        force_download: bool = False,\n        converter: PretrainedSaeHuggingfaceLoader | None = None,\n    ) -&gt; tuple[\"SAE\", dict[str, Any], torch.Tensor | None]:\n        \"\"\"\n        Load a pretrained SAE from the Hugging Face model hub.\n\n        Args:\n            release: The release name. This will be mapped to a huggingface repo id based on the pretrained_saes.yaml file.\n            id: The id of the SAE to load. This will be mapped to a path in the huggingface repo.\n            device: The device to load the SAE on.\n            return_sparsity_if_present: If True, will return the log sparsity tensor if it is present in the model directory in the Hugging Face model hub.\n        \"\"\"\n\n        # get sae directory\n        sae_directory = get_pretrained_saes_directory()\n\n        # get the repo id and path to the SAE\n        if release not in sae_directory:\n            if \"/\" not in release:\n                raise ValueError(\n                    f\"Release {release} not found in pretrained SAEs directory, and is not a valid huggingface repo.\"\n                )\n        elif sae_id not in sae_directory[release].saes_map:\n            # If using Gemma Scope and not the canonical release, give a hint to use it\n            if (\n                \"gemma-scope\" in release\n                and \"canonical\" not in release\n                and f\"{release}-canonical\" in sae_directory\n            ):\n                canonical_ids = list(\n                    sae_directory[release + \"-canonical\"].saes_map.keys()\n                )\n                # Shorten the lengthy string of valid IDs\n                if len(canonical_ids) &gt; 5:\n                    str_canonical_ids = str(canonical_ids[:5])[:-1] + \", ...]\"\n                else:\n                    str_canonical_ids = str(canonical_ids)\n                value_suffix = f\" If you don't want to specify an L0 value, consider using release {release}-canonical which has valid IDs {str_canonical_ids}\"\n            else:\n                value_suffix = \"\"\n\n            valid_ids = list(sae_directory[release].saes_map.keys())\n            # Shorten the lengthy string of valid IDs\n            if len(valid_ids) &gt; 5:\n                str_valid_ids = str(valid_ids[:5])[:-1] + \", ...]\"\n            else:\n                str_valid_ids = str(valid_ids)\n\n            raise ValueError(\n                f\"ID {sae_id} not found in release {release}. Valid IDs are {str_valid_ids}.\"\n                + value_suffix\n            )\n\n        conversion_loader = (\n            converter\n            or NAMED_PRETRAINED_SAE_LOADERS[get_conversion_loader_name(release)]\n        )\n        repo_id, folder_name = get_repo_id_and_folder_name(release, sae_id)\n        config_overrides = get_config_overrides(release, sae_id)\n        config_overrides[\"device\"] = device\n\n        cfg_dict, state_dict, log_sparsities = conversion_loader(\n            repo_id=repo_id,\n            folder_name=folder_name,\n            device=device,\n            force_download=force_download,\n            cfg_overrides=config_overrides,\n        )\n        cfg_dict = handle_config_defaulting(cfg_dict)\n\n        sae = cls(SAEConfig.from_dict(cfg_dict))\n        sae.process_state_dict_for_loading(state_dict)\n        sae.load_state_dict(state_dict)\n\n        # Check if normalization is 'expected_average_only_in'\n        if cfg_dict.get(\"normalize_activations\") == \"expected_average_only_in\":\n            norm_scaling_factor = get_norm_scaling_factor(release, sae_id)\n            if norm_scaling_factor is not None:\n                sae.fold_activation_norm_scaling_factor(norm_scaling_factor)\n                cfg_dict[\"normalize_activations\"] = \"none\"\n            else:\n                warnings.warn(\n                    f\"norm_scaling_factor not found for {release} and {sae_id}, but normalize_activations is 'expected_average_only_in'. Skipping normalization folding.\"\n                )\n\n        return sae, cfg_dict, log_sparsities\n\n    def get_name(self):\n        return f\"sae_{self.cfg.model_name}_{self.cfg.hook_name}_{self.cfg.d_sae}\"\n\n    @classmethod\n    def from_dict(cls, config_dict: dict[str, Any]) -&gt; \"SAE\":\n        return cls(SAEConfig.from_dict(config_dict))\n\n    def turn_on_forward_pass_hook_z_reshaping(self):\n        if not self.cfg.hook_name.endswith(\"_z\"):\n            raise ValueError(\"This method should only be called for hook_z SAEs.\")\n\n        def reshape_fn_in(x: torch.Tensor):\n            self.d_head = x.shape[-1]  # type: ignore\n            self.reshape_fn_in = lambda x: einops.rearrange(\n                x, \"... n_heads d_head -&gt; ... (n_heads d_head)\"\n            )\n            return einops.rearrange(x, \"... n_heads d_head -&gt; ... (n_heads d_head)\")\n\n        self.reshape_fn_in = reshape_fn_in\n\n        self.reshape_fn_out = lambda x, d_head: einops.rearrange(\n            x, \"... (n_heads d_head) -&gt; ... n_heads d_head\", d_head=d_head\n        )\n        self.hook_z_reshaping_mode = True\n\n    def turn_off_forward_pass_hook_z_reshaping(self):\n        self.reshape_fn_in = lambda x: x\n        self.reshape_fn_out = lambda x, d_head: x  # noqa: ARG005\n        self.d_head = None\n        self.hook_z_reshaping_mode = False\n</code></pre>"},{"location":"api/#sae_lens.SAE.decode","title":"<code>decode(feature_acts)</code>","text":"<p>Decodes SAE feature activation tensor into a reconstructed input activation tensor.</p> Source code in <code>sae_lens/sae.py</code> <pre><code>def decode(\n    self, feature_acts: Float[torch.Tensor, \"... d_sae\"]\n) -&gt; Float[torch.Tensor, \"... d_in\"]:\n    \"\"\"Decodes SAE feature activation tensor into a reconstructed input activation tensor.\"\"\"\n    # \"... d_sae, d_sae d_in -&gt; ... d_in\",\n    sae_out = self.hook_sae_recons(\n        self.apply_finetuning_scaling_factor(feature_acts) @ self.W_dec + self.b_dec\n    )\n\n    # handle run time activation normalization if needed\n    # will fail if you call this twice without calling encode in between.\n    sae_out = self.run_time_activation_norm_fn_out(sae_out)\n\n    # handle hook z reshaping if needed.\n    return self.reshape_fn_out(sae_out, self.d_head)  # type: ignore\n</code></pre>"},{"location":"api/#sae_lens.SAE.encode_jumprelu","title":"<code>encode_jumprelu(x)</code>","text":"<p>Calculate SAE features from inputs</p> Source code in <code>sae_lens/sae.py</code> <pre><code>def encode_jumprelu(\n    self, x: Float[torch.Tensor, \"... d_in\"]\n) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n    \"\"\"\n    Calculate SAE features from inputs\n    \"\"\"\n    sae_in = self.process_sae_in(x)\n\n    # \"... d_in, d_in d_sae -&gt; ... d_sae\",\n    hidden_pre = self.hook_sae_acts_pre(sae_in @ self.W_enc + self.b_enc)\n\n    return self.hook_sae_acts_post(\n        self.activation_fn(hidden_pre) * (hidden_pre &gt; self.threshold)\n    )\n</code></pre>"},{"location":"api/#sae_lens.SAE.encode_standard","title":"<code>encode_standard(x)</code>","text":"<p>Calculate SAE features from inputs</p> Source code in <code>sae_lens/sae.py</code> <pre><code>def encode_standard(\n    self, x: Float[torch.Tensor, \"... d_in\"]\n) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n    \"\"\"\n    Calculate SAE features from inputs\n    \"\"\"\n    sae_in = self.process_sae_in(x)\n\n    # \"... d_in, d_in d_sae -&gt; ... d_sae\",\n    hidden_pre = self.hook_sae_acts_pre(sae_in @ self.W_enc + self.b_enc)\n    return self.hook_sae_acts_post(self.activation_fn(hidden_pre))\n</code></pre>"},{"location":"api/#sae_lens.SAE.from_pretrained","title":"<code>from_pretrained(release, sae_id, device='cpu', force_download=False, converter=None)</code>  <code>classmethod</code>","text":"<p>Load a pretrained SAE from the Hugging Face model hub.</p> <p>Parameters:</p> Name Type Description Default <code>release</code> <code>str</code> <p>The release name. This will be mapped to a huggingface repo id based on the pretrained_saes.yaml file.</p> required <code>id</code> <p>The id of the SAE to load. This will be mapped to a path in the huggingface repo.</p> required <code>device</code> <code>str</code> <p>The device to load the SAE on.</p> <code>'cpu'</code> <code>return_sparsity_if_present</code> <p>If True, will return the log sparsity tensor if it is present in the model directory in the Hugging Face model hub.</p> required Source code in <code>sae_lens/sae.py</code> <pre><code>@classmethod\ndef from_pretrained(\n    cls,\n    release: str,\n    sae_id: str,\n    device: str = \"cpu\",\n    force_download: bool = False,\n    converter: PretrainedSaeHuggingfaceLoader | None = None,\n) -&gt; tuple[\"SAE\", dict[str, Any], torch.Tensor | None]:\n    \"\"\"\n    Load a pretrained SAE from the Hugging Face model hub.\n\n    Args:\n        release: The release name. This will be mapped to a huggingface repo id based on the pretrained_saes.yaml file.\n        id: The id of the SAE to load. This will be mapped to a path in the huggingface repo.\n        device: The device to load the SAE on.\n        return_sparsity_if_present: If True, will return the log sparsity tensor if it is present in the model directory in the Hugging Face model hub.\n    \"\"\"\n\n    # get sae directory\n    sae_directory = get_pretrained_saes_directory()\n\n    # get the repo id and path to the SAE\n    if release not in sae_directory:\n        if \"/\" not in release:\n            raise ValueError(\n                f\"Release {release} not found in pretrained SAEs directory, and is not a valid huggingface repo.\"\n            )\n    elif sae_id not in sae_directory[release].saes_map:\n        # If using Gemma Scope and not the canonical release, give a hint to use it\n        if (\n            \"gemma-scope\" in release\n            and \"canonical\" not in release\n            and f\"{release}-canonical\" in sae_directory\n        ):\n            canonical_ids = list(\n                sae_directory[release + \"-canonical\"].saes_map.keys()\n            )\n            # Shorten the lengthy string of valid IDs\n            if len(canonical_ids) &gt; 5:\n                str_canonical_ids = str(canonical_ids[:5])[:-1] + \", ...]\"\n            else:\n                str_canonical_ids = str(canonical_ids)\n            value_suffix = f\" If you don't want to specify an L0 value, consider using release {release}-canonical which has valid IDs {str_canonical_ids}\"\n        else:\n            value_suffix = \"\"\n\n        valid_ids = list(sae_directory[release].saes_map.keys())\n        # Shorten the lengthy string of valid IDs\n        if len(valid_ids) &gt; 5:\n            str_valid_ids = str(valid_ids[:5])[:-1] + \", ...]\"\n        else:\n            str_valid_ids = str(valid_ids)\n\n        raise ValueError(\n            f\"ID {sae_id} not found in release {release}. Valid IDs are {str_valid_ids}.\"\n            + value_suffix\n        )\n\n    conversion_loader = (\n        converter\n        or NAMED_PRETRAINED_SAE_LOADERS[get_conversion_loader_name(release)]\n    )\n    repo_id, folder_name = get_repo_id_and_folder_name(release, sae_id)\n    config_overrides = get_config_overrides(release, sae_id)\n    config_overrides[\"device\"] = device\n\n    cfg_dict, state_dict, log_sparsities = conversion_loader(\n        repo_id=repo_id,\n        folder_name=folder_name,\n        device=device,\n        force_download=force_download,\n        cfg_overrides=config_overrides,\n    )\n    cfg_dict = handle_config_defaulting(cfg_dict)\n\n    sae = cls(SAEConfig.from_dict(cfg_dict))\n    sae.process_state_dict_for_loading(state_dict)\n    sae.load_state_dict(state_dict)\n\n    # Check if normalization is 'expected_average_only_in'\n    if cfg_dict.get(\"normalize_activations\") == \"expected_average_only_in\":\n        norm_scaling_factor = get_norm_scaling_factor(release, sae_id)\n        if norm_scaling_factor is not None:\n            sae.fold_activation_norm_scaling_factor(norm_scaling_factor)\n            cfg_dict[\"normalize_activations\"] = \"none\"\n        else:\n            warnings.warn(\n                f\"norm_scaling_factor not found for {release} and {sae_id}, but normalize_activations is 'expected_average_only_in'. Skipping normalization folding.\"\n            )\n\n    return sae, cfg_dict, log_sparsities\n</code></pre>"},{"location":"api/#sae_lens.SAETrainingRunner","title":"<code>SAETrainingRunner</code>","text":"<p>Class to run the training of a Sparse Autoencoder (SAE) on a TransformerLens model.</p> Source code in <code>sae_lens/sae_training_runner.py</code> <pre><code>class SAETrainingRunner:\n    \"\"\"\n    Class to run the training of a Sparse Autoencoder (SAE) on a TransformerLens model.\n    \"\"\"\n\n    cfg: LanguageModelSAERunnerConfig\n    model: HookedRootModule\n    sae: TrainingSAE\n    activations_store: ActivationsStore\n\n    def __init__(\n        self,\n        cfg: LanguageModelSAERunnerConfig,\n        override_dataset: HfDataset | None = None,\n        override_model: HookedRootModule | None = None,\n        override_sae: TrainingSAE | None = None,\n    ):\n        if override_dataset is not None:\n            logger.warning(\n                f\"You just passed in a dataset which will override the one specified in your configuration: {cfg.dataset_path}. As a consequence this run will not be reproducible via configuration alone.\"\n            )\n        if override_model is not None:\n            logger.warning(\n                f\"You just passed in a model which will override the one specified in your configuration: {cfg.model_name}. As a consequence this run will not be reproducible via configuration alone.\"\n            )\n\n        self.cfg = cfg\n\n        if override_model is None:\n            self.model = load_model(\n                self.cfg.model_class_name,\n                self.cfg.model_name,\n                device=self.cfg.device,\n                model_from_pretrained_kwargs=self.cfg.model_from_pretrained_kwargs,\n            )\n        else:\n            self.model = override_model\n\n        self.activations_store = ActivationsStore.from_config(\n            self.model,\n            self.cfg,\n            override_dataset=override_dataset,\n        )\n\n        if override_sae is None:\n            if self.cfg.from_pretrained_path is not None:\n                self.sae = TrainingSAE.load_from_pretrained(\n                    self.cfg.from_pretrained_path, self.cfg.device\n                )\n            else:\n                self.sae = TrainingSAE(\n                    TrainingSAEConfig.from_dict(\n                        self.cfg.get_training_sae_cfg_dict(),\n                    )\n                )\n                self._init_sae_group_b_decs()\n        else:\n            self.sae = override_sae\n\n    def run(self):\n        \"\"\"\n        Run the training of the SAE.\n        \"\"\"\n\n        if self.cfg.log_to_wandb:\n            wandb.init(\n                project=self.cfg.wandb_project,\n                entity=self.cfg.wandb_entity,\n                config=cast(Any, self.cfg),\n                name=self.cfg.run_name,\n                id=self.cfg.wandb_id,\n            )\n\n        trainer = SAETrainer(\n            model=self.model,\n            sae=self.sae,\n            activation_store=self.activations_store,\n            save_checkpoint_fn=self.save_checkpoint,\n            cfg=self.cfg,\n        )\n\n        self._compile_if_needed()\n        sae = self.run_trainer_with_interruption_handling(trainer)\n\n        if self.cfg.log_to_wandb:\n            wandb.finish()\n\n        return sae\n\n    def _compile_if_needed(self):\n        # Compile model and SAE\n        #  torch.compile can provide significant speedups (10-20% in testing)\n        # using max-autotune gives the best speedups but:\n        # (a) increases VRAM usage,\n        # (b) can't be used on both SAE and LM (some issue with cudagraphs), and\n        # (c) takes some time to compile\n        # optimal settings seem to be:\n        # use max-autotune on SAE and max-autotune-no-cudagraphs on LM\n        # (also pylance seems to really hate this)\n        if self.cfg.compile_llm:\n            self.model = torch.compile(\n                self.model,\n                mode=self.cfg.llm_compilation_mode,\n            )  # type: ignore\n\n        if self.cfg.compile_sae:\n            backend = \"aot_eager\" if self.cfg.device == \"mps\" else \"inductor\"\n\n            self.sae.training_forward_pass = torch.compile(  # type: ignore\n                self.sae.training_forward_pass,\n                mode=self.cfg.sae_compilation_mode,\n                backend=backend,\n            )  # type: ignore\n\n    def run_trainer_with_interruption_handling(self, trainer: SAETrainer):\n        try:\n            # signal handlers (if preempted)\n            signal.signal(signal.SIGINT, interrupt_callback)\n            signal.signal(signal.SIGTERM, interrupt_callback)\n\n            # train SAE\n            sae = trainer.fit()\n\n        except (KeyboardInterrupt, InterruptedException):\n            logger.warning(\"interrupted, saving progress\")\n            checkpoint_name = str(trainer.n_training_tokens)\n            self.save_checkpoint(trainer, checkpoint_name=checkpoint_name)\n            logger.info(\"done saving\")\n            raise\n\n        return sae\n\n    # TODO: move this into the SAE trainer or Training SAE class\n    def _init_sae_group_b_decs(\n        self,\n    ) -&gt; None:\n        \"\"\"\n        extract all activations at a certain layer and use for sae b_dec initialization\n        \"\"\"\n\n        if self.cfg.b_dec_init_method == \"geometric_median\":\n            self.activations_store.set_norm_scaling_factor_if_needed()\n            layer_acts = self.activations_store.storage_buffer.detach()[:, 0, :]\n            # get geometric median of the activations if we're using those.\n            median = compute_geometric_median(\n                layer_acts,\n                maxiter=100,\n            ).median\n            self.sae.initialize_b_dec_with_precalculated(median)  # type: ignore\n        elif self.cfg.b_dec_init_method == \"mean\":\n            self.activations_store.set_norm_scaling_factor_if_needed()\n            layer_acts = self.activations_store.storage_buffer.detach().cpu()[:, 0, :]\n            self.sae.initialize_b_dec_with_mean(layer_acts)  # type: ignore\n\n    @staticmethod\n    def save_checkpoint(\n        trainer: SAETrainer,\n        checkpoint_name: str,\n        wandb_aliases: list[str] | None = None,\n    ) -&gt; None:\n        base_path = Path(trainer.cfg.checkpoint_path) / checkpoint_name\n        base_path.mkdir(exist_ok=True, parents=True)\n\n        trainer.activations_store.save(\n            str(base_path / \"activations_store_state.safetensors\")\n        )\n\n        if trainer.sae.cfg.normalize_sae_decoder:\n            trainer.sae.set_decoder_norm_to_unit_norm()\n\n        weights_path, cfg_path, sparsity_path = trainer.sae.save_model(\n            str(base_path),\n            trainer.log_feature_sparsity,\n        )\n\n        # let's over write the cfg file with the trainer cfg, which is a super set of the original cfg.\n        # and should not cause issues but give us more info about SAEs we trained in SAE Lens.\n        config = trainer.cfg.to_dict()\n        with open(cfg_path, \"w\") as f:\n            json.dump(config, f)\n\n        if trainer.cfg.log_to_wandb:\n            # Avoid wandb saving errors such as:\n            #   ValueError: Artifact name may only contain alphanumeric characters, dashes, underscores, and dots. Invalid name: sae_google/gemma-2b_etc\n            sae_name = trainer.sae.get_name().replace(\"/\", \"__\")\n\n            # save model weights and cfg\n            model_artifact = wandb.Artifact(\n                sae_name,\n                type=\"model\",\n                metadata=dict(trainer.cfg.__dict__),\n            )\n            model_artifact.add_file(str(weights_path))\n            model_artifact.add_file(str(cfg_path))\n            wandb.log_artifact(model_artifact, aliases=wandb_aliases)\n\n            # save log feature sparsity\n            sparsity_artifact = wandb.Artifact(\n                f\"{sae_name}_log_feature_sparsity\",\n                type=\"log_feature_sparsity\",\n                metadata=dict(trainer.cfg.__dict__),\n            )\n            sparsity_artifact.add_file(str(sparsity_path))\n            wandb.log_artifact(sparsity_artifact)\n</code></pre>"},{"location":"api/#sae_lens.SAETrainingRunner.run","title":"<code>run()</code>","text":"<p>Run the training of the SAE.</p> Source code in <code>sae_lens/sae_training_runner.py</code> <pre><code>def run(self):\n    \"\"\"\n    Run the training of the SAE.\n    \"\"\"\n\n    if self.cfg.log_to_wandb:\n        wandb.init(\n            project=self.cfg.wandb_project,\n            entity=self.cfg.wandb_entity,\n            config=cast(Any, self.cfg),\n            name=self.cfg.run_name,\n            id=self.cfg.wandb_id,\n        )\n\n    trainer = SAETrainer(\n        model=self.model,\n        sae=self.sae,\n        activation_store=self.activations_store,\n        save_checkpoint_fn=self.save_checkpoint,\n        cfg=self.cfg,\n    )\n\n    self._compile_if_needed()\n    sae = self.run_trainer_with_interruption_handling(trainer)\n\n    if self.cfg.log_to_wandb:\n        wandb.finish()\n\n    return sae\n</code></pre>"},{"location":"api/#sae_lens.TrainingSAE","title":"<code>TrainingSAE</code>","text":"<p>               Bases: <code>SAE</code></p> <p>A SAE used for training. This class provides a <code>training_forward_pass</code> method which calculates losses used for training.</p> Source code in <code>sae_lens/training/training_sae.py</code> <pre><code>class TrainingSAE(SAE):\n    \"\"\"\n    A SAE used for training. This class provides a `training_forward_pass` method which calculates\n    losses used for training.\n    \"\"\"\n\n    cfg: TrainingSAEConfig\n    use_error_term: bool\n    dtype: torch.dtype\n    device: torch.device\n\n    def __init__(self, cfg: TrainingSAEConfig, use_error_term: bool = False):\n        base_sae_cfg = SAEConfig.from_dict(cfg.get_base_sae_cfg_dict())\n        super().__init__(base_sae_cfg)\n        self.cfg = cfg  # type: ignore\n\n        if cfg.architecture == \"standard\" or cfg.architecture == \"topk\":\n            self.encode_with_hidden_pre_fn = self.encode_with_hidden_pre\n        elif cfg.architecture == \"gated\":\n            self.encode_with_hidden_pre_fn = self.encode_with_hidden_pre_gated\n        elif cfg.architecture == \"jumprelu\":\n            self.encode_with_hidden_pre_fn = self.encode_with_hidden_pre_jumprelu\n            self.bandwidth = cfg.jumprelu_bandwidth\n            self.log_threshold.data = torch.ones(\n                self.cfg.d_sae, dtype=self.dtype, device=self.device\n            ) * np.log(cfg.jumprelu_init_threshold)\n\n        else:\n            raise ValueError(f\"Unknown architecture: {cfg.architecture}\")\n\n        self.check_cfg_compatibility()\n\n        self.use_error_term = use_error_term\n\n        self.initialize_weights_complex()\n\n        # The training SAE will assume that the activation store handles\n        # reshaping.\n        self.turn_off_forward_pass_hook_z_reshaping()\n\n        self.mse_loss_fn = self._get_mse_loss_fn()\n\n    def initialize_weights_jumprelu(self):\n        # same as the superclass, except we use a log_threshold parameter instead of threshold\n        self.log_threshold = nn.Parameter(\n            torch.empty(self.cfg.d_sae, dtype=self.dtype, device=self.device)\n        )\n        self.initialize_weights_basic()\n\n    @property\n    def threshold(self) -&gt; torch.Tensor:\n        if self.cfg.architecture != \"jumprelu\":\n            raise ValueError(\"Threshold is only defined for Jumprelu SAEs\")\n        return torch.exp(self.log_threshold)\n\n    @classmethod\n    def from_dict(cls, config_dict: dict[str, Any]) -&gt; \"TrainingSAE\":\n        return cls(TrainingSAEConfig.from_dict(config_dict))\n\n    def check_cfg_compatibility(self):\n        if self.cfg.architecture != \"standard\" and self.cfg.use_ghost_grads:\n            raise ValueError(f\"{self.cfg.architecture} SAEs do not support ghost grads\")\n        if self.cfg.architecture == \"gated\" and self.use_error_term:\n            raise ValueError(\"Gated SAEs do not support error terms\")\n\n    def encode_standard(\n        self, x: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n        \"\"\"\n        Calcuate SAE features from inputs\n        \"\"\"\n        feature_acts, _ = self.encode_with_hidden_pre_fn(x)\n        return feature_acts\n\n    def encode_with_hidden_pre_jumprelu(\n        self, x: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; tuple[Float[torch.Tensor, \"... d_sae\"], Float[torch.Tensor, \"... d_sae\"]]:\n        sae_in = self.process_sae_in(x)\n\n        hidden_pre = sae_in @ self.W_enc + self.b_enc\n\n        if self.training:\n            hidden_pre = (\n                hidden_pre + torch.randn_like(hidden_pre) * self.cfg.noise_scale\n            )\n\n        threshold = torch.exp(self.log_threshold)\n\n        feature_acts = JumpReLU.apply(hidden_pre, threshold, self.bandwidth)\n\n        return feature_acts, hidden_pre  # type: ignore\n\n    def encode_with_hidden_pre(\n        self, x: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; tuple[Float[torch.Tensor, \"... d_sae\"], Float[torch.Tensor, \"... d_sae\"]]:\n        sae_in = self.process_sae_in(x)\n\n        # \"... d_in, d_in d_sae -&gt; ... d_sae\",\n        hidden_pre = self.hook_sae_acts_pre(sae_in @ self.W_enc + self.b_enc)\n        hidden_pre_noised = hidden_pre + (\n            torch.randn_like(hidden_pre) * self.cfg.noise_scale * self.training\n        )\n        feature_acts = self.hook_sae_acts_post(self.activation_fn(hidden_pre_noised))\n\n        return feature_acts, hidden_pre_noised\n\n    def encode_with_hidden_pre_gated(\n        self, x: Float[torch.Tensor, \"... d_in\"]\n    ) -&gt; tuple[Float[torch.Tensor, \"... d_sae\"], Float[torch.Tensor, \"... d_sae\"]]:\n        sae_in = self.process_sae_in(x)\n\n        # Gating path with Heaviside step function\n        gating_pre_activation = sae_in @ self.W_enc + self.b_gate\n        active_features = (gating_pre_activation &gt; 0).to(self.dtype)\n\n        # Magnitude path with weight sharing\n        magnitude_pre_activation = sae_in @ (self.W_enc * self.r_mag.exp()) + self.b_mag\n        # magnitude_pre_activation_noised = magnitude_pre_activation + (\n        #     torch.randn_like(magnitude_pre_activation) * self.cfg.noise_scale * self.training\n        # )\n        feature_magnitudes = self.activation_fn(\n            magnitude_pre_activation\n        )  # magnitude_pre_activation_noised)\n\n        # Return both the gated feature activations and the magnitude pre-activations\n        return (\n            active_features * feature_magnitudes,\n            magnitude_pre_activation,\n        )  # magnitude_pre_activation_noised\n\n    def forward(\n        self,\n        x: Float[torch.Tensor, \"... d_in\"],\n    ) -&gt; Float[torch.Tensor, \"... d_in\"]:\n        feature_acts, _ = self.encode_with_hidden_pre_fn(x)\n        return self.decode(feature_acts)\n\n    def training_forward_pass(\n        self,\n        sae_in: torch.Tensor,\n        current_l1_coefficient: float,\n        dead_neuron_mask: torch.Tensor | None = None,\n    ) -&gt; TrainStepOutput:\n        # do a forward pass to get SAE out, but we also need the\n        # hidden pre.\n        feature_acts, hidden_pre = self.encode_with_hidden_pre_fn(sae_in)\n        sae_out = self.decode(feature_acts)\n\n        # MSE LOSS\n        per_item_mse_loss = self.mse_loss_fn(sae_out, sae_in)\n        mse_loss = per_item_mse_loss.sum(dim=-1).mean()\n\n        losses: dict[str, float | torch.Tensor] = {}\n\n        if self.cfg.architecture == \"gated\":\n            # Gated SAE Loss Calculation\n\n            # Shared variables\n            sae_in_centered = (\n                self.reshape_fn_in(sae_in) - self.b_dec * self.cfg.apply_b_dec_to_input\n            )\n            pi_gate = sae_in_centered @ self.W_enc + self.b_gate\n            pi_gate_act = torch.relu(pi_gate)\n\n            # SFN sparsity loss - summed over the feature dimension and averaged over the batch\n            l1_loss = (\n                current_l1_coefficient\n                * torch.sum(pi_gate_act * self.W_dec.norm(dim=1), dim=-1).mean()\n            )\n\n            # Auxiliary reconstruction loss - summed over the feature dimension and averaged over the batch\n            via_gate_reconstruction = pi_gate_act @ self.W_dec + self.b_dec\n            aux_reconstruction_loss = torch.sum(\n                (via_gate_reconstruction - sae_in) ** 2, dim=-1\n            ).mean()\n            loss = mse_loss + l1_loss + aux_reconstruction_loss\n            losses[\"auxiliary_reconstruction_loss\"] = aux_reconstruction_loss\n            losses[\"l1_loss\"] = l1_loss\n        elif self.cfg.architecture == \"jumprelu\":\n            threshold = torch.exp(self.log_threshold)\n            l0 = torch.sum(Step.apply(hidden_pre, threshold, self.bandwidth), dim=-1)  # type: ignore\n            l0_loss = (current_l1_coefficient * l0).mean()\n            loss = mse_loss + l0_loss\n            losses[\"l0_loss\"] = l0_loss\n        elif self.cfg.architecture == \"topk\":\n            topk_loss = self.calculate_topk_aux_loss(\n                sae_in=sae_in,\n                sae_out=sae_out,\n                hidden_pre=hidden_pre,\n                dead_neuron_mask=dead_neuron_mask,\n            )\n            losses[\"auxiliary_reconstruction_loss\"] = topk_loss\n            loss = mse_loss + topk_loss\n        else:\n            # default SAE sparsity loss\n            weighted_feature_acts = feature_acts\n            if self.cfg.scale_sparsity_penalty_by_decoder_norm:\n                weighted_feature_acts = feature_acts * self.W_dec.norm(dim=1)\n            sparsity = weighted_feature_acts.norm(\n                p=self.cfg.lp_norm, dim=-1\n            )  # sum over the feature dimension\n\n            l1_loss = (current_l1_coefficient * sparsity).mean()\n            loss = mse_loss + l1_loss\n            if (\n                self.cfg.use_ghost_grads\n                and self.training\n                and dead_neuron_mask is not None\n            ):\n                ghost_grad_loss = self.calculate_ghost_grad_loss(\n                    x=sae_in,\n                    sae_out=sae_out,\n                    per_item_mse_loss=per_item_mse_loss,\n                    hidden_pre=hidden_pre,\n                    dead_neuron_mask=dead_neuron_mask,\n                )\n                losses[\"ghost_grad_loss\"] = ghost_grad_loss\n                loss = loss + ghost_grad_loss\n            losses[\"l1_loss\"] = l1_loss\n\n        losses[\"mse_loss\"] = mse_loss\n\n        return TrainStepOutput(\n            sae_in=sae_in,\n            sae_out=sae_out,\n            feature_acts=feature_acts,\n            hidden_pre=hidden_pre,\n            loss=loss,\n            losses=losses,\n        )\n\n    def calculate_topk_aux_loss(\n        self,\n        sae_in: torch.Tensor,\n        sae_out: torch.Tensor,\n        hidden_pre: torch.Tensor,\n        dead_neuron_mask: torch.Tensor | None,\n    ) -&gt; torch.Tensor:\n        # Mostly taken from https://github.com/EleutherAI/sae/blob/main/sae/sae.py, except without variance normalization\n        # NOTE: checking the number of dead neurons will force a GPU sync, so performance can likely be improved here\n        if dead_neuron_mask is None or (num_dead := int(dead_neuron_mask.sum())) == 0:\n            return sae_out.new_tensor(0.0)\n        residual = (sae_in - sae_out).detach()\n\n        # Heuristic from Appendix B.1 in the paper\n        k_aux = sae_in.shape[-1] // 2\n\n        # Reduce the scale of the loss if there are a small number of dead latents\n        scale = min(num_dead / k_aux, 1.0)\n        k_aux = min(k_aux, num_dead)\n\n        auxk_acts = _calculate_topk_aux_acts(\n            k_aux=k_aux,\n            hidden_pre=hidden_pre,\n            dead_neuron_mask=dead_neuron_mask,\n        )\n\n        # Encourage the top ~50% of dead latents to predict the residual of the\n        # top k living latents\n        recons = self.decode(auxk_acts)\n        auxk_loss = (recons - residual).pow(2).sum(dim=-1).mean()\n        return scale * auxk_loss\n\n    def calculate_ghost_grad_loss(\n        self,\n        x: torch.Tensor,\n        sae_out: torch.Tensor,\n        per_item_mse_loss: torch.Tensor,\n        hidden_pre: torch.Tensor,\n        dead_neuron_mask: torch.Tensor,\n    ) -&gt; torch.Tensor:\n        # 1.\n        residual = x - sae_out\n        l2_norm_residual = torch.norm(residual, dim=-1)\n\n        # 2.\n        # ghost grads use an exponentional activation function, ignoring whatever\n        # the activation function is in the SAE. The forward pass uses the dead neurons only.\n        feature_acts_dead_neurons_only = torch.exp(hidden_pre[:, dead_neuron_mask])\n        ghost_out = feature_acts_dead_neurons_only @ self.W_dec[dead_neuron_mask, :]\n        l2_norm_ghost_out = torch.norm(ghost_out, dim=-1)\n        norm_scaling_factor = l2_norm_residual / (1e-6 + l2_norm_ghost_out * 2)\n        ghost_out = ghost_out * norm_scaling_factor[:, None].detach()\n\n        # 3. There is some fairly complex rescaling here to make sure that the loss\n        # is comparable to the original loss. This is because the ghost grads are\n        # only calculated for the dead neurons, so we need to rescale the loss to\n        # make sure that the loss is comparable to the original loss.\n        # There have been methodological improvements that are not implemented here yet\n        # see here: https://www.lesswrong.com/posts/C5KAZQib3bzzpeyrg/full-post-progress-update-1-from-the-gdm-mech-interp-team#Improving_ghost_grads\n        per_item_mse_loss_ghost_resid = self.mse_loss_fn(ghost_out, residual.detach())\n        mse_rescaling_factor = (\n            per_item_mse_loss / (per_item_mse_loss_ghost_resid + 1e-6)\n        ).detach()\n        per_item_mse_loss_ghost_resid = (\n            mse_rescaling_factor * per_item_mse_loss_ghost_resid\n        )\n\n        return per_item_mse_loss_ghost_resid.mean()\n\n    @torch.no_grad()\n    def _get_mse_loss_fn(self) -&gt; Any:\n        def standard_mse_loss_fn(\n            preds: torch.Tensor, target: torch.Tensor\n        ) -&gt; torch.Tensor:\n            return torch.nn.functional.mse_loss(preds, target, reduction=\"none\")\n\n        def batch_norm_mse_loss_fn(\n            preds: torch.Tensor, target: torch.Tensor\n        ) -&gt; torch.Tensor:\n            target_centered = target - target.mean(dim=0, keepdim=True)\n            normalization = target_centered.norm(dim=-1, keepdim=True)\n            return torch.nn.functional.mse_loss(preds, target, reduction=\"none\") / (\n                normalization + 1e-6\n            )\n\n        if self.cfg.mse_loss_normalization == \"dense_batch\":\n            return batch_norm_mse_loss_fn\n        return standard_mse_loss_fn\n\n    def process_state_dict_for_saving(self, state_dict: dict[str, Any]) -&gt; None:\n        if self.cfg.architecture == \"jumprelu\" and \"log_threshold\" in state_dict:\n            threshold = torch.exp(state_dict[\"log_threshold\"]).detach().contiguous()\n            del state_dict[\"log_threshold\"]\n            state_dict[\"threshold\"] = threshold\n\n    def process_state_dict_for_loading(self, state_dict: dict[str, Any]) -&gt; None:\n        if self.cfg.architecture == \"jumprelu\" and \"threshold\" in state_dict:\n            threshold = state_dict[\"threshold\"]\n            del state_dict[\"threshold\"]\n            state_dict[\"log_threshold\"] = torch.log(threshold).detach().contiguous()\n\n    @classmethod\n    @deprecated(\"Use load_from_disk instead\")\n    def load_from_pretrained(\n        cls, path: str, device: str = \"cpu\", dtype: str | None = None\n    ) -&gt; \"TrainingSAE\":\n        return cls.load_from_disk(path, device, dtype)\n\n    @classmethod\n    def load_from_disk(\n        cls,\n        path: str,\n        device: str = \"cpu\",\n        dtype: str | None = None,\n        converter: PretrainedSaeDiskLoader = sae_lens_disk_loader,\n    ) -&gt; \"TrainingSAE\":\n        overrides = {\"dtype\": dtype} if dtype is not None else None\n        cfg_dict, state_dict = converter(path, device, cfg_overrides=overrides)\n        cfg_dict = handle_config_defaulting(cfg_dict)\n        sae_cfg = TrainingSAEConfig.from_dict(cfg_dict)\n        sae = cls(sae_cfg)\n        sae.process_state_dict_for_loading(state_dict)\n        sae.load_state_dict(state_dict)\n        return sae\n\n    def initialize_weights_complex(self):\n        \"\"\" \"\"\"\n\n        if self.cfg.decoder_orthogonal_init:\n            self.W_dec.data = nn.init.orthogonal_(self.W_dec.data.T).T\n\n        elif self.cfg.decoder_heuristic_init:\n            self.W_dec = nn.Parameter(\n                torch.randn(\n                    self.cfg.d_sae, self.cfg.d_in, dtype=self.dtype, device=self.device\n                )\n            )\n            self.initialize_decoder_norm_constant_norm(\n                self.cfg.decoder_heuristic_init_norm\n            )\n\n        # Then we initialize the encoder weights (either as the transpose of decoder or not)\n        if self.cfg.init_encoder_as_decoder_transpose:\n            self.W_enc.data = self.W_dec.data.T.clone().contiguous()\n        else:\n            self.W_enc = nn.Parameter(\n                torch.nn.init.kaiming_uniform_(\n                    torch.empty(\n                        self.cfg.d_in,\n                        self.cfg.d_sae,\n                        dtype=self.dtype,\n                        device=self.device,\n                    )\n                )\n            )\n\n        if self.cfg.normalize_sae_decoder:\n            with torch.no_grad():\n                # Anthropic normalize this to have unit columns\n                self.set_decoder_norm_to_unit_norm()\n\n    @torch.no_grad()\n    def fold_W_dec_norm(self):\n        # need to deal with the jumprelu having a log_threshold in training\n        if self.cfg.architecture == \"jumprelu\":\n            cur_threshold = self.threshold.clone()\n            W_dec_norms = self.W_dec.norm(dim=-1).unsqueeze(1)\n            super().fold_W_dec_norm()\n            self.log_threshold.data = torch.log(cur_threshold * W_dec_norms.squeeze())\n        else:\n            super().fold_W_dec_norm()\n\n    ## Initialization Methods\n    @torch.no_grad()\n    def initialize_b_dec_with_precalculated(self, origin: torch.Tensor):\n        out = torch.tensor(origin, dtype=self.dtype, device=self.device)\n        self.b_dec.data = out\n\n    @torch.no_grad()\n    def initialize_b_dec_with_mean(self, all_activations: torch.Tensor):\n        previous_b_dec = self.b_dec.clone().cpu()\n        out = all_activations.mean(dim=0)\n\n        previous_distances = torch.norm(all_activations - previous_b_dec, dim=-1)\n        distances = torch.norm(all_activations - out, dim=-1)\n\n        logger.info(\"Reinitializing b_dec with mean of activations\")\n        logger.debug(\n            f\"Previous distances: {previous_distances.median(0).values.mean().item()}\"\n        )\n        logger.debug(f\"New distances: {distances.median(0).values.mean().item()}\")\n\n        self.b_dec.data = out.to(self.dtype).to(self.device)\n\n    ## Training Utils\n    @torch.no_grad()\n    def set_decoder_norm_to_unit_norm(self):\n        self.W_dec.data /= torch.norm(self.W_dec.data, dim=1, keepdim=True)\n\n    @torch.no_grad()\n    def initialize_decoder_norm_constant_norm(self, norm: float = 0.1):\n        \"\"\"\n        A heuristic proceedure inspired by:\n        https://transformer-circuits.pub/2024/april-update/index.html#training-saes\n        \"\"\"\n        # TODO: Parameterise this as a function of m and n\n\n        # ensure W_dec norms at unit norm\n        self.W_dec.data /= torch.norm(self.W_dec.data, dim=1, keepdim=True)\n        self.W_dec.data *= norm  # will break tests but do this for now.\n\n    @torch.no_grad()\n    def remove_gradient_parallel_to_decoder_directions(self):\n        \"\"\"\n        Update grads so that they remove the parallel component\n            (d_sae, d_in) shape\n        \"\"\"\n        assert self.W_dec.grad is not None  # keep pyright happy\n\n        parallel_component = einops.einsum(\n            self.W_dec.grad,\n            self.W_dec.data,\n            \"d_sae d_in, d_sae d_in -&gt; d_sae\",\n        )\n        self.W_dec.grad -= einops.einsum(\n            parallel_component,\n            self.W_dec.data,\n            \"d_sae, d_sae d_in -&gt; d_sae d_in\",\n        )\n</code></pre>"},{"location":"api/#sae_lens.TrainingSAE.encode_standard","title":"<code>encode_standard(x)</code>","text":"<p>Calcuate SAE features from inputs</p> Source code in <code>sae_lens/training/training_sae.py</code> <pre><code>def encode_standard(\n    self, x: Float[torch.Tensor, \"... d_in\"]\n) -&gt; Float[torch.Tensor, \"... d_sae\"]:\n    \"\"\"\n    Calcuate SAE features from inputs\n    \"\"\"\n    feature_acts, _ = self.encode_with_hidden_pre_fn(x)\n    return feature_acts\n</code></pre>"},{"location":"api/#sae_lens.TrainingSAE.initialize_decoder_norm_constant_norm","title":"<code>initialize_decoder_norm_constant_norm(norm=0.1)</code>","text":"<p>A heuristic proceedure inspired by: https://transformer-circuits.pub/2024/april-update/index.html#training-saes</p> Source code in <code>sae_lens/training/training_sae.py</code> <pre><code>@torch.no_grad()\ndef initialize_decoder_norm_constant_norm(self, norm: float = 0.1):\n    \"\"\"\n    A heuristic proceedure inspired by:\n    https://transformer-circuits.pub/2024/april-update/index.html#training-saes\n    \"\"\"\n    # TODO: Parameterise this as a function of m and n\n\n    # ensure W_dec norms at unit norm\n    self.W_dec.data /= torch.norm(self.W_dec.data, dim=1, keepdim=True)\n    self.W_dec.data *= norm  # will break tests but do this for now.\n</code></pre>"},{"location":"api/#sae_lens.TrainingSAE.initialize_weights_complex","title":"<code>initialize_weights_complex()</code>","text":"Source code in <code>sae_lens/training/training_sae.py</code> <pre><code>def initialize_weights_complex(self):\n    \"\"\" \"\"\"\n\n    if self.cfg.decoder_orthogonal_init:\n        self.W_dec.data = nn.init.orthogonal_(self.W_dec.data.T).T\n\n    elif self.cfg.decoder_heuristic_init:\n        self.W_dec = nn.Parameter(\n            torch.randn(\n                self.cfg.d_sae, self.cfg.d_in, dtype=self.dtype, device=self.device\n            )\n        )\n        self.initialize_decoder_norm_constant_norm(\n            self.cfg.decoder_heuristic_init_norm\n        )\n\n    # Then we initialize the encoder weights (either as the transpose of decoder or not)\n    if self.cfg.init_encoder_as_decoder_transpose:\n        self.W_enc.data = self.W_dec.data.T.clone().contiguous()\n    else:\n        self.W_enc = nn.Parameter(\n            torch.nn.init.kaiming_uniform_(\n                torch.empty(\n                    self.cfg.d_in,\n                    self.cfg.d_sae,\n                    dtype=self.dtype,\n                    device=self.device,\n                )\n            )\n        )\n\n    if self.cfg.normalize_sae_decoder:\n        with torch.no_grad():\n            # Anthropic normalize this to have unit columns\n            self.set_decoder_norm_to_unit_norm()\n</code></pre>"},{"location":"api/#sae_lens.TrainingSAE.remove_gradient_parallel_to_decoder_directions","title":"<code>remove_gradient_parallel_to_decoder_directions()</code>","text":"<p>Update grads so that they remove the parallel component     (d_sae, d_in) shape</p> Source code in <code>sae_lens/training/training_sae.py</code> <pre><code>@torch.no_grad()\ndef remove_gradient_parallel_to_decoder_directions(self):\n    \"\"\"\n    Update grads so that they remove the parallel component\n        (d_sae, d_in) shape\n    \"\"\"\n    assert self.W_dec.grad is not None  # keep pyright happy\n\n    parallel_component = einops.einsum(\n        self.W_dec.grad,\n        self.W_dec.data,\n        \"d_sae d_in, d_sae d_in -&gt; d_sae\",\n    )\n    self.W_dec.grad -= einops.einsum(\n        parallel_component,\n        self.W_dec.data,\n        \"d_sae, d_sae d_in -&gt; d_sae d_in\",\n    )\n</code></pre>"},{"location":"citation/","title":"Citation","text":"<pre><code>@misc{bloom2024saetrainingcodebase,\n   title = {SAELens},\n   author = {Bloom, Joseph and Tigges, Curt and Duong, Anthony and Chanin, David},\n   year = {2024},\n   howpublished = {\\url{https://github.com/jbloomAus/SAELens}},\n}}\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome! To get setup for development, follow the instructions below.</p>"},{"location":"contributing/#setup","title":"Setup","text":"<p>Make sure you have poetry installed, clone the repository, and install dependencies with:</p> <pre><code>git clone https://github.com/jbloomAus/SAELens.git # we recommend you make a fork for submitting PR's and clone that!\npoetry lock # can take a while.\npoetry install \nmake check-ci # validate the install\n</code></pre>"},{"location":"contributing/#testing-linting-and-formatting","title":"Testing, Linting, and Formatting","text":"<p>This project uses pytest for testing, pyright for type-checking, and Ruff for formatting and linting.</p> <p>If you add new code, it would be greatly appreciated if you could add tests in the <code>tests</code> directory. You can run the tests with:</p> <pre><code>make test\n</code></pre> <p>Before commiting, make sure you format the code with:</p> <pre><code>make format\n</code></pre> <p>Finally, run all CI checks locally with:</p> <pre><code>make check-ci\n</code></pre> <p>If these pass, you're good to go! Open a pull request with your changes.</p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>This project uses mkdocs for documentation. You can see the docs locally with:</p> <p><pre><code>make docs-serve\n</code></pre> If you make changes to code which requires updating documentation, it would be greatly appreciated if you could update the docs as well.</p>"},{"location":"roadmap/","title":"Roadmap","text":""},{"location":"roadmap/#motivation","title":"Motivation","text":"<ul> <li>Accelerate SAE Research: Support fast experimentation to understand SAEs and improve SAE training so we can train SAEs on larger and more diverse models.</li> <li>Make Research like Play: Support research into language model internals via SAEs. Good tooling can make research tremendously exciting and enjoyable. Balancing modifiability and reliability with ease of understanding / access is the name of the game here.</li> <li>Build an awesome community: Mechanistic Interpretability already has an awesome community but as that community grows, it makes sense that there will be niches. I'd love to build a great community around Sparse Autoencoders.</li> </ul>"},{"location":"roadmap/#goals","title":"Goals","text":""},{"location":"roadmap/#sae-training","title":"SAE Training","text":"<p>SAE Training features will fit into a number of categories including:</p> <ul> <li>Making it easy to train SAEs: Training SAEs is hard for a number of reasons and so making it easy for people to train SAEs with relatively little expertise seems like the main way this codebase will create value. </li> <li>Training SAEs on more models: Supporting training of SAEs on more models, architectures, different activations within those models.</li> <li>Being better at training SAEs: Enabling methodological changes which may improve SAE performance as measured by reconstruction loss, Cross Entropy Loss when using reconstructed activation, L1 loss, L0 and interpretability of features as well as improving speed of training or reducing the compute resources required to train SAEs. </li> <li>Being better at measuring SAE Performance: How do we know when SAEs are doing what we want them to? Improving training metrics should allow better decisions about which methods to use and which hyperparameters choices we make.</li> <li>Training SAE variants: People are already training \u201cTranscoders\u201d which map from one activation to another (such as before / after an MLP layer). These can be easily supported with a few changes. Other variants will come in time and </li> </ul>"},{"location":"roadmap/#analysis-with-saes","title":"Analysis with SAEs","text":"<p>Using SAEs to understand neural network internals is an exciting, but complicated task.</p> <ul> <li>Feature-wise Interpretability: This looks something like \"for each feature, have as much knowledge about it as possible\". Part of this will feature dashboard improvements, or supporting better integrations with Neuronpedia.</li> <li>Mechanistic Interpretability: This comprises the more traditional kinds of Mechanistic Interpretability which TransformerLens supports and should be supported by this codebase. Making it easy to patch, ablate or otherwise intervene on features so as to find circuits will likely speed up lots of researchers.</li> </ul>"},{"location":"roadmap/#other-stuff","title":"Other Stuff","text":"<p>I think there are lots of other types of analysis that could be done in the future with SAE features. I've already explored many different types of statistical tests which can reveal interesting properties of features. There are also things like saliency mapping and attribution techniques which it would be nice to support.</p> <ul> <li>Accessibility and Code Quality: The codebase won\u2019t be used if it doesn\u2019t work and it also won\u2019t get used if it\u2019s too hard to understand, modify or read.  Making the code accessible: This involves tasks like turning the code base into a python package.</li> <li>Knowing how the code is supposed to work: Is the code well-documented? This will require docstrings, tutorials and links to related work and publications. Getting aligned on what the code does is critical to sharing a resource like this. </li> <li>Knowing the code works as intended: All code should be tested.</li> <li>Knowing the code is actually performant: This will ensure code works as intended. However deep learning introduces lots of complexity which makes actually running benchmarks essential to having confidence in the code. </li> </ul>"},{"location":"sae_table/","title":"Pretrained SAEs","text":"<p>This is a list of SAEs importable from the SAELens package. Click on each link for more details.</p> <p>This file contains the contents of <code>sae_lens/pretrained_saes.yaml</code> in Markdown</p>"},{"location":"sae_table/#deepseek-r1-distill-llama-8b-qresearch","title":"deepseek-r1-distill-llama-8b-qresearch","text":"<ul> <li>Huggingface Repo: qresearch/DeepSeek-R1-Distill-Llama-8B-SAE-l19</li> <li>model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.19.hook_resid_postLoad this SAE standard deepseek-r1-distill-llama-8b/19-qresearch-res-65k blocks.19.hook_resid_post 19 65536 1024 lmsys/lmsys-chat-1m none"},{"location":"sae_table/#gemma-2b-it-res-jb","title":"gemma-2b-it-res-jb","text":"<ul> <li>Huggingface Repo: jbloom/Gemma-2b-IT-Residual-Stream-SAEs</li> <li>model: gemma-2b-it</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.12.hook_resid_postLoad this SAE standard gemma-2b-it/12-res-jb blocks.12.hook_resid_post 12 16384 1024 Skylion007/openwebtext none"},{"location":"sae_table/#gemma-2b-res-jb","title":"gemma-2b-res-jb","text":"<ul> <li>Huggingface Repo: jbloom/Gemma-2b-Residual-Stream-SAEs</li> <li>model: gemma-2b</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_postLoad this SAE standard gemma-2b/0-res-jb blocks.0.hook_resid_post 0 16384 1024 HuggingFaceFW/fineweb none blocks.6.hook_resid_postLoad this SAE standard gemma-2b/6-res-jb blocks.6.hook_resid_post 6 16384 1024 HuggingFaceFW/fineweb none blocks.10.hook_resid_postLoad this SAE standard gemma-2b/10-res-jb blocks.10.hook_resid_post 10 16384 1024 ctigges/openwebtext-gemma-1024-cl none blocks.12.hook_resid_postLoad this SAE standard gemma-2b/12-res-jb blocks.12.hook_resid_post 12 16384 1024 HuggingFaceFW/fineweb expected_average_only_in blocks.17.hook_resid_postLoad this SAE standard blocks.17.hook_resid_post 17 16384 1024 ctigges/openwebtext-gemma-1024-cl none"},{"location":"sae_table/#gemma-scope-27b-pt-res","title":"gemma-scope-27b-pt-res","text":"<ul> <li>Huggingface Repo: google/gemma-scope-27b-pt-res</li> <li>model: gemma-2-27b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_10/width_131k/average_l0_106Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_15Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_200Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_24Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_37Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_64Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_150Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_20Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_290Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_31Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_48Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_82Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_155Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_21Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_333Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_38Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_72Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_785Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-27b-pt-res-canonical","title":"gemma-scope-27b-pt-res-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-27b-pt-res</li> <li>model: gemma-2-27b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_10/width_131k/canonicalLoad this SAE jumprelu gemma-2-27b/10-gemmascope-res-131k blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/canonicalLoad this SAE jumprelu gemma-2-27b/22-gemmascope-res-131k blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/canonicalLoad this SAE jumprelu gemma-2-27b/34-gemmascope-res-131k blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-2b-pt-att","title":"gemma-scope-2b-pt-att","text":"<ul> <li>Huggingface Repo: google/gemma-scope-2b-pt-att</li> <li>model: gemma-2-2b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/average_l0_104Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_12Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_18Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_30Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_57Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_146Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_20Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_251Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_40Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_79Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_174Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_19Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_297Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_43Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_93Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_117Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_219Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_24Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_386Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_55Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_116Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_249Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_26Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_454Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_53Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_135Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_268Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_30Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_449Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_59Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_143Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_292Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_30Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_479Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_61Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_184Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_331Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_46Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_537Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_99Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_129Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_282Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_32Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_482Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_64Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_127Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_270Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_34Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_499Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_64Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_148Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_307Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_36Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_541Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_70Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_170Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_350Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_41Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_593Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_80Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_184Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_328Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_41Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_514Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_85Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_203Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_372Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_43Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_570Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_92Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_161Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_298Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_37Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_468Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_71Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_195Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_342Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_44Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_535Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_98Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_144Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_293Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_37Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_527Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_71Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_176Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_316Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_38Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_509Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_79Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_144Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_292Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_34Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_491Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_72Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_122Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_249Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_28Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_423Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_56Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_141Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_274Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_31Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_446Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_62Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_142Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_301Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_32Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_505Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_65Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_106Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_215Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_22Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_373Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_47Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_161Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_30Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_300Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_474Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_73Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_212Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_372Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_39Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_558Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_96Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_177Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_313Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_35Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_492Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_77Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_10Load this SAE jumprelu blocks.0.attn.hook_z 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_16Load this SAE jumprelu blocks.0.attn.hook_z 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_24Load this SAE jumprelu blocks.0.attn.hook_z 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_43Load this SAE jumprelu blocks.0.attn.hook_z 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_75Load this SAE jumprelu blocks.0.attn.hook_z 0 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_15Load this SAE jumprelu blocks.1.attn.hook_z 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_181Load this SAE jumprelu blocks.1.attn.hook_z 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_28Load this SAE jumprelu blocks.1.attn.hook_z 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_55Load this SAE jumprelu blocks.1.attn.hook_z 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_98Load this SAE jumprelu blocks.1.attn.hook_z 1 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_125Load this SAE jumprelu blocks.2.attn.hook_z 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_14Load this SAE jumprelu blocks.2.attn.hook_z 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_228Load this SAE jumprelu blocks.2.attn.hook_z 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_28Load this SAE jumprelu blocks.2.attn.hook_z 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_59Load this SAE jumprelu blocks.2.attn.hook_z 2 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_174Load this SAE jumprelu blocks.3.attn.hook_z 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_19Load this SAE jumprelu blocks.3.attn.hook_z 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_320Load this SAE jumprelu blocks.3.attn.hook_z 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_39Load this SAE jumprelu blocks.3.attn.hook_z 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_83Load this SAE jumprelu blocks.3.attn.hook_z 3 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_188Load this SAE jumprelu blocks.4.attn.hook_z 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_22Load this SAE jumprelu blocks.4.attn.hook_z 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_382Load this SAE jumprelu blocks.4.attn.hook_z 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_43Load this SAE jumprelu blocks.4.attn.hook_z 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_87Load this SAE jumprelu blocks.4.attn.hook_z 4 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_227Load this SAE jumprelu blocks.5.attn.hook_z 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_28Load this SAE jumprelu blocks.5.attn.hook_z 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_400Load this SAE jumprelu blocks.5.attn.hook_z 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_51Load this SAE jumprelu blocks.5.attn.hook_z 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_99Load this SAE jumprelu blocks.5.attn.hook_z 5 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_112Load this SAE jumprelu blocks.6.attn.hook_z 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_261Load this SAE jumprelu blocks.6.attn.hook_z 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_30Load this SAE jumprelu blocks.6.attn.hook_z 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_449Load this SAE jumprelu blocks.6.attn.hook_z 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_55Load this SAE jumprelu blocks.6.attn.hook_z 6 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_176Load this SAE jumprelu blocks.7.attn.hook_z 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_311Load this SAE jumprelu blocks.7.attn.hook_z 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_519Load this SAE jumprelu blocks.7.attn.hook_z 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_52Load this SAE jumprelu blocks.7.attn.hook_z 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_96Load this SAE jumprelu blocks.7.attn.hook_z 7 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_112Load this SAE jumprelu blocks.8.attn.hook_z 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_246Load this SAE jumprelu blocks.8.attn.hook_z 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_35Load this SAE jumprelu blocks.8.attn.hook_z 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_454Load this SAE jumprelu blocks.8.attn.hook_z 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_56Load this SAE jumprelu blocks.8.attn.hook_z 8 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_107Load this SAE jumprelu blocks.9.attn.hook_z 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_231Load this SAE jumprelu blocks.9.attn.hook_z 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_31Load this SAE jumprelu blocks.9.attn.hook_z 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_454Load this SAE jumprelu blocks.9.attn.hook_z 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_57Load this SAE jumprelu blocks.9.attn.hook_z 9 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_134Load this SAE jumprelu blocks.10.attn.hook_z 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_292Load this SAE jumprelu blocks.10.attn.hook_z 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_35Load this SAE jumprelu blocks.10.attn.hook_z 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_521Load this SAE jumprelu blocks.10.attn.hook_z 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_67Load this SAE jumprelu blocks.10.attn.hook_z 10 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_154Load this SAE jumprelu blocks.11.attn.hook_z 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_330Load this SAE jumprelu blocks.11.attn.hook_z 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_41Load this SAE jumprelu blocks.11.attn.hook_z 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_576Load this SAE jumprelu blocks.11.attn.hook_z 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_75Load this SAE jumprelu blocks.11.attn.hook_z 11 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_172Load this SAE jumprelu blocks.12.attn.hook_z 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_320Load this SAE jumprelu blocks.12.attn.hook_z 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_39Load this SAE jumprelu blocks.12.attn.hook_z 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_503Load this SAE jumprelu blocks.12.attn.hook_z 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_79Load this SAE jumprelu blocks.12.attn.hook_z 12 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_191Load this SAE jumprelu blocks.13.attn.hook_z 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_363Load this SAE jumprelu blocks.13.attn.hook_z 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_41Load this SAE jumprelu blocks.13.attn.hook_z 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_556Load this SAE jumprelu blocks.13.attn.hook_z 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_87Load this SAE jumprelu blocks.13.attn.hook_z 13 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_138Load this SAE jumprelu blocks.14.attn.hook_z 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_283Load this SAE jumprelu blocks.14.attn.hook_z 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_37Load this SAE jumprelu blocks.14.attn.hook_z 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_453Load this SAE jumprelu blocks.14.attn.hook_z 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_66Load this SAE jumprelu blocks.14.attn.hook_z 14 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_182Load this SAE jumprelu blocks.15.attn.hook_z 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_327Load this SAE jumprelu blocks.15.attn.hook_z 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_42Load this SAE jumprelu blocks.15.attn.hook_z 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_517Load this SAE jumprelu blocks.15.attn.hook_z 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_90Load this SAE jumprelu blocks.15.attn.hook_z 15 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_129Load this SAE jumprelu blocks.16.attn.hook_z 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_260Load this SAE jumprelu blocks.16.attn.hook_z 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_35Load this SAE jumprelu blocks.16.attn.hook_z 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_502Load this SAE jumprelu blocks.16.attn.hook_z 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_64Load this SAE jumprelu blocks.16.attn.hook_z 16 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_157Load this SAE jumprelu blocks.17.attn.hook_z 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_293Load this SAE jumprelu blocks.17.attn.hook_z 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_35Load this SAE jumprelu blocks.17.attn.hook_z 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_489Load this SAE jumprelu blocks.17.attn.hook_z 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_70Load this SAE jumprelu blocks.17.attn.hook_z 17 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_123Load this SAE jumprelu blocks.18.attn.hook_z 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_255Load this SAE jumprelu blocks.18.attn.hook_z 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_29Load this SAE jumprelu blocks.18.attn.hook_z 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_466Load this SAE jumprelu blocks.18.attn.hook_z 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_58Load this SAE jumprelu blocks.18.attn.hook_z 18 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_106Load this SAE jumprelu blocks.19.attn.hook_z 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_220Load this SAE jumprelu blocks.19.attn.hook_z 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_26Load this SAE jumprelu blocks.19.attn.hook_z 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_411Load this SAE jumprelu blocks.19.attn.hook_z 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_49Load this SAE jumprelu blocks.19.attn.hook_z 19 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_102Load this SAE jumprelu blocks.20.attn.hook_z 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_242Load this SAE jumprelu blocks.20.attn.hook_z 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_26Load this SAE jumprelu blocks.20.attn.hook_z 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_419Load this SAE jumprelu blocks.20.attn.hook_z 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_49Load this SAE jumprelu blocks.20.attn.hook_z 20 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_118Load this SAE jumprelu blocks.21.attn.hook_z 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_266Load this SAE jumprelu blocks.21.attn.hook_z 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_29Load this SAE jumprelu blocks.21.attn.hook_z 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_474Load this SAE jumprelu blocks.21.attn.hook_z 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_56Load this SAE jumprelu blocks.21.attn.hook_z 21 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_112Load this SAE jumprelu blocks.22.attn.hook_z 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_196Load this SAE jumprelu blocks.22.attn.hook_z 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_20Load this SAE jumprelu blocks.22.attn.hook_z 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_361Load this SAE jumprelu blocks.22.attn.hook_z 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_37Load this SAE jumprelu blocks.22.attn.hook_z 22 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_140Load this SAE jumprelu blocks.23.attn.hook_z 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_27Load this SAE jumprelu blocks.23.attn.hook_z 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_276Load this SAE jumprelu blocks.23.attn.hook_z 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_457Load this SAE jumprelu blocks.23.attn.hook_z 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_56Load this SAE jumprelu blocks.23.attn.hook_z 23 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_186Load this SAE jumprelu blocks.24.attn.hook_z 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_32Load this SAE jumprelu blocks.24.attn.hook_z 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_347Load this SAE jumprelu blocks.24.attn.hook_z 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_537Load this SAE jumprelu blocks.24.attn.hook_z 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_77Load this SAE jumprelu blocks.24.attn.hook_z 24 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_153Load this SAE jumprelu blocks.25.attn.hook_z 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_290Load this SAE jumprelu blocks.25.attn.hook_z 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_30Load this SAE jumprelu blocks.25.attn.hook_z 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_465Load this SAE jumprelu blocks.25.attn.hook_z 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_63Load this SAE jumprelu blocks.25.attn.hook_z 25 65536 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-2b-pt-att-canonical","title":"gemma-scope-2b-pt-att-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-2b-pt-att</li> <li>model: gemma-2-2b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/0-gemmascope-att-16k blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/1-gemmascope-att-16k blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/2-gemmascope-att-16k blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/3-gemmascope-att-16k blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/4-gemmascope-att-16k blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/5-gemmascope-att-16k blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/6-gemmascope-att-16k blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/7-gemmascope-att-16k blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/8-gemmascope-att-16k blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/9-gemmascope-att-16k blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/10-gemmascope-att-16k blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/11-gemmascope-att-16k blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-att-16k blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/13-gemmascope-att-16k blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/14-gemmascope-att-16k blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/15-gemmascope-att-16k blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/16-gemmascope-att-16k blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/17-gemmascope-att-16k blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/18-gemmascope-att-16k blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/19-gemmascope-att-16k blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/20-gemmascope-att-16k blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/21-gemmascope-att-16k blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/22-gemmascope-att-16k blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/23-gemmascope-att-16k blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/24-gemmascope-att-16k blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/25-gemmascope-att-16k blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_0/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/0-gemmascope-att-65k blocks.0.attn.hook_z 0 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/1-gemmascope-att-65k blocks.1.attn.hook_z 1 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/2-gemmascope-att-65k blocks.2.attn.hook_z 2 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/3-gemmascope-att-65k blocks.3.attn.hook_z 3 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/4-gemmascope-att-65k blocks.4.attn.hook_z 4 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/5-gemmascope-att-65k blocks.5.attn.hook_z 5 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/6-gemmascope-att-65k blocks.6.attn.hook_z 6 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/7-gemmascope-att-65k blocks.7.attn.hook_z 7 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/8-gemmascope-att-65k blocks.8.attn.hook_z 8 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/9-gemmascope-att-65k blocks.9.attn.hook_z 9 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/10-gemmascope-att-65k blocks.10.attn.hook_z 10 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/11-gemmascope-att-65k blocks.11.attn.hook_z 11 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-att-65k blocks.12.attn.hook_z 12 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/13-gemmascope-att-65k blocks.13.attn.hook_z 13 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/14-gemmascope-att-65k blocks.14.attn.hook_z 14 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/15-gemmascope-att-65k blocks.15.attn.hook_z 15 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/16-gemmascope-att-65k blocks.16.attn.hook_z 16 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/17-gemmascope-att-65k blocks.17.attn.hook_z 17 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/18-gemmascope-att-65k blocks.18.attn.hook_z 18 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/19-gemmascope-att-65k blocks.19.attn.hook_z 19 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/20-gemmascope-att-65k blocks.20.attn.hook_z 20 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/21-gemmascope-att-65k blocks.21.attn.hook_z 21 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/22-gemmascope-att-65k blocks.22.attn.hook_z 22 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/23-gemmascope-att-65k blocks.23.attn.hook_z 23 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/24-gemmascope-att-65k blocks.24.attn.hook_z 24 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/25-gemmascope-att-65k blocks.25.attn.hook_z 25 65536 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-2b-pt-mlp","title":"gemma-scope-2b-pt-mlp","text":"<ul> <li>Huggingface Repo: google/gemma-scope-2b-pt-mlp</li> <li>model: gemma-2-2b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/average_l0_119Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_16Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_30Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_60Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_9Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_105Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_12Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_239Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_24Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_50Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_19Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_213Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_41Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_434Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_95Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_195Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_21Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_377Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_44Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_95Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_18Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_198Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_38Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_433Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_85Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_114Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_23Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_269Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_48Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_575Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_133Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_25Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_328Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_55Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_699Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_146Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_28Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_355Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_60Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_731Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_136Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_27Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_351Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_56Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_739Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_216Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_38Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_482Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_861Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_88Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_110Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_266Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_45Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_568Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_908Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_234Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_42Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_499Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_847Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_98Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_108Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_262Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_44Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_548Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_879Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_112Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_267Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_47Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_553Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_892Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_246Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_41Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_536Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_894Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_97Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_207Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_35Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_492Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_80Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_879Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_185Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_33Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_452Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_72Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_847Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_179Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_31Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_453Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_68Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_853Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_106Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_24Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_292Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_47Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_672Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_109Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_25Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_295Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_50Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_673Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_109Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_24Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_289Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_49Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_658Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_113Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_23Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_279Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_48Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_633Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_121Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_24Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_290Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_51Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_624Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_128Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_27Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_287Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_57Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_627Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_158Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_19Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_35Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_357Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_73Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_126Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_15Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_277Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_29Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_59Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_12Load this SAE jumprelu blocks.0.hook_mlp_out 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_21Load this SAE jumprelu blocks.0.hook_mlp_out 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_39Load this SAE jumprelu blocks.0.hook_mlp_out 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_7Load this SAE jumprelu blocks.0.hook_mlp_out 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_72Load this SAE jumprelu blocks.0.hook_mlp_out 0 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_11Load this SAE jumprelu blocks.1.hook_mlp_out 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_127Load this SAE jumprelu blocks.1.hook_mlp_out 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_20Load this SAE jumprelu blocks.1.hook_mlp_out 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_37Load this SAE jumprelu blocks.1.hook_mlp_out 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_67Load this SAE jumprelu blocks.1.hook_mlp_out 1 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_134Load this SAE jumprelu blocks.2.hook_mlp_out 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_16Load this SAE jumprelu blocks.2.hook_mlp_out 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_265Load this SAE jumprelu blocks.2.hook_mlp_out 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_31Load this SAE jumprelu blocks.2.hook_mlp_out 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_60Load this SAE jumprelu blocks.2.hook_mlp_out 2 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_144Load this SAE jumprelu blocks.3.hook_mlp_out 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_18Load this SAE jumprelu blocks.3.hook_mlp_out 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_279Load this SAE jumprelu blocks.3.hook_mlp_out 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_33Load this SAE jumprelu blocks.3.hook_mlp_out 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_68Load this SAE jumprelu blocks.3.hook_mlp_out 3 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_138Load this SAE jumprelu blocks.4.hook_mlp_out 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_17Load this SAE jumprelu blocks.4.hook_mlp_out 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_299Load this SAE jumprelu blocks.4.hook_mlp_out 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_32Load this SAE jumprelu blocks.4.hook_mlp_out 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_66Load this SAE jumprelu blocks.4.hook_mlp_out 4 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_186Load this SAE jumprelu blocks.5.hook_mlp_out 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_22Load this SAE jumprelu blocks.5.hook_mlp_out 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_407Load this SAE jumprelu blocks.5.hook_mlp_out 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_43Load this SAE jumprelu blocks.5.hook_mlp_out 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_86Load this SAE jumprelu blocks.5.hook_mlp_out 5 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_101Load this SAE jumprelu blocks.6.hook_mlp_out 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_224Load this SAE jumprelu blocks.6.hook_mlp_out 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_24Load this SAE jumprelu blocks.6.hook_mlp_out 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_47Load this SAE jumprelu blocks.6.hook_mlp_out 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_515Load this SAE jumprelu blocks.6.hook_mlp_out 6 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_115Load this SAE jumprelu blocks.7.hook_mlp_out 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_266Load this SAE jumprelu blocks.7.hook_mlp_out 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_28Load this SAE jumprelu blocks.7.hook_mlp_out 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_56Load this SAE jumprelu blocks.7.hook_mlp_out 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_571Load this SAE jumprelu blocks.7.hook_mlp_out 7 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_110Load this SAE jumprelu blocks.8.hook_mlp_out 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_256Load this SAE jumprelu blocks.8.hook_mlp_out 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_31Load this SAE jumprelu blocks.8.hook_mlp_out 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_547Load this SAE jumprelu blocks.8.hook_mlp_out 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_55Load this SAE jumprelu blocks.8.hook_mlp_out 8 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_168Load this SAE jumprelu blocks.9.hook_mlp_out 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_38Load this SAE jumprelu blocks.9.hook_mlp_out 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_387Load this SAE jumprelu blocks.9.hook_mlp_out 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_745Load this SAE jumprelu blocks.9.hook_mlp_out 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_77Load this SAE jumprelu blocks.9.hook_mlp_out 9 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_218Load this SAE jumprelu blocks.10.hook_mlp_out 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_43Load this SAE jumprelu blocks.10.hook_mlp_out 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_474Load this SAE jumprelu blocks.10.hook_mlp_out 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_851Load this SAE jumprelu blocks.10.hook_mlp_out 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_95Load this SAE jumprelu blocks.10.hook_mlp_out 10 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_200Load this SAE jumprelu blocks.11.hook_mlp_out 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_41Load this SAE jumprelu blocks.11.hook_mlp_out 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_436Load this SAE jumprelu blocks.11.hook_mlp_out 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_771Load this SAE jumprelu blocks.11.hook_mlp_out 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_88Load this SAE jumprelu blocks.11.hook_mlp_out 11 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_222Load this SAE jumprelu blocks.12.hook_mlp_out 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_44Load this SAE jumprelu blocks.12.hook_mlp_out 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_482Load this SAE jumprelu blocks.12.hook_mlp_out 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_848Load this SAE jumprelu blocks.12.hook_mlp_out 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_96Load this SAE jumprelu blocks.12.hook_mlp_out 12 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_228Load this SAE jumprelu blocks.13.hook_mlp_out 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_44Load this SAE jumprelu blocks.13.hook_mlp_out 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_480Load this SAE jumprelu blocks.13.hook_mlp_out 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_841Load this SAE jumprelu blocks.13.hook_mlp_out 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_98Load this SAE jumprelu blocks.13.hook_mlp_out 13 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_204Load this SAE jumprelu blocks.14.hook_mlp_out 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_39Load this SAE jumprelu blocks.14.hook_mlp_out 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_463Load this SAE jumprelu blocks.14.hook_mlp_out 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_816Load this SAE jumprelu blocks.14.hook_mlp_out 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_89Load this SAE jumprelu blocks.14.hook_mlp_out 14 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_164Load this SAE jumprelu blocks.15.hook_mlp_out 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_35Load this SAE jumprelu blocks.15.hook_mlp_out 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_405Load this SAE jumprelu blocks.15.hook_mlp_out 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_72Load this SAE jumprelu blocks.15.hook_mlp_out 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_754Load this SAE jumprelu blocks.15.hook_mlp_out 15 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_142Load this SAE jumprelu blocks.16.hook_mlp_out 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_32Load this SAE jumprelu blocks.16.hook_mlp_out 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_348Load this SAE jumprelu blocks.16.hook_mlp_out 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_66Load this SAE jumprelu blocks.16.hook_mlp_out 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_695Load this SAE jumprelu blocks.16.hook_mlp_out 16 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_136Load this SAE jumprelu blocks.17.hook_mlp_out 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_30Load this SAE jumprelu blocks.17.hook_mlp_out 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_342Load this SAE jumprelu blocks.17.hook_mlp_out 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_61Load this SAE jumprelu blocks.17.hook_mlp_out 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_666Load this SAE jumprelu blocks.17.hook_mlp_out 17 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_191Load this SAE jumprelu blocks.18.hook_mlp_out 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_24Load this SAE jumprelu blocks.18.hook_mlp_out 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_44Load this SAE jumprelu blocks.18.hook_mlp_out 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_491Load this SAE jumprelu blocks.18.hook_mlp_out 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_88Load this SAE jumprelu blocks.18.hook_mlp_out 18 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_192Load this SAE jumprelu blocks.19.hook_mlp_out 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_25Load this SAE jumprelu blocks.19.hook_mlp_out 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_45Load this SAE jumprelu blocks.19.hook_mlp_out 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_470Load this SAE jumprelu blocks.19.hook_mlp_out 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_88Load this SAE jumprelu blocks.19.hook_mlp_out 19 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_189Load this SAE jumprelu blocks.20.hook_mlp_out 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_23Load this SAE jumprelu blocks.20.hook_mlp_out 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_44Load this SAE jumprelu blocks.20.hook_mlp_out 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_446Load this SAE jumprelu blocks.20.hook_mlp_out 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_88Load this SAE jumprelu blocks.20.hook_mlp_out 20 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_192Load this SAE jumprelu blocks.21.hook_mlp_out 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_23Load this SAE jumprelu blocks.21.hook_mlp_out 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_42Load this SAE jumprelu blocks.21.hook_mlp_out 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_472Load this SAE jumprelu blocks.21.hook_mlp_out 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_86Load this SAE jumprelu blocks.21.hook_mlp_out 21 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_203Load this SAE jumprelu blocks.22.hook_mlp_out 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_23Load this SAE jumprelu blocks.22.hook_mlp_out 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_46Load this SAE jumprelu blocks.22.hook_mlp_out 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_487Load this SAE jumprelu blocks.22.hook_mlp_out 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_92Load this SAE jumprelu blocks.22.hook_mlp_out 22 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_102Load this SAE jumprelu blocks.23.hook_mlp_out 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_218Load this SAE jumprelu blocks.23.hook_mlp_out 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_25Load this SAE jumprelu blocks.23.hook_mlp_out 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_49Load this SAE jumprelu blocks.23.hook_mlp_out 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_497Load this SAE jumprelu blocks.23.hook_mlp_out 23 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_128Load this SAE jumprelu blocks.24.hook_mlp_out 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_18Load this SAE jumprelu blocks.24.hook_mlp_out 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_268Load this SAE jumprelu blocks.24.hook_mlp_out 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_32Load this SAE jumprelu blocks.24.hook_mlp_out 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_62Load this SAE jumprelu blocks.24.hook_mlp_out 24 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_107Load this SAE jumprelu blocks.25.hook_mlp_out 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_14Load this SAE jumprelu blocks.25.hook_mlp_out 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_215Load this SAE jumprelu blocks.25.hook_mlp_out 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_26Load this SAE jumprelu blocks.25.hook_mlp_out 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_52Load this SAE jumprelu blocks.25.hook_mlp_out 25 65536 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-2b-pt-mlp-canonical","title":"gemma-scope-2b-pt-mlp-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-2b-pt-mlp</li> <li>model: gemma-2-2b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/0-gemmascope-mlp-16k blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/1-gemmascope-mlp-16k blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/2-gemmascope-mlp-16k blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/3-gemmascope-mlp-16k blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/4-gemmascope-mlp-16k blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/5-gemmascope-mlp-16k blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/6-gemmascope-mlp-16k blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/7-gemmascope-mlp-16k blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/8-gemmascope-mlp-16k blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/9-gemmascope-mlp-16k blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/10-gemmascope-mlp-16k blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/11-gemmascope-mlp-16k blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-mlp-16k blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/13-gemmascope-mlp-16k blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/14-gemmascope-mlp-16k blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/15-gemmascope-mlp-16k blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/16-gemmascope-mlp-16k blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/17-gemmascope-mlp-16k blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/18-gemmascope-mlp-16k blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/19-gemmascope-mlp-16k blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/20-gemmascope-mlp-16k blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/21-gemmascope-mlp-16k blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/22-gemmascope-mlp-16k blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/23-gemmascope-mlp-16k blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/24-gemmascope-mlp-16k blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/25-gemmascope-mlp-16k blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_0/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/0-gemmascope-mlp-65k blocks.0.hook_mlp_out 0 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/1-gemmascope-mlp-65k blocks.1.hook_mlp_out 1 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/2-gemmascope-mlp-65k blocks.2.hook_mlp_out 2 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/3-gemmascope-mlp-65k blocks.3.hook_mlp_out 3 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/4-gemmascope-mlp-65k blocks.4.hook_mlp_out 4 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/5-gemmascope-mlp-65k blocks.5.hook_mlp_out 5 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/6-gemmascope-mlp-65k blocks.6.hook_mlp_out 6 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/7-gemmascope-mlp-65k blocks.7.hook_mlp_out 7 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/8-gemmascope-mlp-65k blocks.8.hook_mlp_out 8 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/9-gemmascope-mlp-65k blocks.9.hook_mlp_out 9 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/10-gemmascope-mlp-65k blocks.10.hook_mlp_out 10 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/11-gemmascope-mlp-65k blocks.11.hook_mlp_out 11 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-mlp-65k blocks.12.hook_mlp_out 12 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/13-gemmascope-mlp-65k blocks.13.hook_mlp_out 13 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/14-gemmascope-mlp-65k blocks.14.hook_mlp_out 14 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/15-gemmascope-mlp-65k blocks.15.hook_mlp_out 15 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/16-gemmascope-mlp-65k blocks.16.hook_mlp_out 16 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/17-gemmascope-mlp-65k blocks.17.hook_mlp_out 17 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/18-gemmascope-mlp-65k blocks.18.hook_mlp_out 18 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/19-gemmascope-mlp-65k blocks.19.hook_mlp_out 19 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/20-gemmascope-mlp-65k blocks.20.hook_mlp_out 20 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/21-gemmascope-mlp-65k blocks.21.hook_mlp_out 21 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/22-gemmascope-mlp-65k blocks.22.hook_mlp_out 22 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/23-gemmascope-mlp-65k blocks.23.hook_mlp_out 23 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/24-gemmascope-mlp-65k blocks.24.hook_mlp_out 24 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/25-gemmascope-mlp-65k blocks.25.hook_mlp_out 25 65536 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-2b-pt-res","title":"gemma-scope-2b-pt-res","text":"<ul> <li>Huggingface Repo: google/gemma-scope-2b-pt-res</li> <li>model: gemma-2-2b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations embedding/width_4k/average_l0_6Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted embedding/width_4k/average_l0_44Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted embedding/width_4k/average_l0_21Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted embedding/width_4k/average_l0_111Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_105Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_13Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_226Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_25Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_46Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_10Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_102Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_20Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_250Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_40Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_13Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_141Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_142Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_24Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_304Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_53Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_14Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_142Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_28Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_315Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_59Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_124Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_125Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_17Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_281Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_31Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_60Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_143Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-16k__l0-143 blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_18Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-16k__l0-18 blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_309Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-16k__l0-309 blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_34Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-16k__l0-34 blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_68Load this SAE jumprelu blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_144Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_19Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_301Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_36Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_70Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_137Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_20Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_285Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_36Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_69Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_142Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_20Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_301Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_37Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_71Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_151Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_21Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_340Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_37Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_73Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_166Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_21Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_39Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_395Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_77Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_168Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_22Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_393Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_41Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_80Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_176Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-16k__l0-176 blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_22Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-16k__l0-22 blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_41Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-16k__l0-41 blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_445Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-16k__l0-445 blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_82Load this SAE jumprelu blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_173Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_23Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_403Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_43Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_83Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_84Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_173Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_23Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_388Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_43Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_83Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_84Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_150Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_23Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_308Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_41Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_78Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_154Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_23Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_335Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_42Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_78Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_150Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_23Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_304Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_42Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_77Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_138Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_23Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_280Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_40Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_74Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_137Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-16k__l0-137 blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_23Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-16k__l0-23 blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_279Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-16k__l0-279 blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_40Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-16k__l0-40 blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_73Load this SAE jumprelu blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_139Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_22Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_294Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_38Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_71Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_139Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_22Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_301Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_38Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_70Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_147Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_21Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_349Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_38Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_72Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_157Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_21Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_38Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_404Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_74Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_75Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_158Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_20Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_38Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_457Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_73Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_116Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_16Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_28Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_285Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_55Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_5/width_1m/average_l0_114Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-1m__l0-114 blocks.5.hook_resid_post 5 1048576 1024 monology/pile-uncopyrighted layer_5/width_1m/average_l0_13Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-1m__l0-13 blocks.5.hook_resid_post 5 1048576 1024 monology/pile-uncopyrighted layer_5/width_1m/average_l0_21Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-1m__l0-21 blocks.5.hook_resid_post 5 1048576 1024 monology/pile-uncopyrighted layer_5/width_1m/average_l0_36Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-1m__l0-36 blocks.5.hook_resid_post 5 1048576 1024 monology/pile-uncopyrighted layer_5/width_1m/average_l0_63Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-1m__l0-63 blocks.5.hook_resid_post 5 1048576 1024 monology/pile-uncopyrighted layer_5/width_1m/average_l0_9Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-1m__l0-9 blocks.5.hook_resid_post 5 1048576 1024 monology/pile-uncopyrighted layer_12/width_1m/average_l0_107Load this SAE jumprelu blocks.12.hook_resid_post 12 1048576 1024 monology/pile-uncopyrighted layer_12/width_1m/average_l0_19Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-1m__l0-19 blocks.12.hook_resid_post 12 1048576 1024 monology/pile-uncopyrighted layer_12/width_1m/average_l0_207Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-1m__l0-207 blocks.12.hook_resid_post 12 1048576 1024 monology/pile-uncopyrighted layer_12/width_1m/average_l0_26Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-1m__l0-26 blocks.12.hook_resid_post 12 1048576 1024 monology/pile-uncopyrighted layer_12/width_1m/average_l0_58Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-1m__l0-58 blocks.12.hook_resid_post 12 1048576 1024 monology/pile-uncopyrighted layer_12/width_1m/average_l0_73Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-1m__l0-73 blocks.12.hook_resid_post 12 1048576 1024 monology/pile-uncopyrighted layer_19/width_1m/average_l0_157Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-1m__l0-157 blocks.19.hook_resid_post 19 1048576 1024 monology/pile-uncopyrighted layer_19/width_1m/average_l0_16Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-1m__l0-16 blocks.19.hook_resid_post 19 1048576 1024 monology/pile-uncopyrighted layer_19/width_1m/average_l0_18Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-1m__l0-18 blocks.19.hook_resid_post 19 1048576 1024 monology/pile-uncopyrighted layer_19/width_1m/average_l0_29Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-1m__l0-29 blocks.19.hook_resid_post 19 1048576 1024 monology/pile-uncopyrighted layer_19/width_1m/average_l0_50Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-1m__l0-50 blocks.19.hook_resid_post 19 1048576 1024 monology/pile-uncopyrighted layer_19/width_1m/average_l0_88Load this SAE jumprelu blocks.19.hook_resid_post 19 1048576 1024 monology/pile-uncopyrighted layer_12/width_262k/average_l0_11Load this SAE jumprelu blocks.12.hook_resid_post 12 262144 1024 monology/pile-uncopyrighted layer_12/width_262k/average_l0_121Load this SAE jumprelu blocks.12.hook_resid_post 12 262144 1024 monology/pile-uncopyrighted layer_12/width_262k/average_l0_21Load this SAE jumprelu blocks.12.hook_resid_post 12 262144 1024 monology/pile-uncopyrighted layer_12/width_262k/average_l0_243Load this SAE jumprelu blocks.12.hook_resid_post 12 262144 1024 monology/pile-uncopyrighted layer_12/width_262k/average_l0_36Load this SAE jumprelu blocks.12.hook_resid_post 12 262144 1024 monology/pile-uncopyrighted layer_12/width_262k/average_l0_67Load this SAE jumprelu blocks.12.hook_resid_post 12 262144 1024 monology/pile-uncopyrighted layer_12/width_32k/average_l0_12Load this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted layer_12/width_32k/average_l0_155Load this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted layer_12/width_32k/average_l0_22Load this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted layer_12/width_32k/average_l0_360Load this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted layer_12/width_32k/average_l0_40Load this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted layer_12/width_32k/average_l0_76Load this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted layer_12/width_524k/average_l0_115Load this SAE jumprelu blocks.12.hook_resid_post 12 524288 1024 monology/pile-uncopyrighted layer_12/width_524k/average_l0_22Load this SAE jumprelu blocks.12.hook_resid_post 12 524288 1024 monology/pile-uncopyrighted layer_12/width_524k/average_l0_227Load this SAE jumprelu blocks.12.hook_resid_post 12 524288 1024 monology/pile-uncopyrighted layer_12/width_524k/average_l0_29Load this SAE jumprelu blocks.12.hook_resid_post 12 524288 1024 monology/pile-uncopyrighted layer_12/width_524k/average_l0_46Load this SAE jumprelu blocks.12.hook_resid_post 12 524288 1024 monology/pile-uncopyrighted layer_12/width_524k/average_l0_65Load this SAE jumprelu blocks.12.hook_resid_post 12 524288 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_12Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_129Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_20Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_264Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_36Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_67Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_11Load this SAE jumprelu blocks.0.hook_resid_post 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_17Load this SAE jumprelu blocks.0.hook_resid_post 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_27Load this SAE jumprelu blocks.0.hook_resid_post 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_43Load this SAE jumprelu blocks.0.hook_resid_post 0 65536 1024 monology/pile-uncopyrighted layer_0/width_65k/average_l0_73Load this SAE jumprelu blocks.0.hook_resid_post 0 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_121Load this SAE jumprelu blocks.1.hook_resid_post 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_16Load this SAE jumprelu blocks.1.hook_resid_post 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_30Load this SAE jumprelu blocks.1.hook_resid_post 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_54Load this SAE jumprelu blocks.1.hook_resid_post 1 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/average_l0_9Load this SAE jumprelu blocks.1.hook_resid_post 1 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_11Load this SAE jumprelu blocks.2.hook_resid_post 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_169Load this SAE jumprelu blocks.2.hook_resid_post 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_20Load this SAE jumprelu blocks.2.hook_resid_post 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_37Load this SAE jumprelu blocks.2.hook_resid_post 2 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/average_l0_77Load this SAE jumprelu blocks.2.hook_resid_post 2 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_13Load this SAE jumprelu blocks.3.hook_resid_post 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_193Load this SAE jumprelu blocks.3.hook_resid_post 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_23Load this SAE jumprelu blocks.3.hook_resid_post 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_42Load this SAE jumprelu blocks.3.hook_resid_post 3 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/average_l0_89Load this SAE jumprelu blocks.3.hook_resid_post 3 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_14Load this SAE jumprelu blocks.4.hook_resid_post 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_177Load this SAE jumprelu blocks.4.hook_resid_post 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_25Load this SAE jumprelu blocks.4.hook_resid_post 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_46Load this SAE jumprelu blocks.4.hook_resid_post 4 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/average_l0_89Load this SAE jumprelu blocks.4.hook_resid_post 4 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_105Load this SAE jumprelu blocks.5.hook_resid_post 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_17Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-65k__l0-17 blocks.5.hook_resid_post 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_211Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-65k__l0-211 blocks.5.hook_resid_post 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_29Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-65k__l0-29 blocks.5.hook_resid_post 5 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/average_l0_53Load this SAE jumprelu gemma-2-2b/5-gemmascope-res-65k__l0-53 blocks.5.hook_resid_post 5 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_107Load this SAE jumprelu blocks.6.hook_resid_post 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_17Load this SAE jumprelu blocks.6.hook_resid_post 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_208Load this SAE jumprelu blocks.6.hook_resid_post 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_30Load this SAE jumprelu blocks.6.hook_resid_post 6 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/average_l0_56Load this SAE jumprelu blocks.6.hook_resid_post 6 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_107Load this SAE jumprelu blocks.7.hook_resid_post 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_18Load this SAE jumprelu blocks.7.hook_resid_post 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_203Load this SAE jumprelu blocks.7.hook_resid_post 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_31Load this SAE jumprelu blocks.7.hook_resid_post 7 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/average_l0_57Load this SAE jumprelu blocks.7.hook_resid_post 7 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_111Load this SAE jumprelu blocks.8.hook_resid_post 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_19Load this SAE jumprelu blocks.8.hook_resid_post 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_213Load this SAE jumprelu blocks.8.hook_resid_post 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_33Load this SAE jumprelu blocks.8.hook_resid_post 8 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/average_l0_59Load this SAE jumprelu blocks.8.hook_resid_post 8 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_118Load this SAE jumprelu blocks.9.hook_resid_post 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_19Load this SAE jumprelu blocks.9.hook_resid_post 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_240Load this SAE jumprelu blocks.9.hook_resid_post 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_34Load this SAE jumprelu blocks.9.hook_resid_post 9 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/average_l0_61Load this SAE jumprelu blocks.9.hook_resid_post 9 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_128Load this SAE jumprelu blocks.10.hook_resid_post 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_20Load this SAE jumprelu blocks.10.hook_resid_post 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_265Load this SAE jumprelu blocks.10.hook_resid_post 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_36Load this SAE jumprelu blocks.10.hook_resid_post 10 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/average_l0_66Load this SAE jumprelu blocks.10.hook_resid_post 10 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_134Load this SAE jumprelu blocks.11.hook_resid_post 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_21Load this SAE jumprelu blocks.11.hook_resid_post 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_273Load this SAE jumprelu blocks.11.hook_resid_post 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_37Load this SAE jumprelu blocks.11.hook_resid_post 11 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/average_l0_70Load this SAE jumprelu blocks.11.hook_resid_post 11 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_141Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-65k__l0-141 blocks.12.hook_resid_post 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_21Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-65k__l0-21 blocks.12.hook_resid_post 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_297Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-65k__l0-297 blocks.12.hook_resid_post 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_38Load this SAE jumprelu gemma-2-2b/12-gemmascope-res-65k__l0-38 blocks.12.hook_resid_post 12 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/average_l0_72Load this SAE jumprelu blocks.12.hook_resid_post 12 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_142Load this SAE jumprelu blocks.13.hook_resid_post 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_22Load this SAE jumprelu blocks.13.hook_resid_post 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_288Load this SAE jumprelu blocks.13.hook_resid_post 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_40Load this SAE jumprelu blocks.13.hook_resid_post 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_74Load this SAE jumprelu blocks.13.hook_resid_post 13 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/average_l0_75Load this SAE jumprelu blocks.13.hook_resid_post 13 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_144Load this SAE jumprelu blocks.14.hook_resid_post 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_21Load this SAE jumprelu blocks.14.hook_resid_post 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_284Load this SAE jumprelu blocks.14.hook_resid_post 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_40Load this SAE jumprelu blocks.14.hook_resid_post 14 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/average_l0_73Load this SAE jumprelu blocks.14.hook_resid_post 14 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_127Load this SAE jumprelu blocks.15.hook_resid_post 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_21Load this SAE jumprelu blocks.15.hook_resid_post 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_240Load this SAE jumprelu blocks.15.hook_resid_post 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_38Load this SAE jumprelu blocks.15.hook_resid_post 15 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/average_l0_68Load this SAE jumprelu blocks.15.hook_resid_post 15 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_128Load this SAE jumprelu blocks.16.hook_resid_post 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_21Load this SAE jumprelu blocks.16.hook_resid_post 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_244Load this SAE jumprelu blocks.16.hook_resid_post 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_38Load this SAE jumprelu blocks.16.hook_resid_post 16 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/average_l0_69Load this SAE jumprelu blocks.16.hook_resid_post 16 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_125Load this SAE jumprelu blocks.17.hook_resid_post 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_21Load this SAE jumprelu blocks.17.hook_resid_post 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_233Load this SAE jumprelu blocks.17.hook_resid_post 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_38Load this SAE jumprelu blocks.17.hook_resid_post 17 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/average_l0_68Load this SAE jumprelu blocks.17.hook_resid_post 17 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_116Load this SAE jumprelu blocks.18.hook_resid_post 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_117Load this SAE jumprelu blocks.18.hook_resid_post 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_21Load this SAE jumprelu blocks.18.hook_resid_post 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_216Load this SAE jumprelu blocks.18.hook_resid_post 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_36Load this SAE jumprelu blocks.18.hook_resid_post 18 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/average_l0_64Load this SAE jumprelu blocks.18.hook_resid_post 18 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_115Load this SAE jumprelu blocks.19.hook_resid_post 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_21Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-65k__l0-21 blocks.19.hook_resid_post 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_216Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-65k__l0-216 blocks.19.hook_resid_post 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_35Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-65k__l0-35 blocks.19.hook_resid_post 19 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/average_l0_63Load this SAE jumprelu gemma-2-2b/19-gemmascope-res-65k__l0-63 blocks.19.hook_resid_post 19 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_114Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_20Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_221Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_34Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_61Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_111Load this SAE jumprelu blocks.21.hook_resid_post 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_112Load this SAE jumprelu blocks.21.hook_resid_post 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_20Load this SAE jumprelu blocks.21.hook_resid_post 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_225Load this SAE jumprelu blocks.21.hook_resid_post 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_33Load this SAE jumprelu blocks.21.hook_resid_post 21 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/average_l0_61Load this SAE jumprelu blocks.21.hook_resid_post 21 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_116Load this SAE jumprelu blocks.22.hook_resid_post 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_117Load this SAE jumprelu blocks.22.hook_resid_post 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_20Load this SAE jumprelu blocks.22.hook_resid_post 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_248Load this SAE jumprelu blocks.22.hook_resid_post 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_33Load this SAE jumprelu blocks.22.hook_resid_post 22 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/average_l0_62Load this SAE jumprelu blocks.22.hook_resid_post 22 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_123Load this SAE jumprelu blocks.23.hook_resid_post 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_124Load this SAE jumprelu blocks.23.hook_resid_post 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_20Load this SAE jumprelu blocks.23.hook_resid_post 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_272Load this SAE jumprelu blocks.23.hook_resid_post 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_35Load this SAE jumprelu blocks.23.hook_resid_post 23 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/average_l0_64Load this SAE jumprelu blocks.23.hook_resid_post 23 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_124Load this SAE jumprelu blocks.24.hook_resid_post 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_19Load this SAE jumprelu blocks.24.hook_resid_post 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_273Load this SAE jumprelu blocks.24.hook_resid_post 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_34Load this SAE jumprelu blocks.24.hook_resid_post 24 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/average_l0_63Load this SAE jumprelu blocks.24.hook_resid_post 24 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_15Load this SAE jumprelu blocks.25.hook_resid_post 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_197Load this SAE jumprelu blocks.25.hook_resid_post 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_26Load this SAE jumprelu blocks.25.hook_resid_post 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_48Load this SAE jumprelu blocks.25.hook_resid_post 25 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/average_l0_93Load this SAE jumprelu blocks.25.hook_resid_post 25 65536 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-2b-pt-res-canonical","title":"gemma-scope-2b-pt-res-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-2b-pt-res</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> <li>Publication</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/0-gemmascope-res-16k blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/1-gemmascope-res-16k blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/2-gemmascope-res-16k blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/3-gemmascope-res-16k blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/4-gemmascope-res-16k blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/5-gemmascope-res-16k blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/6-gemmascope-res-16k blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/7-gemmascope-res-16k blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/8-gemmascope-res-16k blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/9-gemmascope-res-16k blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/10-gemmascope-res-16k blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/11-gemmascope-res-16k blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-res-16k blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/13-gemmascope-res-16k blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/14-gemmascope-res-16k blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/15-gemmascope-res-16k blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/16-gemmascope-res-16k blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/17-gemmascope-res-16k blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/18-gemmascope-res-16k blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/19-gemmascope-res-16k blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/20-gemmascope-res-16k blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/21-gemmascope-res-16k blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/22-gemmascope-res-16k blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/23-gemmascope-res-16k blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/24-gemmascope-res-16k blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/canonicalLoad this SAE jumprelu gemma-2-2b/25-gemmascope-res-16k blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_5/width_1m/canonicalLoad this SAE jumprelu gemma-2-2b/5-gemmascope-res-1m blocks.5.hook_resid_post 5 1048576 1024 monology/pile-uncopyrighted layer_12/width_1m/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-res-1m blocks.12.hook_resid_post 12 1048576 1024 monology/pile-uncopyrighted layer_19/width_1m/canonicalLoad this SAE jumprelu gemma-2-2b/19-gemmascope-res-1m blocks.19.hook_resid_post 19 1048576 1024 monology/pile-uncopyrighted layer_12/width_262k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-res-262k blocks.12.hook_resid_post 12 262144 1024 monology/pile-uncopyrighted layer_12/width_32k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-res-32k blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted layer_12/width_524k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-res-524k blocks.12.hook_resid_post 12 524288 1024 monology/pile-uncopyrighted layer_0/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/0-gemmascope-res-65k blocks.0.hook_resid_post 0 65536 1024 monology/pile-uncopyrighted layer_1/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/1-gemmascope-res-65k blocks.1.hook_resid_post 1 65536 1024 monology/pile-uncopyrighted layer_2/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/2-gemmascope-res-65k blocks.2.hook_resid_post 2 65536 1024 monology/pile-uncopyrighted layer_3/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/3-gemmascope-res-65k blocks.3.hook_resid_post 3 65536 1024 monology/pile-uncopyrighted layer_4/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/4-gemmascope-res-65k blocks.4.hook_resid_post 4 65536 1024 monology/pile-uncopyrighted layer_5/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/5-gemmascope-res-65k blocks.5.hook_resid_post 5 65536 1024 monology/pile-uncopyrighted layer_6/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/6-gemmascope-res-65k blocks.6.hook_resid_post 6 65536 1024 monology/pile-uncopyrighted layer_7/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/7-gemmascope-res-65k blocks.7.hook_resid_post 7 65536 1024 monology/pile-uncopyrighted layer_8/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/8-gemmascope-res-65k blocks.8.hook_resid_post 8 65536 1024 monology/pile-uncopyrighted layer_9/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/9-gemmascope-res-65k blocks.9.hook_resid_post 9 65536 1024 monology/pile-uncopyrighted layer_10/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/10-gemmascope-res-65k blocks.10.hook_resid_post 10 65536 1024 monology/pile-uncopyrighted layer_11/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/11-gemmascope-res-65k blocks.11.hook_resid_post 11 65536 1024 monology/pile-uncopyrighted layer_12/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/12-gemmascope-res-65k blocks.12.hook_resid_post 12 65536 1024 monology/pile-uncopyrighted layer_13/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/13-gemmascope-res-65k blocks.13.hook_resid_post 13 65536 1024 monology/pile-uncopyrighted layer_14/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/14-gemmascope-res-65k blocks.14.hook_resid_post 14 65536 1024 monology/pile-uncopyrighted layer_15/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/15-gemmascope-res-65k blocks.15.hook_resid_post 15 65536 1024 monology/pile-uncopyrighted layer_16/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/16-gemmascope-res-65k blocks.16.hook_resid_post 16 65536 1024 monology/pile-uncopyrighted layer_17/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/17-gemmascope-res-65k blocks.17.hook_resid_post 17 65536 1024 monology/pile-uncopyrighted layer_18/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/18-gemmascope-res-65k blocks.18.hook_resid_post 18 65536 1024 monology/pile-uncopyrighted layer_19/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/19-gemmascope-res-65k blocks.19.hook_resid_post 19 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/20-gemmascope-res-65k blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_21/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/21-gemmascope-res-65k blocks.21.hook_resid_post 21 65536 1024 monology/pile-uncopyrighted layer_22/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/22-gemmascope-res-65k blocks.22.hook_resid_post 22 65536 1024 monology/pile-uncopyrighted layer_23/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/23-gemmascope-res-65k blocks.23.hook_resid_post 23 65536 1024 monology/pile-uncopyrighted layer_24/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/24-gemmascope-res-65k blocks.24.hook_resid_post 24 65536 1024 monology/pile-uncopyrighted layer_25/width_65k/canonicalLoad this SAE jumprelu gemma-2-2b/25-gemmascope-res-65k blocks.25.hook_resid_post 25 65536 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-it-res","title":"gemma-scope-9b-it-res","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-it-res</li> <li>model: gemma-2-9b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_20/width_131k/average_l0_13Load this SAE jumprelu blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_153Load this SAE jumprelu blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_24Load this SAE jumprelu blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_43Load this SAE jumprelu blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_81Load this SAE jumprelu blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_14Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_189Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_25Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_47Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_91Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_109Load this SAE jumprelu blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_13Load this SAE jumprelu blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_22Load this SAE jumprelu blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_37Load this SAE jumprelu blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_63Load this SAE jumprelu blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_14Load this SAE jumprelu blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_142Load this SAE jumprelu blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_24Load this SAE jumprelu blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_43Load this SAE jumprelu blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_76Load this SAE jumprelu blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_121Load this SAE jumprelu blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_13Load this SAE jumprelu blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_22Load this SAE jumprelu blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_39Load this SAE jumprelu blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_67Load this SAE jumprelu blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_14Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_186Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_26Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_47Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_88Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-it-res-canonical","title":"gemma-scope-9b-it-res-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-it-res</li> <li>model: gemma-2-9b-it</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_9/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b-it/9-gemmascope-res-16k blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b-it/20-gemmascope-res-16k blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b-it/31-gemmascope-res-16k blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_9/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b-it/9-gemmascope-res-131k blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b-it/20-gemmascope-res-131k blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b-it/31-gemmascope-res-131k blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-pt-att","title":"gemma-scope-9b-pt-att","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-pt-att</li> <li>model: gemma-2-9b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/average_l0_12Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_16Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_25Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_38Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_61Load this SAE jumprelu blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_8Load this SAE jumprelu blocks.0.attn.hook_z 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_11Load this SAE jumprelu blocks.0.attn.hook_z 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_15Load this SAE jumprelu blocks.0.attn.hook_z 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_22Load this SAE jumprelu blocks.0.attn.hook_z 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_33Load this SAE jumprelu blocks.0.attn.hook_z 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_55Load this SAE jumprelu blocks.0.attn.hook_z 0 131072 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_17Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_34Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_77Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_147Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_266Load this SAE jumprelu blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_8Load this SAE jumprelu blocks.1.attn.hook_z 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_12Load this SAE jumprelu blocks.1.attn.hook_z 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_18Load this SAE jumprelu blocks.1.attn.hook_z 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_29Load this SAE jumprelu blocks.1.attn.hook_z 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_63Load this SAE jumprelu blocks.1.attn.hook_z 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_116Load this SAE jumprelu blocks.1.attn.hook_z 1 131072 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_18Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_33Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_63Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_132Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_301Load this SAE jumprelu blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_16Load this SAE jumprelu blocks.10.attn.hook_z 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_28Load this SAE jumprelu blocks.10.attn.hook_z 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_51Load this SAE jumprelu blocks.10.attn.hook_z 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_97Load this SAE jumprelu blocks.10.attn.hook_z 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_199Load this SAE jumprelu blocks.10.attn.hook_z 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_440Load this SAE jumprelu blocks.10.attn.hook_z 10 131072 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_18Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_34Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_67Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_153Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_366Load this SAE jumprelu blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_17Load this SAE jumprelu blocks.11.attn.hook_z 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_29Load this SAE jumprelu blocks.11.attn.hook_z 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_54Load this SAE jumprelu blocks.11.attn.hook_z 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_104Load this SAE jumprelu blocks.11.attn.hook_z 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_241Load this SAE jumprelu blocks.11.attn.hook_z 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_552Load this SAE jumprelu blocks.11.attn.hook_z 11 131072 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_19Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_35Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_68Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_149Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_337Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_654Load this SAE jumprelu blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_17Load this SAE jumprelu blocks.12.attn.hook_z 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_29Load this SAE jumprelu blocks.12.attn.hook_z 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_55Load this SAE jumprelu blocks.12.attn.hook_z 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_110Load this SAE jumprelu blocks.12.attn.hook_z 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_237Load this SAE jumprelu blocks.12.attn.hook_z 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_525Load this SAE jumprelu blocks.12.attn.hook_z 12 131072 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_20Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_38Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_77Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_170Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_380Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_675Load this SAE jumprelu blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_18Load this SAE jumprelu blocks.13.attn.hook_z 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_33Load this SAE jumprelu blocks.13.attn.hook_z 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_64Load this SAE jumprelu blocks.13.attn.hook_z 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_126Load this SAE jumprelu blocks.13.attn.hook_z 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_283Load this SAE jumprelu blocks.13.attn.hook_z 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_611Load this SAE jumprelu blocks.13.attn.hook_z 13 131072 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_21Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_40Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_81Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_179Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_411Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_767Load this SAE jumprelu blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_18Load this SAE jumprelu blocks.14.attn.hook_z 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_35Load this SAE jumprelu blocks.14.attn.hook_z 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_67Load this SAE jumprelu blocks.14.attn.hook_z 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_131Load this SAE jumprelu blocks.14.attn.hook_z 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_306Load this SAE jumprelu blocks.14.attn.hook_z 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_650Load this SAE jumprelu blocks.14.attn.hook_z 14 131072 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_21Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_40Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_79Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_168Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_344Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_638Load this SAE jumprelu blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_19Load this SAE jumprelu blocks.15.attn.hook_z 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_35Load this SAE jumprelu blocks.15.attn.hook_z 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_67Load this SAE jumprelu blocks.15.attn.hook_z 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_130Load this SAE jumprelu blocks.15.attn.hook_z 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_283Load this SAE jumprelu blocks.15.attn.hook_z 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_540Load this SAE jumprelu blocks.15.attn.hook_z 15 131072 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_21Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_40Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_81Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_172Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_376Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_705Load this SAE jumprelu blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_19Load this SAE jumprelu blocks.16.attn.hook_z 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_36Load this SAE jumprelu blocks.16.attn.hook_z 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_71Load this SAE jumprelu blocks.16.attn.hook_z 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_140Load this SAE jumprelu blocks.16.attn.hook_z 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_298Load this SAE jumprelu blocks.16.attn.hook_z 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_621Load this SAE jumprelu blocks.16.attn.hook_z 16 131072 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_24Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_50Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_110Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_227Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_435Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_719Load this SAE jumprelu blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_22Load this SAE jumprelu blocks.17.attn.hook_z 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_44Load this SAE jumprelu blocks.17.attn.hook_z 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_90Load this SAE jumprelu blocks.17.attn.hook_z 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_191Load this SAE jumprelu blocks.17.attn.hook_z 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_380Load this SAE jumprelu blocks.17.attn.hook_z 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_672Load this SAE jumprelu blocks.17.attn.hook_z 17 131072 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_21Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_40Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_80Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_171Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_352Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_646Load this SAE jumprelu blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_19Load this SAE jumprelu blocks.18.attn.hook_z 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_35Load this SAE jumprelu blocks.18.attn.hook_z 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_69Load this SAE jumprelu blocks.18.attn.hook_z 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_133Load this SAE jumprelu blocks.18.attn.hook_z 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_294Load this SAE jumprelu blocks.18.attn.hook_z 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_557Load this SAE jumprelu blocks.18.attn.hook_z 18 131072 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_21Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_41Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_86Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_186Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_360Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_661Load this SAE jumprelu blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_19Load this SAE jumprelu blocks.19.attn.hook_z 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_38Load this SAE jumprelu blocks.19.attn.hook_z 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_71Load this SAE jumprelu blocks.19.attn.hook_z 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_152Load this SAE jumprelu blocks.19.attn.hook_z 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_307Load this SAE jumprelu blocks.19.attn.hook_z 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_571Load this SAE jumprelu blocks.19.attn.hook_z 19 131072 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_15Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_30Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_69Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_180Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_384Load this SAE jumprelu blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_7Load this SAE jumprelu blocks.2.attn.hook_z 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_11Load this SAE jumprelu blocks.2.attn.hook_z 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_18Load this SAE jumprelu blocks.2.attn.hook_z 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_32Load this SAE jumprelu blocks.2.attn.hook_z 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_62Load this SAE jumprelu blocks.2.attn.hook_z 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_135Load this SAE jumprelu blocks.2.attn.hook_z 2 131072 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_20Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_39Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_76Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_158Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_342Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_674Load this SAE jumprelu blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_18Load this SAE jumprelu blocks.20.attn.hook_z 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_34Load this SAE jumprelu blocks.20.attn.hook_z 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_65Load this SAE jumprelu blocks.20.attn.hook_z 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_125Load this SAE jumprelu blocks.20.attn.hook_z 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_270Load this SAE jumprelu blocks.20.attn.hook_z 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_558Load this SAE jumprelu blocks.20.attn.hook_z 20 131072 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_21Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_41Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_86Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_195Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_420Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_792Load this SAE jumprelu blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_18Load this SAE jumprelu blocks.21.attn.hook_z 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_35Load this SAE jumprelu blocks.21.attn.hook_z 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_71Load this SAE jumprelu blocks.21.attn.hook_z 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_150Load this SAE jumprelu blocks.21.attn.hook_z 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_333Load this SAE jumprelu blocks.21.attn.hook_z 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_665Load this SAE jumprelu blocks.21.attn.hook_z 21 131072 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_20Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_36Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_70Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_141Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_289Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_569Load this SAE jumprelu blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_17Load this SAE jumprelu blocks.22.attn.hook_z 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_32Load this SAE jumprelu blocks.22.attn.hook_z 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_59Load this SAE jumprelu blocks.22.attn.hook_z 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_115Load this SAE jumprelu blocks.22.attn.hook_z 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_231Load this SAE jumprelu blocks.22.attn.hook_z 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_446Load this SAE jumprelu blocks.22.attn.hook_z 22 131072 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_21Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_41Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_80Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_173Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_356Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_649Load this SAE jumprelu blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_19Load this SAE jumprelu blocks.23.attn.hook_z 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_36Load this SAE jumprelu blocks.23.attn.hook_z 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_66Load this SAE jumprelu blocks.23.attn.hook_z 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_134Load this SAE jumprelu blocks.23.attn.hook_z 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_288Load this SAE jumprelu blocks.23.attn.hook_z 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_568Load this SAE jumprelu blocks.23.attn.hook_z 23 131072 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_21Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_40Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_79Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_167Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_348Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_615Load this SAE jumprelu blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_19Load this SAE jumprelu blocks.24.attn.hook_z 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_35Load this SAE jumprelu blocks.24.attn.hook_z 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_66Load this SAE jumprelu blocks.24.attn.hook_z 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_130Load this SAE jumprelu blocks.24.attn.hook_z 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_273Load this SAE jumprelu blocks.24.attn.hook_z 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_542Load this SAE jumprelu blocks.24.attn.hook_z 24 131072 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_19Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_36Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_73Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_156Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_371Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_686Load this SAE jumprelu blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_17Load this SAE jumprelu blocks.25.attn.hook_z 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_31Load this SAE jumprelu blocks.25.attn.hook_z 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_59Load this SAE jumprelu blocks.25.attn.hook_z 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_115Load this SAE jumprelu blocks.25.attn.hook_z 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_261Load this SAE jumprelu blocks.25.attn.hook_z 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_605Load this SAE jumprelu blocks.25.attn.hook_z 25 131072 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_20Load this SAE jumprelu blocks.26.attn.hook_z 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_38Load this SAE jumprelu blocks.26.attn.hook_z 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_75Load this SAE jumprelu blocks.26.attn.hook_z 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_159Load this SAE jumprelu blocks.26.attn.hook_z 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_336Load this SAE jumprelu blocks.26.attn.hook_z 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_634Load this SAE jumprelu blocks.26.attn.hook_z 26 16384 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_18Load this SAE jumprelu blocks.26.attn.hook_z 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_32Load this SAE jumprelu blocks.26.attn.hook_z 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_62Load this SAE jumprelu blocks.26.attn.hook_z 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_120Load this SAE jumprelu blocks.26.attn.hook_z 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_267Load this SAE jumprelu blocks.26.attn.hook_z 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_525Load this SAE jumprelu blocks.26.attn.hook_z 26 131072 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_18Load this SAE jumprelu blocks.27.attn.hook_z 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_33Load this SAE jumprelu blocks.27.attn.hook_z 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_64Load this SAE jumprelu blocks.27.attn.hook_z 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_136Load this SAE jumprelu blocks.27.attn.hook_z 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_306Load this SAE jumprelu blocks.27.attn.hook_z 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_613Load this SAE jumprelu blocks.27.attn.hook_z 27 16384 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_16Load this SAE jumprelu blocks.27.attn.hook_z 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_28Load this SAE jumprelu blocks.27.attn.hook_z 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_53Load this SAE jumprelu blocks.27.attn.hook_z 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_102Load this SAE jumprelu blocks.27.attn.hook_z 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_211Load this SAE jumprelu blocks.27.attn.hook_z 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_458Load this SAE jumprelu blocks.27.attn.hook_z 27 131072 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_20Load this SAE jumprelu blocks.28.attn.hook_z 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_37Load this SAE jumprelu blocks.28.attn.hook_z 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_71Load this SAE jumprelu blocks.28.attn.hook_z 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_143Load this SAE jumprelu blocks.28.attn.hook_z 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_279Load this SAE jumprelu blocks.28.attn.hook_z 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_498Load this SAE jumprelu blocks.28.attn.hook_z 28 16384 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_19Load this SAE jumprelu blocks.28.attn.hook_z 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_32Load this SAE jumprelu blocks.28.attn.hook_z 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_59Load this SAE jumprelu blocks.28.attn.hook_z 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_115Load this SAE jumprelu blocks.28.attn.hook_z 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_230Load this SAE jumprelu blocks.28.attn.hook_z 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_452Load this SAE jumprelu blocks.28.attn.hook_z 28 131072 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_18Load this SAE jumprelu blocks.29.attn.hook_z 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_35Load this SAE jumprelu blocks.29.attn.hook_z 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_76Load this SAE jumprelu blocks.29.attn.hook_z 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_171Load this SAE jumprelu blocks.29.attn.hook_z 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_308Load this SAE jumprelu blocks.29.attn.hook_z 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_559Load this SAE jumprelu blocks.29.attn.hook_z 29 16384 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_17Load this SAE jumprelu blocks.29.attn.hook_z 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_30Load this SAE jumprelu blocks.29.attn.hook_z 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_57Load this SAE jumprelu blocks.29.attn.hook_z 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_128Load this SAE jumprelu blocks.29.attn.hook_z 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_265Load this SAE jumprelu blocks.29.attn.hook_z 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_446Load this SAE jumprelu blocks.29.attn.hook_z 29 131072 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_23Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_44Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_102Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_221Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_435Load this SAE jumprelu blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_10Load this SAE jumprelu blocks.3.attn.hook_z 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_17Load this SAE jumprelu blocks.3.attn.hook_z 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_31Load this SAE jumprelu blocks.3.attn.hook_z 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_58Load this SAE jumprelu blocks.3.attn.hook_z 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_119Load this SAE jumprelu blocks.3.attn.hook_z 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_252Load this SAE jumprelu blocks.3.attn.hook_z 3 131072 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_19Load this SAE jumprelu blocks.30.attn.hook_z 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_36Load this SAE jumprelu blocks.30.attn.hook_z 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_73Load this SAE jumprelu blocks.30.attn.hook_z 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_157Load this SAE jumprelu blocks.30.attn.hook_z 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_313Load this SAE jumprelu blocks.30.attn.hook_z 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_558Load this SAE jumprelu blocks.30.attn.hook_z 30 16384 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_17Load this SAE jumprelu blocks.30.attn.hook_z 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_29Load this SAE jumprelu blocks.30.attn.hook_z 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_55Load this SAE jumprelu blocks.30.attn.hook_z 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_109Load this SAE jumprelu blocks.30.attn.hook_z 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_236Load this SAE jumprelu blocks.30.attn.hook_z 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_491Load this SAE jumprelu blocks.30.attn.hook_z 30 131072 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_18Load this SAE jumprelu blocks.31.attn.hook_z 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_36Load this SAE jumprelu blocks.31.attn.hook_z 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_73Load this SAE jumprelu blocks.31.attn.hook_z 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_168Load this SAE jumprelu blocks.31.attn.hook_z 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_356Load this SAE jumprelu blocks.31.attn.hook_z 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_630Load this SAE jumprelu blocks.31.attn.hook_z 31 16384 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_16Load this SAE jumprelu blocks.31.attn.hook_z 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_29Load this SAE jumprelu blocks.31.attn.hook_z 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_56Load this SAE jumprelu blocks.31.attn.hook_z 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_117Load this SAE jumprelu blocks.31.attn.hook_z 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_265Load this SAE jumprelu blocks.31.attn.hook_z 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_543Load this SAE jumprelu blocks.31.attn.hook_z 31 131072 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_18Load this SAE jumprelu blocks.32.attn.hook_z 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_35Load this SAE jumprelu blocks.32.attn.hook_z 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_74Load this SAE jumprelu blocks.32.attn.hook_z 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_158Load this SAE jumprelu blocks.32.attn.hook_z 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_306Load this SAE jumprelu blocks.32.attn.hook_z 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_534Load this SAE jumprelu blocks.32.attn.hook_z 32 16384 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_16Load this SAE jumprelu blocks.32.attn.hook_z 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_31Load this SAE jumprelu blocks.32.attn.hook_z 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_56Load this SAE jumprelu blocks.32.attn.hook_z 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_117Load this SAE jumprelu blocks.32.attn.hook_z 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_248Load this SAE jumprelu blocks.32.attn.hook_z 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_464Load this SAE jumprelu blocks.32.attn.hook_z 32 131072 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_17Load this SAE jumprelu blocks.33.attn.hook_z 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_37Load this SAE jumprelu blocks.33.attn.hook_z 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_78Load this SAE jumprelu blocks.33.attn.hook_z 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_158Load this SAE jumprelu blocks.33.attn.hook_z 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_318Load this SAE jumprelu blocks.33.attn.hook_z 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_531Load this SAE jumprelu blocks.33.attn.hook_z 33 16384 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_16Load this SAE jumprelu blocks.33.attn.hook_z 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_28Load this SAE jumprelu blocks.33.attn.hook_z 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_58Load this SAE jumprelu blocks.33.attn.hook_z 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_128Load this SAE jumprelu blocks.33.attn.hook_z 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_248Load this SAE jumprelu blocks.33.attn.hook_z 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_471Load this SAE jumprelu blocks.33.attn.hook_z 33 131072 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_17Load this SAE jumprelu blocks.34.attn.hook_z 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_38Load this SAE jumprelu blocks.34.attn.hook_z 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_91Load this SAE jumprelu blocks.34.attn.hook_z 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_192Load this SAE jumprelu blocks.34.attn.hook_z 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_339Load this SAE jumprelu blocks.34.attn.hook_z 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_527Load this SAE jumprelu blocks.34.attn.hook_z 34 16384 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_15Load this SAE jumprelu blocks.34.attn.hook_z 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_29Load this SAE jumprelu blocks.34.attn.hook_z 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_63Load this SAE jumprelu blocks.34.attn.hook_z 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_199Load this SAE jumprelu blocks.34.attn.hook_z 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_291Load this SAE jumprelu blocks.34.attn.hook_z 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_483Load this SAE jumprelu blocks.34.attn.hook_z 34 131072 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_14Load this SAE jumprelu blocks.35.attn.hook_z 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_33Load this SAE jumprelu blocks.35.attn.hook_z 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_77Load this SAE jumprelu blocks.35.attn.hook_z 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_168Load this SAE jumprelu blocks.35.attn.hook_z 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_303Load this SAE jumprelu blocks.35.attn.hook_z 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_488Load this SAE jumprelu blocks.35.attn.hook_z 35 16384 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_13Load this SAE jumprelu blocks.35.attn.hook_z 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_26Load this SAE jumprelu blocks.35.attn.hook_z 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_54Load this SAE jumprelu blocks.35.attn.hook_z 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_124Load this SAE jumprelu blocks.35.attn.hook_z 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_258Load this SAE jumprelu blocks.35.attn.hook_z 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_427Load this SAE jumprelu blocks.35.attn.hook_z 35 131072 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_15Load this SAE jumprelu blocks.36.attn.hook_z 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_32Load this SAE jumprelu blocks.36.attn.hook_z 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_69Load this SAE jumprelu blocks.36.attn.hook_z 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_144Load this SAE jumprelu blocks.36.attn.hook_z 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_293Load this SAE jumprelu blocks.36.attn.hook_z 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_544Load this SAE jumprelu blocks.36.attn.hook_z 36 16384 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_16Load this SAE jumprelu blocks.36.attn.hook_z 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_26Load this SAE jumprelu blocks.36.attn.hook_z 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_51Load this SAE jumprelu blocks.36.attn.hook_z 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_105Load this SAE jumprelu blocks.36.attn.hook_z 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_229Load this SAE jumprelu blocks.36.attn.hook_z 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_455Load this SAE jumprelu blocks.36.attn.hook_z 36 131072 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_17Load this SAE jumprelu blocks.37.attn.hook_z 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_34Load this SAE jumprelu blocks.37.attn.hook_z 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_82Load this SAE jumprelu blocks.37.attn.hook_z 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_172Load this SAE jumprelu blocks.37.attn.hook_z 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_309Load this SAE jumprelu blocks.37.attn.hook_z 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_519Load this SAE jumprelu blocks.37.attn.hook_z 37 16384 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_15Load this SAE jumprelu blocks.37.attn.hook_z 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_28Load this SAE jumprelu blocks.37.attn.hook_z 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_55Load this SAE jumprelu blocks.37.attn.hook_z 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_124Load this SAE jumprelu blocks.37.attn.hook_z 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_248Load this SAE jumprelu blocks.37.attn.hook_z 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_450Load this SAE jumprelu blocks.37.attn.hook_z 37 131072 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_18Load this SAE jumprelu blocks.38.attn.hook_z 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_36Load this SAE jumprelu blocks.38.attn.hook_z 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_81Load this SAE jumprelu blocks.38.attn.hook_z 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_175Load this SAE jumprelu blocks.38.attn.hook_z 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_334Load this SAE jumprelu blocks.38.attn.hook_z 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_547Load this SAE jumprelu blocks.38.attn.hook_z 38 16384 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_17Load this SAE jumprelu blocks.38.attn.hook_z 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_30Load this SAE jumprelu blocks.38.attn.hook_z 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_60Load this SAE jumprelu blocks.38.attn.hook_z 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_135Load this SAE jumprelu blocks.38.attn.hook_z 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_284Load this SAE jumprelu blocks.38.attn.hook_z 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_489Load this SAE jumprelu blocks.38.attn.hook_z 38 131072 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_15Load this SAE jumprelu blocks.39.attn.hook_z 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_33Load this SAE jumprelu blocks.39.attn.hook_z 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_77Load this SAE jumprelu blocks.39.attn.hook_z 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_176Load this SAE jumprelu blocks.39.attn.hook_z 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_391Load this SAE jumprelu blocks.39.attn.hook_z 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_694Load this SAE jumprelu blocks.39.attn.hook_z 39 16384 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_17Load this SAE jumprelu blocks.39.attn.hook_z 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_27Load this SAE jumprelu blocks.39.attn.hook_z 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_54Load this SAE jumprelu blocks.39.attn.hook_z 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_120Load this SAE jumprelu blocks.39.attn.hook_z 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_273Load this SAE jumprelu blocks.39.attn.hook_z 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_604Load this SAE jumprelu blocks.39.attn.hook_z 39 131072 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_26Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_54Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_126Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_274Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_524Load this SAE jumprelu blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_12Load this SAE jumprelu blocks.4.attn.hook_z 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_21Load this SAE jumprelu blocks.4.attn.hook_z 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_38Load this SAE jumprelu blocks.4.attn.hook_z 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_75Load this SAE jumprelu blocks.4.attn.hook_z 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_163Load this SAE jumprelu blocks.4.attn.hook_z 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_330Load this SAE jumprelu blocks.4.attn.hook_z 4 131072 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_18Load this SAE jumprelu blocks.40.attn.hook_z 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_38Load this SAE jumprelu blocks.40.attn.hook_z 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_91Load this SAE jumprelu blocks.40.attn.hook_z 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_189Load this SAE jumprelu blocks.40.attn.hook_z 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_341Load this SAE jumprelu blocks.40.attn.hook_z 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_603Load this SAE jumprelu blocks.40.attn.hook_z 40 16384 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_16Load this SAE jumprelu blocks.40.attn.hook_z 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_30Load this SAE jumprelu blocks.40.attn.hook_z 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_64Load this SAE jumprelu blocks.40.attn.hook_z 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_144Load this SAE jumprelu blocks.40.attn.hook_z 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_269Load this SAE jumprelu blocks.40.attn.hook_z 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_493Load this SAE jumprelu blocks.40.attn.hook_z 40 131072 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_13Load this SAE jumprelu blocks.41.attn.hook_z 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_25Load this SAE jumprelu blocks.41.attn.hook_z 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_56Load this SAE jumprelu blocks.41.attn.hook_z 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_129Load this SAE jumprelu blocks.41.attn.hook_z 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_254Load this SAE jumprelu blocks.41.attn.hook_z 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_450Load this SAE jumprelu blocks.41.attn.hook_z 41 16384 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_13Load this SAE jumprelu blocks.41.attn.hook_z 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_22Load this SAE jumprelu blocks.41.attn.hook_z 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_43Load this SAE jumprelu blocks.41.attn.hook_z 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_92Load this SAE jumprelu blocks.41.attn.hook_z 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_202Load this SAE jumprelu blocks.41.attn.hook_z 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_370Load this SAE jumprelu blocks.41.attn.hook_z 41 131072 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_25Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_53Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_125Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_270Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_529Load this SAE jumprelu blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_12Load this SAE jumprelu blocks.5.attn.hook_z 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_21Load this SAE jumprelu blocks.5.attn.hook_z 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_39Load this SAE jumprelu blocks.5.attn.hook_z 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_78Load this SAE jumprelu blocks.5.attn.hook_z 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_160Load this SAE jumprelu blocks.5.attn.hook_z 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_351Load this SAE jumprelu blocks.5.attn.hook_z 5 131072 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_16Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_28Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_51Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_108Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_258Load this SAE jumprelu blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_14Load this SAE jumprelu blocks.6.attn.hook_z 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_24Load this SAE jumprelu blocks.6.attn.hook_z 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_41Load this SAE jumprelu blocks.6.attn.hook_z 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_73Load this SAE jumprelu blocks.6.attn.hook_z 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_148Load this SAE jumprelu blocks.6.attn.hook_z 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_353Load this SAE jumprelu blocks.6.attn.hook_z 6 131072 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_18Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_33Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_70Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_160Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_335Load this SAE jumprelu blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_16Load this SAE jumprelu blocks.7.attn.hook_z 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_28Load this SAE jumprelu blocks.7.attn.hook_z 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_52Load this SAE jumprelu blocks.7.attn.hook_z 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_106Load this SAE jumprelu blocks.7.attn.hook_z 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_229Load this SAE jumprelu blocks.7.attn.hook_z 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_473Load this SAE jumprelu blocks.7.attn.hook_z 7 131072 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_17Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_32Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_65Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_150Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_362Load this SAE jumprelu blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_16Load this SAE jumprelu blocks.8.attn.hook_z 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_27Load this SAE jumprelu blocks.8.attn.hook_z 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_51Load this SAE jumprelu blocks.8.attn.hook_z 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_98Load this SAE jumprelu blocks.8.attn.hook_z 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_222Load this SAE jumprelu blocks.8.attn.hook_z 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_531Load this SAE jumprelu blocks.8.attn.hook_z 8 131072 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_18Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_34Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_71Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_172Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_349Load this SAE jumprelu blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_16Load this SAE jumprelu blocks.9.attn.hook_z 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_30Load this SAE jumprelu blocks.9.attn.hook_z 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_54Load this SAE jumprelu blocks.9.attn.hook_z 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_111Load this SAE jumprelu blocks.9.attn.hook_z 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_263Load this SAE jumprelu blocks.9.attn.hook_z 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_511Load this SAE jumprelu blocks.9.attn.hook_z 9 131072 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-pt-att-canonical","title":"gemma-scope-9b-pt-att-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-pt-att</li> <li>model: gemma-2-9b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/0-gemmascope-att-16k blocks.0.attn.hook_z 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/1-gemmascope-att-16k blocks.1.attn.hook_z 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/2-gemmascope-att-16k blocks.2.attn.hook_z 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/3-gemmascope-att-16k blocks.3.attn.hook_z 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/4-gemmascope-att-16k blocks.4.attn.hook_z 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/5-gemmascope-att-16k blocks.5.attn.hook_z 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/6-gemmascope-att-16k blocks.6.attn.hook_z 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/7-gemmascope-att-16k blocks.7.attn.hook_z 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/8-gemmascope-att-16k blocks.8.attn.hook_z 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/9-gemmascope-att-16k blocks.9.attn.hook_z 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/10-gemmascope-att-16k blocks.10.attn.hook_z 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/11-gemmascope-att-16k blocks.11.attn.hook_z 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/12-gemmascope-att-16k blocks.12.attn.hook_z 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/13-gemmascope-att-16k blocks.13.attn.hook_z 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/14-gemmascope-att-16k blocks.14.attn.hook_z 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/15-gemmascope-att-16k blocks.15.attn.hook_z 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/16-gemmascope-att-16k blocks.16.attn.hook_z 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/17-gemmascope-att-16k blocks.17.attn.hook_z 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/18-gemmascope-att-16k blocks.18.attn.hook_z 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/19-gemmascope-att-16k blocks.19.attn.hook_z 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-att-16k blocks.20.attn.hook_z 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/21-gemmascope-att-16k blocks.21.attn.hook_z 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/22-gemmascope-att-16k blocks.22.attn.hook_z 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/23-gemmascope-att-16k blocks.23.attn.hook_z 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/24-gemmascope-att-16k blocks.24.attn.hook_z 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/25-gemmascope-att-16k blocks.25.attn.hook_z 25 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/26-gemmascope-att-16k blocks.26.attn.hook_z 26 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/27-gemmascope-att-16k blocks.27.attn.hook_z 27 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/28-gemmascope-att-16k blocks.28.attn.hook_z 28 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/29-gemmascope-att-16k blocks.29.attn.hook_z 29 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/30-gemmascope-att-16k blocks.30.attn.hook_z 30 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/31-gemmascope-att-16k blocks.31.attn.hook_z 31 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/32-gemmascope-att-16k blocks.32.attn.hook_z 32 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/33-gemmascope-att-16k blocks.33.attn.hook_z 33 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/34-gemmascope-att-16k blocks.34.attn.hook_z 34 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/35-gemmascope-att-16k blocks.35.attn.hook_z 35 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/36-gemmascope-att-16k blocks.36.attn.hook_z 36 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/37-gemmascope-att-16k blocks.37.attn.hook_z 37 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/38-gemmascope-att-16k blocks.38.attn.hook_z 38 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/39-gemmascope-att-16k blocks.39.attn.hook_z 39 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/40-gemmascope-att-16k blocks.40.attn.hook_z 40 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/41-gemmascope-att-16k blocks.41.attn.hook_z 41 16384 1024 monology/pile-uncopyrighted layer_0/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/0-gemmascope-att-131k blocks.0.attn.hook_z 0 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/1-gemmascope-att-131k blocks.1.attn.hook_z 1 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/2-gemmascope-att-131k blocks.2.attn.hook_z 2 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/3-gemmascope-att-131k blocks.3.attn.hook_z 3 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/4-gemmascope-att-131k blocks.4.attn.hook_z 4 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/5-gemmascope-att-131k blocks.5.attn.hook_z 5 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/6-gemmascope-att-131k blocks.6.attn.hook_z 6 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/7-gemmascope-att-131k blocks.7.attn.hook_z 7 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/8-gemmascope-att-131k blocks.8.attn.hook_z 8 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/9-gemmascope-att-131k blocks.9.attn.hook_z 9 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/10-gemmascope-att-131k blocks.10.attn.hook_z 10 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/11-gemmascope-att-131k blocks.11.attn.hook_z 11 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/12-gemmascope-att-131k blocks.12.attn.hook_z 12 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/13-gemmascope-att-131k blocks.13.attn.hook_z 13 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/14-gemmascope-att-131k blocks.14.attn.hook_z 14 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/15-gemmascope-att-131k blocks.15.attn.hook_z 15 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/16-gemmascope-att-131k blocks.16.attn.hook_z 16 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/17-gemmascope-att-131k blocks.17.attn.hook_z 17 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/18-gemmascope-att-131k blocks.18.attn.hook_z 18 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/19-gemmascope-att-131k blocks.19.attn.hook_z 19 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-att-131k blocks.20.attn.hook_z 20 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/21-gemmascope-att-131k blocks.21.attn.hook_z 21 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/22-gemmascope-att-131k blocks.22.attn.hook_z 22 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/23-gemmascope-att-131k blocks.23.attn.hook_z 23 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/24-gemmascope-att-131k blocks.24.attn.hook_z 24 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/25-gemmascope-att-131k blocks.25.attn.hook_z 25 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/26-gemmascope-att-131k blocks.26.attn.hook_z 26 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/27-gemmascope-att-131k blocks.27.attn.hook_z 27 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/28-gemmascope-att-131k blocks.28.attn.hook_z 28 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/29-gemmascope-att-131k blocks.29.attn.hook_z 29 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/30-gemmascope-att-131k blocks.30.attn.hook_z 30 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/31-gemmascope-att-131k blocks.31.attn.hook_z 31 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/32-gemmascope-att-131k blocks.32.attn.hook_z 32 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/33-gemmascope-att-131k blocks.33.attn.hook_z 33 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/34-gemmascope-att-131k blocks.34.attn.hook_z 34 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/35-gemmascope-att-131k blocks.35.attn.hook_z 35 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/36-gemmascope-att-131k blocks.36.attn.hook_z 36 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/37-gemmascope-att-131k blocks.37.attn.hook_z 37 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/38-gemmascope-att-131k blocks.38.attn.hook_z 38 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/39-gemmascope-att-131k blocks.39.attn.hook_z 39 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/40-gemmascope-att-131k blocks.40.attn.hook_z 40 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/41-gemmascope-att-131k blocks.41.attn.hook_z 41 131072 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-pt-mlp","title":"gemma-scope-9b-pt-mlp","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-pt-mlp</li> <li>model: gemma-2-9b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/average_l0_6Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_10Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_16Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_28Load this SAE jumprelu blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_50Load this SAE jumprelu gemma-2-9b/0-gemmascope-mlp-16k__l0-50 blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_3Load this SAE jumprelu blocks.0.hook_mlp_out 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_5Load this SAE jumprelu blocks.0.hook_mlp_out 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_7Load this SAE jumprelu blocks.0.hook_mlp_out 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_11Load this SAE jumprelu blocks.0.hook_mlp_out 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_18Load this SAE jumprelu blocks.0.hook_mlp_out 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_30Load this SAE jumprelu blocks.0.hook_mlp_out 0 131072 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_12Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_26Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_56Load this SAE jumprelu gemma-2-9b/1-gemmascope-mlp-16k__l0-56 blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_128Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_278Load this SAE jumprelu blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_6Load this SAE jumprelu blocks.1.hook_mlp_out 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_10Load this SAE jumprelu blocks.1.hook_mlp_out 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_18Load this SAE jumprelu blocks.1.hook_mlp_out 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_32Load this SAE jumprelu blocks.1.hook_mlp_out 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_59Load this SAE jumprelu blocks.1.hook_mlp_out 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_106Load this SAE jumprelu blocks.1.hook_mlp_out 1 131072 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_13Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_24Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_49Load this SAE jumprelu gemma-2-9b/10-gemmascope-mlp-16k__l0-49 blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_114Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_276Load this SAE jumprelu blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_12Load this SAE jumprelu blocks.10.hook_mlp_out 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_22Load this SAE jumprelu blocks.10.hook_mlp_out 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_42Load this SAE jumprelu blocks.10.hook_mlp_out 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_83Load this SAE jumprelu blocks.10.hook_mlp_out 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_167Load this SAE jumprelu blocks.10.hook_mlp_out 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_362Load this SAE jumprelu blocks.10.hook_mlp_out 10 131072 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_17Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/11-gemmascope-mlp-16k__l0-34 blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_76Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_180Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_421Load this SAE jumprelu blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_17Load this SAE jumprelu blocks.11.hook_mlp_out 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_31Load this SAE jumprelu blocks.11.hook_mlp_out 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_60Load this SAE jumprelu blocks.11.hook_mlp_out 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_120Load this SAE jumprelu blocks.11.hook_mlp_out 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_259Load this SAE jumprelu blocks.11.hook_mlp_out 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_569Load this SAE jumprelu blocks.11.hook_mlp_out 11 131072 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_20Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_42Load this SAE jumprelu gemma-2-9b/12-gemmascope-mlp-16k__l0-42 blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_96Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_237Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_543Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_1033Load this SAE jumprelu blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_19Load this SAE jumprelu blocks.12.hook_mlp_out 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_38Load this SAE jumprelu blocks.12.hook_mlp_out 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_77Load this SAE jumprelu blocks.12.hook_mlp_out 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_159Load this SAE jumprelu blocks.12.hook_mlp_out 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_338Load this SAE jumprelu blocks.12.hook_mlp_out 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_745Load this SAE jumprelu blocks.12.hook_mlp_out 12 131072 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_19Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_40Load this SAE jumprelu gemma-2-9b/13-gemmascope-mlp-16k__l0-40 blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_94Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_225Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_512Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_992Load this SAE jumprelu blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_20Load this SAE jumprelu blocks.13.hook_mlp_out 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_38Load this SAE jumprelu blocks.13.hook_mlp_out 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_75Load this SAE jumprelu blocks.13.hook_mlp_out 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_160Load this SAE jumprelu blocks.13.hook_mlp_out 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_351Load this SAE jumprelu blocks.13.hook_mlp_out 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_703Load this SAE jumprelu blocks.13.hook_mlp_out 13 131072 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_19Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_41Load this SAE jumprelu gemma-2-9b/14-gemmascope-mlp-16k__l0-41 blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_97Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_236Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_538Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_1023Load this SAE jumprelu blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_20Load this SAE jumprelu blocks.14.hook_mlp_out 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_40Load this SAE jumprelu blocks.14.hook_mlp_out 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_80Load this SAE jumprelu blocks.14.hook_mlp_out 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_174Load this SAE jumprelu blocks.14.hook_mlp_out 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_374Load this SAE jumprelu blocks.14.hook_mlp_out 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_743Load this SAE jumprelu blocks.14.hook_mlp_out 14 131072 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_20Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_45Load this SAE jumprelu gemma-2-9b/15-gemmascope-mlp-16k__l0-45 blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_107Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_260Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_572Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_1053Load this SAE jumprelu blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_21Load this SAE jumprelu blocks.15.hook_mlp_out 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_43Load this SAE jumprelu blocks.15.hook_mlp_out 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_89Load this SAE jumprelu blocks.15.hook_mlp_out 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_194Load this SAE jumprelu blocks.15.hook_mlp_out 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_421Load this SAE jumprelu blocks.15.hook_mlp_out 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_828Load this SAE jumprelu blocks.15.hook_mlp_out 15 131072 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_16Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/16-gemmascope-mlp-16k__l0-37 blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_91Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_221Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_489Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_916Load this SAE jumprelu blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_17Load this SAE jumprelu blocks.16.hook_mlp_out 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_38Load this SAE jumprelu blocks.16.hook_mlp_out 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_81Load this SAE jumprelu blocks.16.hook_mlp_out 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_175Load this SAE jumprelu blocks.16.hook_mlp_out 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_384Load this SAE jumprelu blocks.16.hook_mlp_out 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_744Load this SAE jumprelu blocks.16.hook_mlp_out 16 131072 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_18Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_41Load this SAE jumprelu gemma-2-9b/17-gemmascope-mlp-16k__l0-41 blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_104Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_274Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_624Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_1137Load this SAE jumprelu blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_22Load this SAE jumprelu blocks.17.hook_mlp_out 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_43Load this SAE jumprelu blocks.17.hook_mlp_out 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_91Load this SAE jumprelu blocks.17.hook_mlp_out 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_207Load this SAE jumprelu blocks.17.hook_mlp_out 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_483Load this SAE jumprelu blocks.17.hook_mlp_out 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_950Load this SAE jumprelu blocks.17.hook_mlp_out 17 131072 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_16Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_36Load this SAE jumprelu gemma-2-9b/18-gemmascope-mlp-16k__l0-36 blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_89Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_235Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_564Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_1052Load this SAE jumprelu blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_19Load this SAE jumprelu blocks.18.hook_mlp_out 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_37Load this SAE jumprelu blocks.18.hook_mlp_out 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_82Load this SAE jumprelu blocks.18.hook_mlp_out 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_174Load this SAE jumprelu blocks.18.hook_mlp_out 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_420Load this SAE jumprelu blocks.18.hook_mlp_out 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_865Load this SAE jumprelu blocks.18.hook_mlp_out 18 131072 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_16Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_38Load this SAE jumprelu gemma-2-9b/19-gemmascope-mlp-16k__l0-38 blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_98Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_255Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_599Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_1097Load this SAE jumprelu blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_19Load this SAE jumprelu blocks.19.hook_mlp_out 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_40Load this SAE jumprelu blocks.19.hook_mlp_out 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_85Load this SAE jumprelu blocks.19.hook_mlp_out 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_189Load this SAE jumprelu blocks.19.hook_mlp_out 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_440Load this SAE jumprelu blocks.19.hook_mlp_out 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_899Load this SAE jumprelu blocks.19.hook_mlp_out 19 131072 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_8Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_16Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_33Load this SAE jumprelu gemma-2-9b/2-gemmascope-mlp-16k__l0-33 blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_81Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_163Load this SAE jumprelu blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_4Load this SAE jumprelu blocks.2.hook_mlp_out 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_7Load this SAE jumprelu blocks.2.hook_mlp_out 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_12Load this SAE jumprelu blocks.2.hook_mlp_out 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_20Load this SAE jumprelu blocks.2.hook_mlp_out 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_35Load this SAE jumprelu blocks.2.hook_mlp_out 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_61Load this SAE jumprelu blocks.2.hook_mlp_out 2 131072 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_17Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_41Load this SAE jumprelu gemma-2-9b/20-gemmascope-mlp-16k__l0-41 blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_108Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_284Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_643Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_1127Load this SAE jumprelu blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_20Load this SAE jumprelu blocks.20.hook_mlp_out 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_41Load this SAE jumprelu blocks.20.hook_mlp_out 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_93Load this SAE jumprelu blocks.20.hook_mlp_out 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_212Load this SAE jumprelu blocks.20.hook_mlp_out 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_477Load this SAE jumprelu blocks.20.hook_mlp_out 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_992Load this SAE jumprelu blocks.20.hook_mlp_out 20 131072 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_15Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/21-gemmascope-mlp-16k__l0-34 blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_88Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_241Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_571Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_1063Load this SAE jumprelu blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_16Load this SAE jumprelu blocks.21.hook_mlp_out 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_35Load this SAE jumprelu blocks.21.hook_mlp_out 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_79Load this SAE jumprelu blocks.21.hook_mlp_out 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_179Load this SAE jumprelu blocks.21.hook_mlp_out 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_417Load this SAE jumprelu blocks.21.hook_mlp_out 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_884Load this SAE jumprelu blocks.21.hook_mlp_out 21 131072 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_15Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/22-gemmascope-mlp-16k__l0-34 blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_85Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_226Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_566Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_1065Load this SAE jumprelu blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_17Load this SAE jumprelu blocks.22.hook_mlp_out 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_35Load this SAE jumprelu blocks.22.hook_mlp_out 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_77Load this SAE jumprelu blocks.22.hook_mlp_out 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_172Load this SAE jumprelu blocks.22.hook_mlp_out 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_404Load this SAE jumprelu blocks.22.hook_mlp_out 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_861Load this SAE jumprelu blocks.22.hook_mlp_out 22 131072 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_15Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_31Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_73Load this SAE jumprelu gemma-2-9b/23-gemmascope-mlp-16k__l0-73 blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_190Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_492Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_990Load this SAE jumprelu blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_17Load this SAE jumprelu blocks.23.hook_mlp_out 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_32Load this SAE jumprelu blocks.23.hook_mlp_out 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_67Load this SAE jumprelu blocks.23.hook_mlp_out 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_146Load this SAE jumprelu blocks.23.hook_mlp_out 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_354Load this SAE jumprelu blocks.23.hook_mlp_out 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_754Load this SAE jumprelu blocks.23.hook_mlp_out 23 131072 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_15Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_32Load this SAE jumprelu gemma-2-9b/24-gemmascope-mlp-16k__l0-32 blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_73Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_192Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_494Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_999Load this SAE jumprelu blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_17Load this SAE jumprelu blocks.24.hook_mlp_out 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_33Load this SAE jumprelu blocks.24.hook_mlp_out 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_67Load this SAE jumprelu blocks.24.hook_mlp_out 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_147Load this SAE jumprelu blocks.24.hook_mlp_out 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_351Load this SAE jumprelu blocks.24.hook_mlp_out 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_709Load this SAE jumprelu blocks.24.hook_mlp_out 24 131072 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_15Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_31Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_72Load this SAE jumprelu gemma-2-9b/25-gemmascope-mlp-16k__l0-72 blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_184Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_494Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_1013Load this SAE jumprelu blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_16Load this SAE jumprelu blocks.25.hook_mlp_out 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_32Load this SAE jumprelu blocks.25.hook_mlp_out 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_65Load this SAE jumprelu blocks.25.hook_mlp_out 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_139Load this SAE jumprelu blocks.25.hook_mlp_out 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_326Load this SAE jumprelu blocks.25.hook_mlp_out 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_691Load this SAE jumprelu blocks.25.hook_mlp_out 25 131072 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_14Load this SAE jumprelu blocks.26.hook_mlp_out 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_26Load this SAE jumprelu blocks.26.hook_mlp_out 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_57Load this SAE jumprelu gemma-2-9b/26-gemmascope-mlp-16k__l0-57 blocks.26.hook_mlp_out 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_142Load this SAE jumprelu blocks.26.hook_mlp_out 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_394Load this SAE jumprelu blocks.26.hook_mlp_out 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_887Load this SAE jumprelu blocks.26.hook_mlp_out 26 16384 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_14Load this SAE jumprelu blocks.26.hook_mlp_out 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_27Load this SAE jumprelu blocks.26.hook_mlp_out 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_53Load this SAE jumprelu blocks.26.hook_mlp_out 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_110Load this SAE jumprelu blocks.26.hook_mlp_out 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_249Load this SAE jumprelu blocks.26.hook_mlp_out 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_568Load this SAE jumprelu blocks.26.hook_mlp_out 26 131072 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_14Load this SAE jumprelu blocks.27.hook_mlp_out 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_25Load this SAE jumprelu blocks.27.hook_mlp_out 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_52Load this SAE jumprelu gemma-2-9b/27-gemmascope-mlp-16k__l0-52 blocks.27.hook_mlp_out 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_126Load this SAE jumprelu blocks.27.hook_mlp_out 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_352Load this SAE jumprelu blocks.27.hook_mlp_out 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_813Load this SAE jumprelu blocks.27.hook_mlp_out 27 16384 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_14Load this SAE jumprelu blocks.27.hook_mlp_out 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_26Load this SAE jumprelu blocks.27.hook_mlp_out 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_49Load this SAE jumprelu blocks.27.hook_mlp_out 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_99Load this SAE jumprelu blocks.27.hook_mlp_out 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_211Load this SAE jumprelu blocks.27.hook_mlp_out 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_487Load this SAE jumprelu blocks.27.hook_mlp_out 27 131072 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_14Load this SAE jumprelu blocks.28.hook_mlp_out 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_26Load this SAE jumprelu blocks.28.hook_mlp_out 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_50Load this SAE jumprelu gemma-2-9b/28-gemmascope-mlp-16k__l0-50 blocks.28.hook_mlp_out 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_115Load this SAE jumprelu blocks.28.hook_mlp_out 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_324Load this SAE jumprelu blocks.28.hook_mlp_out 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_773Load this SAE jumprelu blocks.28.hook_mlp_out 28 16384 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_15Load this SAE jumprelu blocks.28.hook_mlp_out 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_26Load this SAE jumprelu blocks.28.hook_mlp_out 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_47Load this SAE jumprelu blocks.28.hook_mlp_out 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_91Load this SAE jumprelu blocks.28.hook_mlp_out 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_189Load this SAE jumprelu blocks.28.hook_mlp_out 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_425Load this SAE jumprelu blocks.28.hook_mlp_out 28 131072 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_15Load this SAE jumprelu blocks.29.hook_mlp_out 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_26Load this SAE jumprelu blocks.29.hook_mlp_out 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_49Load this SAE jumprelu gemma-2-9b/29-gemmascope-mlp-16k__l0-49 blocks.29.hook_mlp_out 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_111Load this SAE jumprelu blocks.29.hook_mlp_out 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_311Load this SAE jumprelu blocks.29.hook_mlp_out 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_725Load this SAE jumprelu blocks.29.hook_mlp_out 29 16384 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_15Load this SAE jumprelu blocks.29.hook_mlp_out 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_26Load this SAE jumprelu blocks.29.hook_mlp_out 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_47Load this SAE jumprelu blocks.29.hook_mlp_out 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_87Load this SAE jumprelu blocks.29.hook_mlp_out 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_174Load this SAE jumprelu blocks.29.hook_mlp_out 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_386Load this SAE jumprelu blocks.29.hook_mlp_out 29 131072 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_13Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_25Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_55Load this SAE jumprelu gemma-2-9b/3-gemmascope-mlp-16k__l0-55 blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_126Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_234Load this SAE jumprelu blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_6Load this SAE jumprelu blocks.3.hook_mlp_out 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_11Load this SAE jumprelu blocks.3.hook_mlp_out 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_19Load this SAE jumprelu blocks.3.hook_mlp_out 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_33Load this SAE jumprelu blocks.3.hook_mlp_out 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_58Load this SAE jumprelu blocks.3.hook_mlp_out 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_109Load this SAE jumprelu blocks.3.hook_mlp_out 3 131072 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_14Load this SAE jumprelu blocks.30.hook_mlp_out 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_26Load this SAE jumprelu blocks.30.hook_mlp_out 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_51Load this SAE jumprelu gemma-2-9b/30-gemmascope-mlp-16k__l0-51 blocks.30.hook_mlp_out 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_116Load this SAE jumprelu blocks.30.hook_mlp_out 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_333Load this SAE jumprelu blocks.30.hook_mlp_out 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_806Load this SAE jumprelu blocks.30.hook_mlp_out 30 16384 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_14Load this SAE jumprelu blocks.30.hook_mlp_out 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_26Load this SAE jumprelu blocks.30.hook_mlp_out 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_47Load this SAE jumprelu blocks.30.hook_mlp_out 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_89Load this SAE jumprelu blocks.30.hook_mlp_out 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_179Load this SAE jumprelu blocks.30.hook_mlp_out 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_391Load this SAE jumprelu blocks.30.hook_mlp_out 30 131072 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_12Load this SAE jumprelu blocks.31.hook_mlp_out 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_22Load this SAE jumprelu blocks.31.hook_mlp_out 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_43Load this SAE jumprelu gemma-2-9b/31-gemmascope-mlp-16k__l0-43 blocks.31.hook_mlp_out 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_94Load this SAE jumprelu blocks.31.hook_mlp_out 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_263Load this SAE jumprelu blocks.31.hook_mlp_out 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_671Load this SAE jumprelu blocks.31.hook_mlp_out 31 16384 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_12Load this SAE jumprelu blocks.31.hook_mlp_out 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_22Load this SAE jumprelu blocks.31.hook_mlp_out 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_40Load this SAE jumprelu blocks.31.hook_mlp_out 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_77Load this SAE jumprelu blocks.31.hook_mlp_out 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_153Load this SAE jumprelu blocks.31.hook_mlp_out 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_326Load this SAE jumprelu blocks.31.hook_mlp_out 31 131072 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_11Load this SAE jumprelu blocks.32.hook_mlp_out 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_21Load this SAE jumprelu blocks.32.hook_mlp_out 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_44Load this SAE jumprelu gemma-2-9b/32-gemmascope-mlp-16k__l0-44 blocks.32.hook_mlp_out 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_98Load this SAE jumprelu blocks.32.hook_mlp_out 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_267Load this SAE jumprelu blocks.32.hook_mlp_out 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_623Load this SAE jumprelu blocks.32.hook_mlp_out 32 16384 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_12Load this SAE jumprelu blocks.32.hook_mlp_out 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_21Load this SAE jumprelu blocks.32.hook_mlp_out 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_40Load this SAE jumprelu blocks.32.hook_mlp_out 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_76Load this SAE jumprelu blocks.32.hook_mlp_out 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_155Load this SAE jumprelu blocks.32.hook_mlp_out 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_336Load this SAE jumprelu blocks.32.hook_mlp_out 32 131072 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_12Load this SAE jumprelu blocks.33.hook_mlp_out 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_23Load this SAE jumprelu blocks.33.hook_mlp_out 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_48Load this SAE jumprelu gemma-2-9b/33-gemmascope-mlp-16k__l0-48 blocks.33.hook_mlp_out 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_107Load this SAE jumprelu blocks.33.hook_mlp_out 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_282Load this SAE jumprelu blocks.33.hook_mlp_out 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_628Load this SAE jumprelu blocks.33.hook_mlp_out 33 16384 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_12Load this SAE jumprelu blocks.33.hook_mlp_out 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_22Load this SAE jumprelu blocks.33.hook_mlp_out 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_42Load this SAE jumprelu blocks.33.hook_mlp_out 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_83Load this SAE jumprelu blocks.33.hook_mlp_out 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_168Load this SAE jumprelu blocks.33.hook_mlp_out 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_394Load this SAE jumprelu blocks.33.hook_mlp_out 33 131072 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_11Load this SAE jumprelu blocks.34.hook_mlp_out 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_22Load this SAE jumprelu blocks.34.hook_mlp_out 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_47Load this SAE jumprelu gemma-2-9b/34-gemmascope-mlp-16k__l0-47 blocks.34.hook_mlp_out 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_107Load this SAE jumprelu blocks.34.hook_mlp_out 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_268Load this SAE jumprelu blocks.34.hook_mlp_out 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_559Load this SAE jumprelu blocks.34.hook_mlp_out 34 16384 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_10Load this SAE jumprelu blocks.34.hook_mlp_out 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_20Load this SAE jumprelu blocks.34.hook_mlp_out 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_40Load this SAE jumprelu blocks.34.hook_mlp_out 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_82Load this SAE jumprelu blocks.34.hook_mlp_out 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_167Load this SAE jumprelu blocks.34.hook_mlp_out 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_390Load this SAE jumprelu blocks.34.hook_mlp_out 34 131072 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_10Load this SAE jumprelu blocks.35.hook_mlp_out 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_21Load this SAE jumprelu blocks.35.hook_mlp_out 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_46Load this SAE jumprelu gemma-2-9b/35-gemmascope-mlp-16k__l0-46 blocks.35.hook_mlp_out 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_108Load this SAE jumprelu blocks.35.hook_mlp_out 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_254Load this SAE jumprelu blocks.35.hook_mlp_out 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_538Load this SAE jumprelu blocks.35.hook_mlp_out 35 16384 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_10Load this SAE jumprelu blocks.35.hook_mlp_out 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_19Load this SAE jumprelu blocks.35.hook_mlp_out 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_39Load this SAE jumprelu blocks.35.hook_mlp_out 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_80Load this SAE jumprelu blocks.35.hook_mlp_out 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_176Load this SAE jumprelu blocks.35.hook_mlp_out 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_389Load this SAE jumprelu blocks.35.hook_mlp_out 35 131072 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_11Load this SAE jumprelu blocks.36.hook_mlp_out 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_22Load this SAE jumprelu blocks.36.hook_mlp_out 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_47Load this SAE jumprelu gemma-2-9b/36-gemmascope-mlp-16k__l0-47 blocks.36.hook_mlp_out 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_109Load this SAE jumprelu blocks.36.hook_mlp_out 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_256Load this SAE jumprelu blocks.36.hook_mlp_out 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_523Load this SAE jumprelu blocks.36.hook_mlp_out 36 16384 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_11Load this SAE jumprelu blocks.36.hook_mlp_out 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_20Load this SAE jumprelu blocks.36.hook_mlp_out 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_40Load this SAE jumprelu blocks.36.hook_mlp_out 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_81Load this SAE jumprelu blocks.36.hook_mlp_out 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_174Load this SAE jumprelu blocks.36.hook_mlp_out 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_389Load this SAE jumprelu blocks.36.hook_mlp_out 36 131072 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_12Load this SAE jumprelu blocks.37.hook_mlp_out 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_24Load this SAE jumprelu blocks.37.hook_mlp_out 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_53Load this SAE jumprelu gemma-2-9b/37-gemmascope-mlp-16k__l0-53 blocks.37.hook_mlp_out 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_119Load this SAE jumprelu blocks.37.hook_mlp_out 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_267Load this SAE jumprelu blocks.37.hook_mlp_out 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_549Load this SAE jumprelu blocks.37.hook_mlp_out 37 16384 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_12Load this SAE jumprelu blocks.37.hook_mlp_out 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_23Load this SAE jumprelu blocks.37.hook_mlp_out 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_44Load this SAE jumprelu blocks.37.hook_mlp_out 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_90Load this SAE jumprelu blocks.37.hook_mlp_out 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_203Load this SAE jumprelu blocks.37.hook_mlp_out 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_403Load this SAE jumprelu blocks.37.hook_mlp_out 37 131072 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_11Load this SAE jumprelu blocks.38.hook_mlp_out 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_22Load this SAE jumprelu blocks.38.hook_mlp_out 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_45Load this SAE jumprelu gemma-2-9b/38-gemmascope-mlp-16k__l0-45 blocks.38.hook_mlp_out 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_98Load this SAE jumprelu blocks.38.hook_mlp_out 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_225Load this SAE jumprelu blocks.38.hook_mlp_out 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_491Load this SAE jumprelu blocks.38.hook_mlp_out 38 16384 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_11Load this SAE jumprelu blocks.38.hook_mlp_out 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_21Load this SAE jumprelu blocks.38.hook_mlp_out 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_40Load this SAE jumprelu blocks.38.hook_mlp_out 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_79Load this SAE jumprelu blocks.38.hook_mlp_out 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_161Load this SAE jumprelu blocks.38.hook_mlp_out 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_347Load this SAE jumprelu blocks.38.hook_mlp_out 38 131072 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_12Load this SAE jumprelu blocks.39.hook_mlp_out 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_22Load this SAE jumprelu blocks.39.hook_mlp_out 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_43Load this SAE jumprelu gemma-2-9b/39-gemmascope-mlp-16k__l0-43 blocks.39.hook_mlp_out 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_90Load this SAE jumprelu blocks.39.hook_mlp_out 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_207Load this SAE jumprelu blocks.39.hook_mlp_out 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_458Load this SAE jumprelu blocks.39.hook_mlp_out 39 16384 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_11Load this SAE jumprelu blocks.39.hook_mlp_out 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_21Load this SAE jumprelu blocks.39.hook_mlp_out 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_38Load this SAE jumprelu blocks.39.hook_mlp_out 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_75Load this SAE jumprelu blocks.39.hook_mlp_out 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_150Load this SAE jumprelu blocks.39.hook_mlp_out 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_319Load this SAE jumprelu blocks.39.hook_mlp_out 39 131072 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_15Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_30Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_66Load this SAE jumprelu gemma-2-9b/4-gemmascope-mlp-16k__l0-66 blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_151Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_343Load this SAE jumprelu blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_8Load this SAE jumprelu blocks.4.hook_mlp_out 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_14Load this SAE jumprelu blocks.4.hook_mlp_out 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_24Load this SAE jumprelu blocks.4.hook_mlp_out 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_45Load this SAE jumprelu blocks.4.hook_mlp_out 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_84Load this SAE jumprelu blocks.4.hook_mlp_out 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_157Load this SAE jumprelu blocks.4.hook_mlp_out 4 131072 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_11Load this SAE jumprelu blocks.40.hook_mlp_out 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_19Load this SAE jumprelu blocks.40.hook_mlp_out 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/40-gemmascope-mlp-16k__l0-37 blocks.40.hook_mlp_out 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_74Load this SAE jumprelu blocks.40.hook_mlp_out 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_162Load this SAE jumprelu blocks.40.hook_mlp_out 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_371Load this SAE jumprelu blocks.40.hook_mlp_out 40 16384 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_11Load this SAE jumprelu blocks.40.hook_mlp_out 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_18Load this SAE jumprelu blocks.40.hook_mlp_out 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_33Load this SAE jumprelu blocks.40.hook_mlp_out 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_63Load this SAE jumprelu blocks.40.hook_mlp_out 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_125Load this SAE jumprelu blocks.40.hook_mlp_out 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_267Load this SAE jumprelu blocks.40.hook_mlp_out 40 131072 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_8Load this SAE jumprelu blocks.41.hook_mlp_out 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_15Load this SAE jumprelu blocks.41.hook_mlp_out 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_28Load this SAE jumprelu blocks.41.hook_mlp_out 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_58Load this SAE jumprelu gemma-2-9b/41-gemmascope-mlp-16k__l0-58 blocks.41.hook_mlp_out 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_126Load this SAE jumprelu blocks.41.hook_mlp_out 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_288Load this SAE jumprelu blocks.41.hook_mlp_out 41 16384 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_8Load this SAE jumprelu blocks.41.hook_mlp_out 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_14Load this SAE jumprelu blocks.41.hook_mlp_out 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_25Load this SAE jumprelu blocks.41.hook_mlp_out 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_49Load this SAE jumprelu blocks.41.hook_mlp_out 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_99Load this SAE jumprelu blocks.41.hook_mlp_out 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_208Load this SAE jumprelu blocks.41.hook_mlp_out 41 131072 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_14Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_24Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_46Load this SAE jumprelu gemma-2-9b/5-gemmascope-mlp-16k__l0-46 blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_93Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_194Load this SAE jumprelu blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_7Load this SAE jumprelu blocks.5.hook_mlp_out 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_12Load this SAE jumprelu blocks.5.hook_mlp_out 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_21Load this SAE jumprelu blocks.5.hook_mlp_out 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_37Load this SAE jumprelu blocks.5.hook_mlp_out 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_68Load this SAE jumprelu blocks.5.hook_mlp_out 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_131Load this SAE jumprelu blocks.5.hook_mlp_out 5 131072 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_12Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_23Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_46Load this SAE jumprelu gemma-2-9b/6-gemmascope-mlp-16k__l0-46 blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_96Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_206Load this SAE jumprelu blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_12Load this SAE jumprelu blocks.6.hook_mlp_out 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_22Load this SAE jumprelu blocks.6.hook_mlp_out 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_40Load this SAE jumprelu blocks.6.hook_mlp_out 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_72Load this SAE jumprelu blocks.6.hook_mlp_out 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_135Load this SAE jumprelu blocks.6.hook_mlp_out 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_271Load this SAE jumprelu blocks.6.hook_mlp_out 6 131072 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_14Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_25Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_47Load this SAE jumprelu gemma-2-9b/7-gemmascope-mlp-16k__l0-47 blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_101Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_231Load this SAE jumprelu blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_13Load this SAE jumprelu blocks.7.hook_mlp_out 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_23Load this SAE jumprelu blocks.7.hook_mlp_out 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_41Load this SAE jumprelu blocks.7.hook_mlp_out 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_75Load this SAE jumprelu blocks.7.hook_mlp_out 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_143Load this SAE jumprelu blocks.7.hook_mlp_out 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_309Load this SAE jumprelu blocks.7.hook_mlp_out 7 131072 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_15Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_27Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_55Load this SAE jumprelu gemma-2-9b/8-gemmascope-mlp-16k__l0-55 blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_124Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_309Load this SAE jumprelu blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_15Load this SAE jumprelu blocks.8.hook_mlp_out 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_26Load this SAE jumprelu blocks.8.hook_mlp_out 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_48Load this SAE jumprelu blocks.8.hook_mlp_out 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_89Load this SAE jumprelu blocks.8.hook_mlp_out 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_184Load this SAE jumprelu blocks.8.hook_mlp_out 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_423Load this SAE jumprelu blocks.8.hook_mlp_out 8 131072 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_12Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_21Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_40Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_83Load this SAE jumprelu gemma-2-9b/9-gemmascope-mlp-16k__l0-83 blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_200Load this SAE jumprelu blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_12Load this SAE jumprelu blocks.9.hook_mlp_out 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_21Load this SAE jumprelu blocks.9.hook_mlp_out 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_38Load this SAE jumprelu blocks.9.hook_mlp_out 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_67Load this SAE jumprelu blocks.9.hook_mlp_out 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_129Load this SAE jumprelu blocks.9.hook_mlp_out 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_269Load this SAE jumprelu blocks.9.hook_mlp_out 9 131072 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-pt-mlp-canonical","title":"gemma-scope-9b-pt-mlp-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-pt-mlp</li> <li>model: gemma-2-9b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/0-gemmascope-mlp-16k blocks.0.hook_mlp_out 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/1-gemmascope-mlp-16k blocks.1.hook_mlp_out 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/2-gemmascope-mlp-16k blocks.2.hook_mlp_out 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/3-gemmascope-mlp-16k blocks.3.hook_mlp_out 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/4-gemmascope-mlp-16k blocks.4.hook_mlp_out 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/5-gemmascope-mlp-16k blocks.5.hook_mlp_out 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/6-gemmascope-mlp-16k blocks.6.hook_mlp_out 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/7-gemmascope-mlp-16k blocks.7.hook_mlp_out 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/8-gemmascope-mlp-16k blocks.8.hook_mlp_out 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/9-gemmascope-mlp-16k blocks.9.hook_mlp_out 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/10-gemmascope-mlp-16k blocks.10.hook_mlp_out 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/11-gemmascope-mlp-16k blocks.11.hook_mlp_out 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/12-gemmascope-mlp-16k blocks.12.hook_mlp_out 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/13-gemmascope-mlp-16k blocks.13.hook_mlp_out 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/14-gemmascope-mlp-16k blocks.14.hook_mlp_out 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/15-gemmascope-mlp-16k blocks.15.hook_mlp_out 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/16-gemmascope-mlp-16k blocks.16.hook_mlp_out 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/17-gemmascope-mlp-16k blocks.17.hook_mlp_out 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/18-gemmascope-mlp-16k blocks.18.hook_mlp_out 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/19-gemmascope-mlp-16k blocks.19.hook_mlp_out 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-mlp-16k blocks.20.hook_mlp_out 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/21-gemmascope-mlp-16k blocks.21.hook_mlp_out 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/22-gemmascope-mlp-16k blocks.22.hook_mlp_out 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/23-gemmascope-mlp-16k blocks.23.hook_mlp_out 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/24-gemmascope-mlp-16k blocks.24.hook_mlp_out 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/25-gemmascope-mlp-16k blocks.25.hook_mlp_out 25 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/26-gemmascope-mlp-16k blocks.26.hook_mlp_out 26 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/27-gemmascope-mlp-16k blocks.27.hook_mlp_out 27 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/28-gemmascope-mlp-16k blocks.28.hook_mlp_out 28 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/29-gemmascope-mlp-16k blocks.29.hook_mlp_out 29 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/30-gemmascope-mlp-16k blocks.30.hook_mlp_out 30 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/31-gemmascope-mlp-16k blocks.31.hook_mlp_out 31 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/32-gemmascope-mlp-16k blocks.32.hook_mlp_out 32 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/33-gemmascope-mlp-16k blocks.33.hook_mlp_out 33 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/34-gemmascope-mlp-16k blocks.34.hook_mlp_out 34 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/35-gemmascope-mlp-16k blocks.35.hook_mlp_out 35 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/36-gemmascope-mlp-16k blocks.36.hook_mlp_out 36 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/37-gemmascope-mlp-16k blocks.37.hook_mlp_out 37 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/38-gemmascope-mlp-16k blocks.38.hook_mlp_out 38 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/39-gemmascope-mlp-16k blocks.39.hook_mlp_out 39 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/40-gemmascope-mlp-16k blocks.40.hook_mlp_out 40 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/41-gemmascope-mlp-16k blocks.41.hook_mlp_out 41 16384 1024 monology/pile-uncopyrighted layer_0/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/0-gemmascope-mlp-131k blocks.0.hook_mlp_out 0 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/1-gemmascope-mlp-131k blocks.1.hook_mlp_out 1 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/2-gemmascope-mlp-131k blocks.2.hook_mlp_out 2 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/3-gemmascope-mlp-131k blocks.3.hook_mlp_out 3 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/4-gemmascope-mlp-131k blocks.4.hook_mlp_out 4 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/5-gemmascope-mlp-131k blocks.5.hook_mlp_out 5 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/6-gemmascope-mlp-131k blocks.6.hook_mlp_out 6 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/7-gemmascope-mlp-131k blocks.7.hook_mlp_out 7 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/8-gemmascope-mlp-131k blocks.8.hook_mlp_out 8 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/9-gemmascope-mlp-131k blocks.9.hook_mlp_out 9 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/10-gemmascope-mlp-131k blocks.10.hook_mlp_out 10 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/11-gemmascope-mlp-131k blocks.11.hook_mlp_out 11 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/12-gemmascope-mlp-131k blocks.12.hook_mlp_out 12 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/13-gemmascope-mlp-131k blocks.13.hook_mlp_out 13 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/14-gemmascope-mlp-131k blocks.14.hook_mlp_out 14 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/15-gemmascope-mlp-131k blocks.15.hook_mlp_out 15 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/16-gemmascope-mlp-131k blocks.16.hook_mlp_out 16 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/17-gemmascope-mlp-131k blocks.17.hook_mlp_out 17 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/18-gemmascope-mlp-131k blocks.18.hook_mlp_out 18 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/19-gemmascope-mlp-131k blocks.19.hook_mlp_out 19 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-mlp-131k blocks.20.hook_mlp_out 20 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/21-gemmascope-mlp-131k blocks.21.hook_mlp_out 21 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/22-gemmascope-mlp-131k blocks.22.hook_mlp_out 22 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/23-gemmascope-mlp-131k blocks.23.hook_mlp_out 23 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/24-gemmascope-mlp-131k blocks.24.hook_mlp_out 24 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/25-gemmascope-mlp-131k blocks.25.hook_mlp_out 25 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/26-gemmascope-mlp-131k blocks.26.hook_mlp_out 26 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/27-gemmascope-mlp-131k blocks.27.hook_mlp_out 27 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/28-gemmascope-mlp-131k blocks.28.hook_mlp_out 28 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/29-gemmascope-mlp-131k blocks.29.hook_mlp_out 29 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/30-gemmascope-mlp-131k blocks.30.hook_mlp_out 30 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/31-gemmascope-mlp-131k blocks.31.hook_mlp_out 31 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/32-gemmascope-mlp-131k blocks.32.hook_mlp_out 32 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/33-gemmascope-mlp-131k blocks.33.hook_mlp_out 33 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/34-gemmascope-mlp-131k blocks.34.hook_mlp_out 34 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/35-gemmascope-mlp-131k blocks.35.hook_mlp_out 35 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/36-gemmascope-mlp-131k blocks.36.hook_mlp_out 36 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/37-gemmascope-mlp-131k blocks.37.hook_mlp_out 37 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/38-gemmascope-mlp-131k blocks.38.hook_mlp_out 38 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/39-gemmascope-mlp-131k blocks.39.hook_mlp_out 39 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/40-gemmascope-mlp-131k blocks.40.hook_mlp_out 40 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/41-gemmascope-mlp-131k blocks.41.hook_mlp_out 41 131072 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-pt-res","title":"gemma-scope-9b-pt-res","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-pt-res</li> <li>model: gemma-2-9b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations embedding/width_4k/average_l0_14Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted embedding/width_4k/average_l0_22Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted embedding/width_4k/average_l0_7Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted embedding/width_4k/average_l0_80Load this SAE jumprelu hook_embed 0 4096 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_11Load this SAE jumprelu blocks.0.hook_resid_post 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_15Load this SAE jumprelu blocks.0.hook_resid_post 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_21Load this SAE jumprelu blocks.0.hook_resid_post 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_30Load this SAE jumprelu gemma-2-9b/0-gemmascope-res-131k__l0-30 blocks.0.hook_resid_post 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_41Load this SAE jumprelu blocks.0.hook_resid_post 0 131072 1024 monology/pile-uncopyrighted layer_0/width_131k/average_l0_8Load this SAE jumprelu blocks.0.hook_resid_post 0 131072 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_11Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_129Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_17Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_35Load this SAE jumprelu gemma-2-9b/0-gemmascope-res-16k__l0-35 blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_0/width_16k/average_l0_68Load this SAE jumprelu blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_13Load this SAE jumprelu blocks.1.hook_resid_post 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_20Load this SAE jumprelu blocks.1.hook_resid_post 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_33Load this SAE jumprelu gemma-2-9b/1-gemmascope-res-131k__l0-33 blocks.1.hook_resid_post 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_56Load this SAE jumprelu blocks.1.hook_resid_post 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_6Load this SAE jumprelu blocks.1.hook_resid_post 1 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/average_l0_9Load this SAE jumprelu blocks.1.hook_resid_post 1 131072 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_15Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_175Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_31Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_69Load this SAE jumprelu gemma-2-9b/1-gemmascope-res-16k__l0-69 blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/average_l0_9Load this SAE jumprelu blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_15Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_151Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_27Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_47Load this SAE jumprelu gemma-2-9b/10-gemmascope-res-131k__l0-47 blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_84Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/average_l0_9Load this SAE jumprelu blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_10Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_113Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_17Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_243Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_31Load this SAE jumprelu blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/average_l0_57Load this SAE jumprelu gemma-2-9b/10-gemmascope-res-16k__l0-57 blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_16Load this SAE jumprelu blocks.11.hook_resid_post 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_162Load this SAE jumprelu blocks.11.hook_resid_post 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_27Load this SAE jumprelu blocks.11.hook_resid_post 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_49Load this SAE jumprelu gemma-2-9b/11-gemmascope-res-131k__l0-49 blocks.11.hook_resid_post 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_88Load this SAE jumprelu blocks.11.hook_resid_post 11 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/average_l0_9Load this SAE jumprelu blocks.11.hook_resid_post 11 131072 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_10Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_118Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_18Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_255Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_32Load this SAE jumprelu gemma-2-9b/11-gemmascope-res-16k__l0-32 blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/average_l0_60Load this SAE jumprelu blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_10Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_17Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_183Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_29Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_52Load this SAE jumprelu gemma-2-9b/12-gemmascope-res-131k__l0-52 blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/average_l0_96Load this SAE jumprelu blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_10Load this SAE jumprelu blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_130Load this SAE jumprelu blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_19Load this SAE jumprelu blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_287Load this SAE jumprelu blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_33Load this SAE jumprelu gemma-2-9b/12-gemmascope-res-16k__l0-33 blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/average_l0_64Load this SAE jumprelu blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_10Load this SAE jumprelu blocks.13.hook_resid_post 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_17Load this SAE jumprelu blocks.13.hook_resid_post 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_189Load this SAE jumprelu blocks.13.hook_resid_post 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_30Load this SAE jumprelu gemma-2-9b/13-gemmascope-res-131k__l0-30 blocks.13.hook_resid_post 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_54Load this SAE jumprelu blocks.13.hook_resid_post 13 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/average_l0_99Load this SAE jumprelu blocks.13.hook_resid_post 13 131072 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_11Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_132Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_19Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_285Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/13-gemmascope-res-16k__l0-34 blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/average_l0_65Load this SAE jumprelu blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_10Load this SAE jumprelu blocks.14.hook_resid_post 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_105Load this SAE jumprelu blocks.14.hook_resid_post 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_18Load this SAE jumprelu blocks.14.hook_resid_post 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_197Load this SAE jumprelu blocks.14.hook_resid_post 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_31Load this SAE jumprelu blocks.14.hook_resid_post 14 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/average_l0_56Load this SAE jumprelu gemma-2-9b/14-gemmascope-res-131k__l0-56 blocks.14.hook_resid_post 14 131072 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_11Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_137Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_19Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_294Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_35Load this SAE jumprelu gemma-2-9b/14-gemmascope-res-16k__l0-35 blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/average_l0_67Load this SAE jumprelu blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_10Load this SAE jumprelu blocks.15.hook_resid_post 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_103Load this SAE jumprelu blocks.15.hook_resid_post 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_17Load this SAE jumprelu blocks.15.hook_resid_post 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_198Load this SAE jumprelu blocks.15.hook_resid_post 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_30Load this SAE jumprelu blocks.15.hook_resid_post 15 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/average_l0_55Load this SAE jumprelu gemma-2-9b/15-gemmascope-res-131k__l0-55 blocks.15.hook_resid_post 15 131072 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_10Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_131Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_18Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_290Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/15-gemmascope-res-16k__l0-34 blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/average_l0_65Load this SAE jumprelu blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_11Load this SAE jumprelu blocks.16.hook_resid_post 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_121Load this SAE jumprelu blocks.16.hook_resid_post 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_20Load this SAE jumprelu blocks.16.hook_resid_post 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_232Load this SAE jumprelu blocks.16.hook_resid_post 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_35Load this SAE jumprelu gemma-2-9b/16-gemmascope-res-131k__l0-35 blocks.16.hook_resid_post 16 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/average_l0_65Load this SAE jumprelu blocks.16.hook_resid_post 16 131072 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_11Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_152Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_21Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_346Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_39Load this SAE jumprelu gemma-2-9b/16-gemmascope-res-16k__l0-39 blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/average_l0_75Load this SAE jumprelu blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_11Load this SAE jumprelu blocks.17.hook_resid_post 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_117Load this SAE jumprelu blocks.17.hook_resid_post 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_19Load this SAE jumprelu blocks.17.hook_resid_post 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_221Load this SAE jumprelu blocks.17.hook_resid_post 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_35Load this SAE jumprelu gemma-2-9b/17-gemmascope-res-131k__l0-35 blocks.17.hook_resid_post 17 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/average_l0_64Load this SAE jumprelu blocks.17.hook_resid_post 17 131072 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_12Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_144Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_21Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_317Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_38Load this SAE jumprelu gemma-2-9b/17-gemmascope-res-16k__l0-38 blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/average_l0_73Load this SAE jumprelu blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_11Load this SAE jumprelu blocks.18.hook_resid_post 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_113Load this SAE jumprelu blocks.18.hook_resid_post 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_19Load this SAE jumprelu blocks.18.hook_resid_post 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_221Load this SAE jumprelu blocks.18.hook_resid_post 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_34Load this SAE jumprelu gemma-2-9b/18-gemmascope-res-131k__l0-34 blocks.18.hook_resid_post 18 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/average_l0_62Load this SAE jumprelu blocks.18.hook_resid_post 18 131072 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_11Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_140Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_20Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_309Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/18-gemmascope-res-16k__l0-37 blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/average_l0_71Load this SAE jumprelu blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_10Load this SAE jumprelu blocks.19.hook_resid_post 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_110Load this SAE jumprelu blocks.19.hook_resid_post 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_18Load this SAE jumprelu blocks.19.hook_resid_post 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_210Load this SAE jumprelu blocks.19.hook_resid_post 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_32Load this SAE jumprelu gemma-2-9b/19-gemmascope-res-131k__l0-32 blocks.19.hook_resid_post 19 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/average_l0_60Load this SAE jumprelu blocks.19.hook_resid_post 19 131072 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_11Load this SAE jumprelu blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_132Load this SAE jumprelu blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_19Load this SAE jumprelu blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_293Load this SAE jumprelu blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_35Load this SAE jumprelu gemma-2-9b/19-gemmascope-res-16k__l0-35 blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/average_l0_67Load this SAE jumprelu blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_12Load this SAE jumprelu blocks.2.hook_resid_post 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_19Load this SAE jumprelu blocks.2.hook_resid_post 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_36Load this SAE jumprelu gemma-2-9b/2-gemmascope-res-131k__l0-36 blocks.2.hook_resid_post 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_5Load this SAE jumprelu blocks.2.hook_resid_post 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_70Load this SAE jumprelu blocks.2.hook_resid_post 2 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/average_l0_8Load this SAE jumprelu blocks.2.hook_resid_post 2 131072 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_14Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_189Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_29Load this SAE jumprelu blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_67Load this SAE jumprelu gemma-2-9b/2-gemmascope-res-16k__l0-67 blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/average_l0_8Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-10 blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_11Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-11 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_114Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-12 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_19Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-19 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_221Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-221 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_276Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-276 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_34Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-34 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_53Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-53 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/average_l0_62Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k__l0-62 blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_11Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k__l0-11 blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_138Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k__l0-138 blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_20Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k__l0-20 blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_310Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k__l0-310 blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_36Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k__l0-36 blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_408Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k__l0-408 blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_58Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k__l0-58 blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/average_l0_68Load this SAE jumprelu blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_20/width_1m/average_l0_101Load this SAE jumprelu blocks.20.hook_resid_post 20 1048576 1024 monology/pile-uncopyrighted layer_20/width_1m/average_l0_11Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-1m__l0-11 blocks.20.hook_resid_post 20 1048576 1024 monology/pile-uncopyrighted layer_20/width_1m/average_l0_19Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-1m__l0-19 blocks.20.hook_resid_post 20 1048576 1024 monology/pile-uncopyrighted layer_20/width_1m/average_l0_193Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-1m__l0-193 blocks.20.hook_resid_post 20 1048576 1024 monology/pile-uncopyrighted layer_20/width_1m/average_l0_34Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-1m__l0-34 blocks.20.hook_resid_post 20 1048576 1024 monology/pile-uncopyrighted layer_20/width_1m/average_l0_57Load this SAE jumprelu gemma-2-9b/20-gemmascope-res-1m__l0-57 blocks.20.hook_resid_post 20 1048576 1024 monology/pile-uncopyrighted layer_20/width_262k/average_l0_11Load this SAE jumprelu blocks.20.hook_resid_post 20 262144 1024 monology/pile-uncopyrighted layer_20/width_262k/average_l0_259Load this SAE jumprelu blocks.20.hook_resid_post 20 262144 1024 monology/pile-uncopyrighted layer_20/width_262k/average_l0_50Load this SAE jumprelu blocks.20.hook_resid_post 20 262144 1024 monology/pile-uncopyrighted layer_20/width_32k/average_l0_11Load this SAE jumprelu blocks.20.hook_resid_post 20 32768 1024 monology/pile-uncopyrighted layer_20/width_32k/average_l0_344Load this SAE jumprelu blocks.20.hook_resid_post 20 32768 1024 monology/pile-uncopyrighted layer_20/width_32k/average_l0_57Load this SAE jumprelu blocks.20.hook_resid_post 20 32768 1024 monology/pile-uncopyrighted layer_20/width_524k/average_l0_10Load this SAE jumprelu blocks.20.hook_resid_post 20 524288 1024 monology/pile-uncopyrighted layer_20/width_524k/average_l0_241Load this SAE jumprelu blocks.20.hook_resid_post 20 524288 1024 monology/pile-uncopyrighted layer_20/width_524k/average_l0_48Load this SAE jumprelu blocks.20.hook_resid_post 20 524288 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_11Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_55Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_20/width_65k/average_l0_298Load this SAE jumprelu blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_109Load this SAE jumprelu blocks.21.hook_resid_post 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_11Load this SAE jumprelu blocks.21.hook_resid_post 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_19Load this SAE jumprelu blocks.21.hook_resid_post 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_204Load this SAE jumprelu blocks.21.hook_resid_post 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_33Load this SAE jumprelu gemma-2-9b/21-gemmascope-res-131k__l0-33 blocks.21.hook_resid_post 21 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/average_l0_58Load this SAE jumprelu blocks.21.hook_resid_post 21 131072 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_11Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_129Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_19Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_278Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_36Load this SAE jumprelu gemma-2-9b/21-gemmascope-res-16k__l0-36 blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/average_l0_66Load this SAE jumprelu blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_10Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_105Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_18Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_197Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_32Load this SAE jumprelu gemma-2-9b/22-gemmascope-res-131k__l0-32 blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/average_l0_58Load this SAE jumprelu blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_11Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_123Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_19Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_268Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_35Load this SAE jumprelu gemma-2-9b/22-gemmascope-res-16k__l0-35 blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/average_l0_65Load this SAE jumprelu blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_10Load this SAE jumprelu blocks.23.hook_resid_post 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_101Load this SAE jumprelu blocks.23.hook_resid_post 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_18Load this SAE jumprelu blocks.23.hook_resid_post 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_187Load this SAE jumprelu blocks.23.hook_resid_post 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_32Load this SAE jumprelu gemma-2-9b/23-gemmascope-res-131k__l0-32 blocks.23.hook_resid_post 23 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/average_l0_56Load this SAE jumprelu blocks.23.hook_resid_post 23 131072 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_11Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_120Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_19Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_248Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_35Load this SAE jumprelu gemma-2-9b/23-gemmascope-res-16k__l0-35 blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/average_l0_63Load this SAE jumprelu blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_10Load this SAE jumprelu blocks.24.hook_resid_post 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_17Load this SAE jumprelu blocks.24.hook_resid_post 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_180Load this SAE jumprelu blocks.24.hook_resid_post 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_30Load this SAE jumprelu blocks.24.hook_resid_post 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_55Load this SAE jumprelu gemma-2-9b/24-gemmascope-res-131k__l0-55 blocks.24.hook_resid_post 24 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/average_l0_97Load this SAE jumprelu blocks.24.hook_resid_post 24 131072 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_10Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_114Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_19Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_234Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/24-gemmascope-res-16k__l0-34 blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/average_l0_61Load this SAE jumprelu blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_10Load this SAE jumprelu blocks.25.hook_resid_post 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_177Load this SAE jumprelu blocks.25.hook_resid_post 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_18Load this SAE jumprelu blocks.25.hook_resid_post 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_31Load this SAE jumprelu blocks.25.hook_resid_post 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_54Load this SAE jumprelu gemma-2-9b/25-gemmascope-res-131k__l0-54 blocks.25.hook_resid_post 25 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/average_l0_96Load this SAE jumprelu blocks.25.hook_resid_post 25 131072 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_11Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_114Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_19Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_231Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/25-gemmascope-res-16k__l0-34 blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/average_l0_61Load this SAE jumprelu blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_10Load this SAE jumprelu blocks.26.hook_resid_post 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_176Load this SAE jumprelu blocks.26.hook_resid_post 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_18Load this SAE jumprelu blocks.26.hook_resid_post 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_32Load this SAE jumprelu gemma-2-9b/26-gemmascope-res-131k__l0-32 blocks.26.hook_resid_post 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_55Load this SAE jumprelu blocks.26.hook_resid_post 26 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/average_l0_97Load this SAE jumprelu blocks.26.hook_resid_post 26 131072 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_11Load this SAE jumprelu blocks.26.hook_resid_post 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_116Load this SAE jumprelu blocks.26.hook_resid_post 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_20Load this SAE jumprelu blocks.26.hook_resid_post 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_233Load this SAE jumprelu blocks.26.hook_resid_post 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_35Load this SAE jumprelu gemma-2-9b/26-gemmascope-res-16k__l0-35 blocks.26.hook_resid_post 26 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/average_l0_63Load this SAE jumprelu blocks.26.hook_resid_post 26 16384 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_11Load this SAE jumprelu blocks.27.hook_resid_post 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_171Load this SAE jumprelu blocks.27.hook_resid_post 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_19Load this SAE jumprelu blocks.27.hook_resid_post 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_33Load this SAE jumprelu gemma-2-9b/27-gemmascope-res-131k__l0-33 blocks.27.hook_resid_post 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_56Load this SAE jumprelu blocks.27.hook_resid_post 27 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/average_l0_96Load this SAE jumprelu blocks.27.hook_resid_post 27 131072 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_118Load this SAE jumprelu blocks.27.hook_resid_post 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_12Load this SAE jumprelu blocks.27.hook_resid_post 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_21Load this SAE jumprelu blocks.27.hook_resid_post 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_230Load this SAE jumprelu blocks.27.hook_resid_post 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_36Load this SAE jumprelu gemma-2-9b/27-gemmascope-res-16k__l0-36 blocks.27.hook_resid_post 27 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/average_l0_65Load this SAE jumprelu blocks.27.hook_resid_post 27 16384 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_11Load this SAE jumprelu blocks.28.hook_resid_post 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_171Load this SAE jumprelu blocks.28.hook_resid_post 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_19Load this SAE jumprelu blocks.28.hook_resid_post 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_32Load this SAE jumprelu gemma-2-9b/28-gemmascope-res-131k__l0-32 blocks.28.hook_resid_post 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_57Load this SAE jumprelu blocks.28.hook_resid_post 28 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/average_l0_98Load this SAE jumprelu blocks.28.hook_resid_post 28 131072 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_119Load this SAE jumprelu blocks.28.hook_resid_post 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_12Load this SAE jumprelu blocks.28.hook_resid_post 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_21Load this SAE jumprelu blocks.28.hook_resid_post 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_229Load this SAE jumprelu blocks.28.hook_resid_post 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/28-gemmascope-res-16k__l0-37 blocks.28.hook_resid_post 28 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/average_l0_65Load this SAE jumprelu blocks.28.hook_resid_post 28 16384 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_11Load this SAE jumprelu blocks.29.hook_resid_post 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_171Load this SAE jumprelu blocks.29.hook_resid_post 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_19Load this SAE jumprelu blocks.29.hook_resid_post 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_33Load this SAE jumprelu gemma-2-9b/29-gemmascope-res-131k__l0-33 blocks.29.hook_resid_post 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_56Load this SAE jumprelu blocks.29.hook_resid_post 29 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/average_l0_97Load this SAE jumprelu blocks.29.hook_resid_post 29 131072 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_119Load this SAE jumprelu blocks.29.hook_resid_post 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_12Load this SAE jumprelu blocks.29.hook_resid_post 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_21Load this SAE jumprelu blocks.29.hook_resid_post 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_224Load this SAE jumprelu blocks.29.hook_resid_post 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_38Load this SAE jumprelu gemma-2-9b/29-gemmascope-res-16k__l0-38 blocks.29.hook_resid_post 29 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/average_l0_66Load this SAE jumprelu blocks.29.hook_resid_post 29 16384 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_103Load this SAE jumprelu blocks.3.hook_resid_post 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_14Load this SAE jumprelu blocks.3.hook_resid_post 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_25Load this SAE jumprelu blocks.3.hook_resid_post 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_46Load this SAE jumprelu gemma-2-9b/3-gemmascope-res-131k__l0-46 blocks.3.hook_resid_post 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_6Load this SAE jumprelu blocks.3.hook_resid_post 3 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/average_l0_9Load this SAE jumprelu blocks.3.hook_resid_post 3 131072 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_10Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_17Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_229Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/3-gemmascope-res-16k__l0-37 blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/average_l0_90Load this SAE jumprelu blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_11Load this SAE jumprelu blocks.30.hook_resid_post 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_170Load this SAE jumprelu blocks.30.hook_resid_post 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_18Load this SAE jumprelu blocks.30.hook_resid_post 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_32Load this SAE jumprelu gemma-2-9b/30-gemmascope-res-131k__l0-32 blocks.30.hook_resid_post 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_56Load this SAE jumprelu blocks.30.hook_resid_post 30 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/average_l0_95Load this SAE jumprelu blocks.30.hook_resid_post 30 131072 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_12Load this SAE jumprelu blocks.30.hook_resid_post 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_120Load this SAE jumprelu blocks.30.hook_resid_post 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_21Load this SAE jumprelu blocks.30.hook_resid_post 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_226Load this SAE jumprelu blocks.30.hook_resid_post 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/30-gemmascope-res-16k__l0-37 blocks.30.hook_resid_post 30 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/average_l0_66Load this SAE jumprelu blocks.30.hook_resid_post 30 16384 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_10Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-131k__l0-10 blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_160Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-131k__l0-160 blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_18Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-131k__l0-18 blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_31Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-131k__l0-31 blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_52Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-131k__l0-52 blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/average_l0_92Load this SAE jumprelu blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_11Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-16k__l0-11 blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_114Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-16k__l0-114 blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_20Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-16k__l0-20 blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_218Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-16k__l0-218 blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_35Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-16k__l0-35 blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/average_l0_63Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-16k__l0-63 blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_31/width_1m/average_l0_11Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-1m__l0-11 blocks.31.hook_resid_post 31 1048576 1024 monology/pile-uncopyrighted layer_31/width_1m/average_l0_132Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-1m__l0-132 blocks.31.hook_resid_post 31 1048576 1024 monology/pile-uncopyrighted layer_31/width_1m/average_l0_25Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-1m__l0-25 blocks.31.hook_resid_post 31 1048576 1024 monology/pile-uncopyrighted layer_31/width_1m/average_l0_27Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-1m__l0-27 blocks.31.hook_resid_post 31 1048576 1024 monology/pile-uncopyrighted layer_31/width_1m/average_l0_45Load this SAE jumprelu gemma-2-9b/31-gemmascope-res-1m__l0-45 blocks.31.hook_resid_post 31 1048576 1024 monology/pile-uncopyrighted layer_31/width_1m/average_l0_77Load this SAE jumprelu blocks.31.hook_resid_post 31 1048576 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_10Load this SAE jumprelu blocks.32.hook_resid_post 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_158Load this SAE jumprelu blocks.32.hook_resid_post 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_18Load this SAE jumprelu blocks.32.hook_resid_post 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_30Load this SAE jumprelu blocks.32.hook_resid_post 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_51Load this SAE jumprelu gemma-2-9b/32-gemmascope-res-131k__l0-51 blocks.32.hook_resid_post 32 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/average_l0_88Load this SAE jumprelu blocks.32.hook_resid_post 32 131072 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_11Load this SAE jumprelu blocks.32.hook_resid_post 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_111Load this SAE jumprelu blocks.32.hook_resid_post 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_20Load this SAE jumprelu blocks.32.hook_resid_post 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_219Load this SAE jumprelu blocks.32.hook_resid_post 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/32-gemmascope-res-16k__l0-34 blocks.32.hook_resid_post 32 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/average_l0_61Load this SAE jumprelu blocks.32.hook_resid_post 32 16384 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_10Load this SAE jumprelu blocks.33.hook_resid_post 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_165Load this SAE jumprelu blocks.33.hook_resid_post 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_18Load this SAE jumprelu blocks.33.hook_resid_post 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_30Load this SAE jumprelu blocks.33.hook_resid_post 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_51Load this SAE jumprelu gemma-2-9b/33-gemmascope-res-131k__l0-51 blocks.33.hook_resid_post 33 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/average_l0_91Load this SAE jumprelu blocks.33.hook_resid_post 33 131072 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_11Load this SAE jumprelu blocks.33.hook_resid_post 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_114Load this SAE jumprelu blocks.33.hook_resid_post 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_20Load this SAE jumprelu blocks.33.hook_resid_post 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_228Load this SAE jumprelu blocks.33.hook_resid_post 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/33-gemmascope-res-16k__l0-34 blocks.33.hook_resid_post 33 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/average_l0_63Load this SAE jumprelu blocks.33.hook_resid_post 33 16384 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_10Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_163Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_17Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_30Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_51Load this SAE jumprelu gemma-2-9b/34-gemmascope-res-131k__l0-51 blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/average_l0_89Load this SAE jumprelu blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_11Load this SAE jumprelu blocks.34.hook_resid_post 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_114Load this SAE jumprelu blocks.34.hook_resid_post 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_19Load this SAE jumprelu blocks.34.hook_resid_post 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_229Load this SAE jumprelu blocks.34.hook_resid_post 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/34-gemmascope-res-16k__l0-34 blocks.34.hook_resid_post 34 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/average_l0_60Load this SAE jumprelu blocks.34.hook_resid_post 34 16384 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_10Load this SAE jumprelu blocks.35.hook_resid_post 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_17Load this SAE jumprelu blocks.35.hook_resid_post 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_171Load this SAE jumprelu blocks.35.hook_resid_post 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_30Load this SAE jumprelu blocks.35.hook_resid_post 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_51Load this SAE jumprelu gemma-2-9b/35-gemmascope-res-131k__l0-51 blocks.35.hook_resid_post 35 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/average_l0_94Load this SAE jumprelu blocks.35.hook_resid_post 35 131072 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_11Load this SAE jumprelu blocks.35.hook_resid_post 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_120Load this SAE jumprelu blocks.35.hook_resid_post 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_19Load this SAE jumprelu blocks.35.hook_resid_post 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_246Load this SAE jumprelu blocks.35.hook_resid_post 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/35-gemmascope-res-16k__l0-34 blocks.35.hook_resid_post 35 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/average_l0_61Load this SAE jumprelu blocks.35.hook_resid_post 35 16384 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_10Load this SAE jumprelu blocks.36.hook_resid_post 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_17Load this SAE jumprelu blocks.36.hook_resid_post 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_180Load this SAE jumprelu blocks.36.hook_resid_post 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_30Load this SAE jumprelu blocks.36.hook_resid_post 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_51Load this SAE jumprelu gemma-2-9b/36-gemmascope-res-131k__l0-51 blocks.36.hook_resid_post 36 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/average_l0_93Load this SAE jumprelu blocks.36.hook_resid_post 36 131072 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_11Load this SAE jumprelu blocks.36.hook_resid_post 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_120Load this SAE jumprelu blocks.36.hook_resid_post 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_19Load this SAE jumprelu blocks.36.hook_resid_post 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_252Load this SAE jumprelu blocks.36.hook_resid_post 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/36-gemmascope-res-16k__l0-34 blocks.36.hook_resid_post 36 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/average_l0_61Load this SAE jumprelu blocks.36.hook_resid_post 36 16384 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_10Load this SAE jumprelu blocks.37.hook_resid_post 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_18Load this SAE jumprelu blocks.37.hook_resid_post 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_184Load this SAE jumprelu blocks.37.hook_resid_post 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_30Load this SAE jumprelu blocks.37.hook_resid_post 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_53Load this SAE jumprelu gemma-2-9b/37-gemmascope-res-131k__l0-53 blocks.37.hook_resid_post 37 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/average_l0_96Load this SAE jumprelu blocks.37.hook_resid_post 37 131072 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_11Load this SAE jumprelu blocks.37.hook_resid_post 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_124Load this SAE jumprelu blocks.37.hook_resid_post 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_20Load this SAE jumprelu blocks.37.hook_resid_post 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_266Load this SAE jumprelu blocks.37.hook_resid_post 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/37-gemmascope-res-16k__l0-34 blocks.37.hook_resid_post 37 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/average_l0_63Load this SAE jumprelu blocks.37.hook_resid_post 37 16384 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_10Load this SAE jumprelu blocks.38.hook_resid_post 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_101Load this SAE jumprelu blocks.38.hook_resid_post 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_18Load this SAE jumprelu blocks.38.hook_resid_post 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_194Load this SAE jumprelu blocks.38.hook_resid_post 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_30Load this SAE jumprelu blocks.38.hook_resid_post 38 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/average_l0_53Load this SAE jumprelu gemma-2-9b/38-gemmascope-res-131k__l0-53 blocks.38.hook_resid_post 38 131072 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_11Load this SAE jumprelu blocks.38.hook_resid_post 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_128Load this SAE jumprelu blocks.38.hook_resid_post 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_20Load this SAE jumprelu blocks.38.hook_resid_post 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_286Load this SAE jumprelu blocks.38.hook_resid_post 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/38-gemmascope-res-16k__l0-34 blocks.38.hook_resid_post 38 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/average_l0_64Load this SAE jumprelu blocks.38.hook_resid_post 38 16384 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_10Load this SAE jumprelu blocks.39.hook_resid_post 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_18Load this SAE jumprelu blocks.39.hook_resid_post 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_199Load this SAE jumprelu blocks.39.hook_resid_post 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_30Load this SAE jumprelu blocks.39.hook_resid_post 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_54Load this SAE jumprelu gemma-2-9b/39-gemmascope-res-131k__l0-54 blocks.39.hook_resid_post 39 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/average_l0_99Load this SAE jumprelu blocks.39.hook_resid_post 39 131072 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_11Load this SAE jumprelu blocks.39.hook_resid_post 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_131Load this SAE jumprelu blocks.39.hook_resid_post 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_19Load this SAE jumprelu blocks.39.hook_resid_post 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_298Load this SAE jumprelu blocks.39.hook_resid_post 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_34Load this SAE jumprelu gemma-2-9b/39-gemmascope-res-16k__l0-34 blocks.39.hook_resid_post 39 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/average_l0_64Load this SAE jumprelu blocks.39.hook_resid_post 39 16384 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_101Load this SAE jumprelu blocks.4.hook_resid_post 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_16Load this SAE jumprelu blocks.4.hook_resid_post 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_28Load this SAE jumprelu blocks.4.hook_resid_post 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_51Load this SAE jumprelu gemma-2-9b/4-gemmascope-res-131k__l0-51 blocks.4.hook_resid_post 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_6Load this SAE jumprelu blocks.4.hook_resid_post 4 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/average_l0_9Load this SAE jumprelu blocks.4.hook_resid_post 4 131072 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_10Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_18Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_234Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/4-gemmascope-res-16k__l0-37 blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/average_l0_91Load this SAE jumprelu blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_10Load this SAE jumprelu blocks.40.hook_resid_post 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_17Load this SAE jumprelu blocks.40.hook_resid_post 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_193Load this SAE jumprelu blocks.40.hook_resid_post 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_29Load this SAE jumprelu blocks.40.hook_resid_post 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_49Load this SAE jumprelu gemma-2-9b/40-gemmascope-res-131k__l0-49 blocks.40.hook_resid_post 40 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/average_l0_94Load this SAE jumprelu blocks.40.hook_resid_post 40 131072 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_10Load this SAE jumprelu blocks.40.hook_resid_post 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_125Load this SAE jumprelu blocks.40.hook_resid_post 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_18Load this SAE jumprelu blocks.40.hook_resid_post 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_292Load this SAE jumprelu blocks.40.hook_resid_post 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_32Load this SAE jumprelu gemma-2-9b/40-gemmascope-res-16k__l0-32 blocks.40.hook_resid_post 40 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/average_l0_61Load this SAE jumprelu blocks.40.hook_resid_post 40 16384 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_10Load this SAE jumprelu blocks.41.hook_resid_post 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_15Load this SAE jumprelu blocks.41.hook_resid_post 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_175Load this SAE jumprelu blocks.41.hook_resid_post 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_26Load this SAE jumprelu blocks.41.hook_resid_post 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_45Load this SAE jumprelu gemma-2-9b/41-gemmascope-res-131k__l0-45 blocks.41.hook_resid_post 41 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/average_l0_84Load this SAE jumprelu blocks.41.hook_resid_post 41 131072 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_10Load this SAE jumprelu blocks.41.hook_resid_post 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_113Load this SAE jumprelu blocks.41.hook_resid_post 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_16Load this SAE jumprelu blocks.41.hook_resid_post 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_270Load this SAE jumprelu blocks.41.hook_resid_post 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_28Load this SAE jumprelu blocks.41.hook_resid_post 41 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/average_l0_52Load this SAE jumprelu gemma-2-9b/41-gemmascope-res-16k__l0-52 blocks.41.hook_resid_post 41 16384 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_10Load this SAE jumprelu blocks.5.hook_resid_post 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_16Load this SAE jumprelu blocks.5.hook_resid_post 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_29Load this SAE jumprelu blocks.5.hook_resid_post 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_51Load this SAE jumprelu gemma-2-9b/5-gemmascope-res-131k__l0-51 blocks.5.hook_resid_post 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_6Load this SAE jumprelu blocks.5.hook_resid_post 5 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/average_l0_94Load this SAE jumprelu blocks.5.hook_resid_post 5 131072 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_11Load this SAE jumprelu blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_193Load this SAE jumprelu blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_20Load this SAE jumprelu blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_37Load this SAE jumprelu gemma-2-9b/5-gemmascope-res-16k__l0-37 blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/average_l0_77Load this SAE jumprelu blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_12Load this SAE jumprelu blocks.6.hook_resid_post 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_120Load this SAE jumprelu blocks.6.hook_resid_post 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_21Load this SAE jumprelu blocks.6.hook_resid_post 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_36Load this SAE jumprelu blocks.6.hook_resid_post 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_66Load this SAE jumprelu gemma-2-9b/6-gemmascope-res-131k__l0-66 blocks.6.hook_resid_post 6 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/average_l0_7Load this SAE jumprelu blocks.6.hook_resid_post 6 131072 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_14Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_224Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_25Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_47Load this SAE jumprelu gemma-2-9b/6-gemmascope-res-16k__l0-47 blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_8Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/average_l0_93Load this SAE jumprelu blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_119Load this SAE jumprelu blocks.7.hook_resid_post 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_13Load this SAE jumprelu blocks.7.hook_resid_post 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_21Load this SAE jumprelu blocks.7.hook_resid_post 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_38Load this SAE jumprelu gemma-2-9b/7-gemmascope-res-131k__l0-38 blocks.7.hook_resid_post 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_65Load this SAE jumprelu blocks.7.hook_resid_post 7 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/average_l0_8Load this SAE jumprelu blocks.7.hook_resid_post 7 131072 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_14Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_198Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_25Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_46Load this SAE jumprelu gemma-2-9b/7-gemmascope-res-16k__l0-46 blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_8Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/average_l0_92Load this SAE jumprelu blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_129Load this SAE jumprelu blocks.8.hook_resid_post 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_14Load this SAE jumprelu blocks.8.hook_resid_post 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_24Load this SAE jumprelu blocks.8.hook_resid_post 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_41Load this SAE jumprelu gemma-2-9b/8-gemmascope-res-131k__l0-41 blocks.8.hook_resid_post 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_72Load this SAE jumprelu blocks.8.hook_resid_post 8 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/average_l0_8Load this SAE jumprelu blocks.8.hook_resid_post 8 131072 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_16Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_207Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_28Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_51Load this SAE jumprelu gemma-2-9b/8-gemmascope-res-16k__l0-51 blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_9Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/average_l0_99Load this SAE jumprelu blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_134Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-131k__l0-134 blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_14Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-131k__l0-14 blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_25Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-131k__l0-25 blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_42Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-131k__l0-42 blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_75Load this SAE jumprelu blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/average_l0_8Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-131k__l0-8 blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_100Load this SAE jumprelu blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_16Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-16k__l0-16 blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_209Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-16k__l0-209 blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_28Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-16k__l0-28 blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_51Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-16k__l0-51 blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/average_l0_9Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-16k__l0-9 blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_9/width_1m/average_l0_122Load this SAE jumprelu blocks.9.hook_resid_post 9 1048576 1024 monology/pile-uncopyrighted layer_9/width_1m/average_l0_14Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-1m__l0-14 blocks.9.hook_resid_post 9 1048576 1024 monology/pile-uncopyrighted layer_9/width_1m/average_l0_24Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-1m__l0-24 blocks.9.hook_resid_post 9 1048576 1024 monology/pile-uncopyrighted layer_9/width_1m/average_l0_41Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-1m__l0-41 blocks.9.hook_resid_post 9 1048576 1024 monology/pile-uncopyrighted layer_9/width_1m/average_l0_70Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-1m__l0-70 blocks.9.hook_resid_post 9 1048576 1024 monology/pile-uncopyrighted layer_9/width_1m/average_l0_9Load this SAE jumprelu gemma-2-9b/9-gemmascope-res-1m__l0-9 blocks.9.hook_resid_post 9 1048576 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gemma-scope-9b-pt-res-canonical","title":"gemma-scope-9b-pt-res-canonical","text":"<ul> <li>Huggingface Repo: google/gemma-scope-9b-pt-res</li> <li>model: gemma-2-9b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations layer_0/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/0-gemmascope-res-16k blocks.0.hook_resid_post 0 16384 1024 monology/pile-uncopyrighted layer_1/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/1-gemmascope-res-16k blocks.1.hook_resid_post 1 16384 1024 monology/pile-uncopyrighted layer_2/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/2-gemmascope-res-16k blocks.2.hook_resid_post 2 16384 1024 monology/pile-uncopyrighted layer_3/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/3-gemmascope-res-16k blocks.3.hook_resid_post 3 16384 1024 monology/pile-uncopyrighted layer_4/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/4-gemmascope-res-16k blocks.4.hook_resid_post 4 16384 1024 monology/pile-uncopyrighted layer_5/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/5-gemmascope-res-16k blocks.5.hook_resid_post 5 16384 1024 monology/pile-uncopyrighted layer_6/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/6-gemmascope-res-16k blocks.6.hook_resid_post 6 16384 1024 monology/pile-uncopyrighted layer_7/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/7-gemmascope-res-16k blocks.7.hook_resid_post 7 16384 1024 monology/pile-uncopyrighted layer_8/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/8-gemmascope-res-16k blocks.8.hook_resid_post 8 16384 1024 monology/pile-uncopyrighted layer_9/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/9-gemmascope-res-16k blocks.9.hook_resid_post 9 16384 1024 monology/pile-uncopyrighted layer_10/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/10-gemmascope-res-16k blocks.10.hook_resid_post 10 16384 1024 monology/pile-uncopyrighted layer_11/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/11-gemmascope-res-16k blocks.11.hook_resid_post 11 16384 1024 monology/pile-uncopyrighted layer_12/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/12-gemmascope-res-16k blocks.12.hook_resid_post 12 16384 1024 monology/pile-uncopyrighted layer_13/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/13-gemmascope-res-16k blocks.13.hook_resid_post 13 16384 1024 monology/pile-uncopyrighted layer_14/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/14-gemmascope-res-16k blocks.14.hook_resid_post 14 16384 1024 monology/pile-uncopyrighted layer_15/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/15-gemmascope-res-16k blocks.15.hook_resid_post 15 16384 1024 monology/pile-uncopyrighted layer_16/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/16-gemmascope-res-16k blocks.16.hook_resid_post 16 16384 1024 monology/pile-uncopyrighted layer_17/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/17-gemmascope-res-16k blocks.17.hook_resid_post 17 16384 1024 monology/pile-uncopyrighted layer_18/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/18-gemmascope-res-16k blocks.18.hook_resid_post 18 16384 1024 monology/pile-uncopyrighted layer_19/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/19-gemmascope-res-16k blocks.19.hook_resid_post 19 16384 1024 monology/pile-uncopyrighted layer_20/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-res-16k blocks.20.hook_resid_post 20 16384 1024 monology/pile-uncopyrighted layer_21/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/21-gemmascope-res-16k blocks.21.hook_resid_post 21 16384 1024 monology/pile-uncopyrighted layer_22/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/22-gemmascope-res-16k blocks.22.hook_resid_post 22 16384 1024 monology/pile-uncopyrighted layer_23/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/23-gemmascope-res-16k blocks.23.hook_resid_post 23 16384 1024 monology/pile-uncopyrighted layer_24/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/24-gemmascope-res-16k blocks.24.hook_resid_post 24 16384 1024 monology/pile-uncopyrighted layer_25/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/25-gemmascope-res-16k blocks.25.hook_resid_post 25 16384 1024 monology/pile-uncopyrighted layer_26/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/26-gemmascope-res-16k blocks.26.hook_resid_post 26 16384 1024 monology/pile-uncopyrighted layer_27/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/27-gemmascope-res-16k blocks.27.hook_resid_post 27 16384 1024 monology/pile-uncopyrighted layer_28/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/28-gemmascope-res-16k blocks.28.hook_resid_post 28 16384 1024 monology/pile-uncopyrighted layer_29/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/29-gemmascope-res-16k blocks.29.hook_resid_post 29 16384 1024 monology/pile-uncopyrighted layer_30/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/30-gemmascope-res-16k blocks.30.hook_resid_post 30 16384 1024 monology/pile-uncopyrighted layer_31/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/31-gemmascope-res-16k blocks.31.hook_resid_post 31 16384 1024 monology/pile-uncopyrighted layer_32/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/32-gemmascope-res-16k blocks.32.hook_resid_post 32 16384 1024 monology/pile-uncopyrighted layer_33/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/33-gemmascope-res-16k blocks.33.hook_resid_post 33 16384 1024 monology/pile-uncopyrighted layer_34/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/34-gemmascope-res-16k blocks.34.hook_resid_post 34 16384 1024 monology/pile-uncopyrighted layer_35/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/35-gemmascope-res-16k blocks.35.hook_resid_post 35 16384 1024 monology/pile-uncopyrighted layer_36/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/36-gemmascope-res-16k blocks.36.hook_resid_post 36 16384 1024 monology/pile-uncopyrighted layer_37/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/37-gemmascope-res-16k blocks.37.hook_resid_post 37 16384 1024 monology/pile-uncopyrighted layer_38/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/38-gemmascope-res-16k blocks.38.hook_resid_post 38 16384 1024 monology/pile-uncopyrighted layer_39/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/39-gemmascope-res-16k blocks.39.hook_resid_post 39 16384 1024 monology/pile-uncopyrighted layer_40/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/40-gemmascope-res-16k blocks.40.hook_resid_post 40 16384 1024 monology/pile-uncopyrighted layer_41/width_16k/canonicalLoad this SAE jumprelu gemma-2-9b/41-gemmascope-res-16k blocks.41.hook_resid_post 41 16384 1024 monology/pile-uncopyrighted layer_0/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/0-gemmascope-res-131k blocks.0.hook_resid_post 0 131072 1024 monology/pile-uncopyrighted layer_1/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/1-gemmascope-res-131k blocks.1.hook_resid_post 1 131072 1024 monology/pile-uncopyrighted layer_2/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/2-gemmascope-res-131k blocks.2.hook_resid_post 2 131072 1024 monology/pile-uncopyrighted layer_3/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/3-gemmascope-res-131k blocks.3.hook_resid_post 3 131072 1024 monology/pile-uncopyrighted layer_4/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/4-gemmascope-res-131k blocks.4.hook_resid_post 4 131072 1024 monology/pile-uncopyrighted layer_5/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/5-gemmascope-res-131k blocks.5.hook_resid_post 5 131072 1024 monology/pile-uncopyrighted layer_6/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/6-gemmascope-res-131k blocks.6.hook_resid_post 6 131072 1024 monology/pile-uncopyrighted layer_7/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/7-gemmascope-res-131k blocks.7.hook_resid_post 7 131072 1024 monology/pile-uncopyrighted layer_8/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/8-gemmascope-res-131k blocks.8.hook_resid_post 8 131072 1024 monology/pile-uncopyrighted layer_9/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/9-gemmascope-res-131k blocks.9.hook_resid_post 9 131072 1024 monology/pile-uncopyrighted layer_10/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/10-gemmascope-res-131k blocks.10.hook_resid_post 10 131072 1024 monology/pile-uncopyrighted layer_11/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/11-gemmascope-res-131k blocks.11.hook_resid_post 11 131072 1024 monology/pile-uncopyrighted layer_12/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/12-gemmascope-res-131k blocks.12.hook_resid_post 12 131072 1024 monology/pile-uncopyrighted layer_13/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/13-gemmascope-res-131k blocks.13.hook_resid_post 13 131072 1024 monology/pile-uncopyrighted layer_14/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/14-gemmascope-res-131k blocks.14.hook_resid_post 14 131072 1024 monology/pile-uncopyrighted layer_15/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/15-gemmascope-res-131k blocks.15.hook_resid_post 15 131072 1024 monology/pile-uncopyrighted layer_16/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/16-gemmascope-res-131k blocks.16.hook_resid_post 16 131072 1024 monology/pile-uncopyrighted layer_17/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/17-gemmascope-res-131k blocks.17.hook_resid_post 17 131072 1024 monology/pile-uncopyrighted layer_18/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/18-gemmascope-res-131k blocks.18.hook_resid_post 18 131072 1024 monology/pile-uncopyrighted layer_19/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/19-gemmascope-res-131k blocks.19.hook_resid_post 19 131072 1024 monology/pile-uncopyrighted layer_20/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-res-131k blocks.20.hook_resid_post 20 131072 1024 monology/pile-uncopyrighted layer_21/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/21-gemmascope-res-131k blocks.21.hook_resid_post 21 131072 1024 monology/pile-uncopyrighted layer_22/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/22-gemmascope-res-131k blocks.22.hook_resid_post 22 131072 1024 monology/pile-uncopyrighted layer_23/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/23-gemmascope-res-131k blocks.23.hook_resid_post 23 131072 1024 monology/pile-uncopyrighted layer_24/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/24-gemmascope-res-131k blocks.24.hook_resid_post 24 131072 1024 monology/pile-uncopyrighted layer_25/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/25-gemmascope-res-131k blocks.25.hook_resid_post 25 131072 1024 monology/pile-uncopyrighted layer_26/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/26-gemmascope-res-131k blocks.26.hook_resid_post 26 131072 1024 monology/pile-uncopyrighted layer_27/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/27-gemmascope-res-131k blocks.27.hook_resid_post 27 131072 1024 monology/pile-uncopyrighted layer_28/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/28-gemmascope-res-131k blocks.28.hook_resid_post 28 131072 1024 monology/pile-uncopyrighted layer_29/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/29-gemmascope-res-131k blocks.29.hook_resid_post 29 131072 1024 monology/pile-uncopyrighted layer_30/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/30-gemmascope-res-131k blocks.30.hook_resid_post 30 131072 1024 monology/pile-uncopyrighted layer_31/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/31-gemmascope-res-131k blocks.31.hook_resid_post 31 131072 1024 monology/pile-uncopyrighted layer_32/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/32-gemmascope-res-131k blocks.32.hook_resid_post 32 131072 1024 monology/pile-uncopyrighted layer_33/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/33-gemmascope-res-131k blocks.33.hook_resid_post 33 131072 1024 monology/pile-uncopyrighted layer_34/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/34-gemmascope-res-131k blocks.34.hook_resid_post 34 131072 1024 monology/pile-uncopyrighted layer_35/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/35-gemmascope-res-131k blocks.35.hook_resid_post 35 131072 1024 monology/pile-uncopyrighted layer_36/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/36-gemmascope-res-131k blocks.36.hook_resid_post 36 131072 1024 monology/pile-uncopyrighted layer_37/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/37-gemmascope-res-131k blocks.37.hook_resid_post 37 131072 1024 monology/pile-uncopyrighted layer_38/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/38-gemmascope-res-131k blocks.38.hook_resid_post 38 131072 1024 monology/pile-uncopyrighted layer_39/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/39-gemmascope-res-131k blocks.39.hook_resid_post 39 131072 1024 monology/pile-uncopyrighted layer_40/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/40-gemmascope-res-131k blocks.40.hook_resid_post 40 131072 1024 monology/pile-uncopyrighted layer_41/width_131k/canonicalLoad this SAE jumprelu gemma-2-9b/41-gemmascope-res-131k blocks.41.hook_resid_post 41 131072 1024 monology/pile-uncopyrighted layer_9/width_1m/canonicalLoad this SAE jumprelu gemma-2-9b/9-gemmascope-res-1m blocks.9.hook_resid_post 9 1048576 1024 monology/pile-uncopyrighted layer_20/width_1m/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-res-1m blocks.20.hook_resid_post 20 1048576 1024 monology/pile-uncopyrighted layer_31/width_1m/canonicalLoad this SAE jumprelu gemma-2-9b/31-gemmascope-res-1m blocks.31.hook_resid_post 31 1048576 1024 monology/pile-uncopyrighted layer_20/width_32k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-res-32k blocks.20.hook_resid_post 20 32768 1024 monology/pile-uncopyrighted layer_20/width_524k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-res-524k blocks.20.hook_resid_post 20 524288 1024 monology/pile-uncopyrighted layer_20/width_65k/canonicalLoad this SAE jumprelu gemma-2-9b/20-gemmascope-res-65k blocks.20.hook_resid_post 20 65536 1024 monology/pile-uncopyrighted"},{"location":"sae_table/#gpt2-small-attn-out-v5-128k","title":"gpt2-small-attn-out-v5-128k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-128k-attn-out-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_attn_outLoad this SAE standard gpt2-small/0-att_128k-oai blocks.0.hook_attn_out 0 131072 64 Skylion007/openwebtext layer_norm blocks.1.hook_attn_outLoad this SAE standard gpt2-small/1-att_128k-oai blocks.1.hook_attn_out 1 131072 64 Skylion007/openwebtext layer_norm blocks.2.hook_attn_outLoad this SAE standard gpt2-small/2-att_128k-oai blocks.2.hook_attn_out 2 131072 64 Skylion007/openwebtext layer_norm blocks.3.hook_attn_outLoad this SAE standard gpt2-small/3-att_128k-oai blocks.3.hook_attn_out 3 131072 64 Skylion007/openwebtext layer_norm blocks.4.hook_attn_outLoad this SAE standard gpt2-small/4-att_128k-oai blocks.4.hook_attn_out 4 131072 64 Skylion007/openwebtext layer_norm blocks.5.hook_attn_outLoad this SAE standard gpt2-small/5-att_128k-oai blocks.5.hook_attn_out 5 131072 64 Skylion007/openwebtext layer_norm blocks.6.hook_attn_outLoad this SAE standard gpt2-small/6-att_128k-oai blocks.6.hook_attn_out 6 131072 64 Skylion007/openwebtext layer_norm blocks.7.hook_attn_outLoad this SAE standard gpt2-small/7-att_128k-oai blocks.7.hook_attn_out 7 131072 64 Skylion007/openwebtext layer_norm blocks.8.hook_attn_outLoad this SAE standard gpt2-small/8-att_128k-oai blocks.8.hook_attn_out 8 131072 64 Skylion007/openwebtext layer_norm blocks.9.hook_attn_outLoad this SAE standard gpt2-small/9-att_128k-oai blocks.9.hook_attn_out 9 131072 64 Skylion007/openwebtext layer_norm blocks.10.hook_attn_outLoad this SAE standard gpt2-small/10-att_128k-oai blocks.10.hook_attn_out 10 131072 64 Skylion007/openwebtext layer_norm blocks.11.hook_attn_outLoad this SAE standard gpt2-small/11-att_128k-oai blocks.11.hook_attn_out 11 131072 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#gpt2-small-attn-out-v5-32k","title":"gpt2-small-attn-out-v5-32k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-32k-attn-out-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_attn_outLoad this SAE standard gpt2-small/0-att_32k-oai blocks.0.hook_attn_out 0 32768 64 Skylion007/openwebtext layer_norm blocks.1.hook_attn_outLoad this SAE standard gpt2-small/1-att_32k-oai blocks.1.hook_attn_out 1 32768 64 Skylion007/openwebtext layer_norm blocks.2.hook_attn_outLoad this SAE standard gpt2-small/2-att_32k-oai blocks.2.hook_attn_out 2 32768 64 Skylion007/openwebtext layer_norm blocks.3.hook_attn_outLoad this SAE standard gpt2-small/3-att_32k-oai blocks.3.hook_attn_out 3 32768 64 Skylion007/openwebtext layer_norm blocks.4.hook_attn_outLoad this SAE standard gpt2-small/4-att_32k-oai blocks.4.hook_attn_out 4 32768 64 Skylion007/openwebtext layer_norm blocks.5.hook_attn_outLoad this SAE standard gpt2-small/5-att_32k-oai blocks.5.hook_attn_out 5 32768 64 Skylion007/openwebtext layer_norm blocks.6.hook_attn_outLoad this SAE standard gpt2-small/6-att_32k-oai blocks.6.hook_attn_out 6 32768 64 Skylion007/openwebtext layer_norm blocks.7.hook_attn_outLoad this SAE standard gpt2-small/7-att_32k-oai blocks.7.hook_attn_out 7 32768 64 Skylion007/openwebtext layer_norm blocks.8.hook_attn_outLoad this SAE standard gpt2-small/8-att_32k-oai blocks.8.hook_attn_out 8 32768 64 Skylion007/openwebtext layer_norm blocks.9.hook_attn_outLoad this SAE standard gpt2-small/9-att_32k-oai blocks.9.hook_attn_out 9 32768 64 Skylion007/openwebtext layer_norm blocks.10.hook_attn_outLoad this SAE standard gpt2-small/10-att_32k-oai blocks.10.hook_attn_out 10 32768 64 Skylion007/openwebtext layer_norm blocks.11.hook_attn_outLoad this SAE standard gpt2-small/11-att_32k-oai blocks.11.hook_attn_out 11 32768 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#gpt2-small-hook-z-kk","title":"gpt2-small-hook-z-kk","text":"<ul> <li>Huggingface Repo: ckkissane/attn-saes-gpt2-small-all-layers</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> <li>Publication</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_zLoad this SAE standard gpt2-small/0-att-kk blocks.0.attn.hook_z 0 24576 128 Skylion007/openwebtext none blocks.1.hook_zLoad this SAE standard gpt2-small/1-att-kk blocks.1.attn.hook_z 1 24576 128 Skylion007/openwebtext none blocks.2.hook_zLoad this SAE standard gpt2-small/2-att-kk blocks.2.attn.hook_z 2 24576 128 Skylion007/openwebtext none blocks.3.hook_zLoad this SAE standard gpt2-small/3-att-kk blocks.3.attn.hook_z 3 24576 128 Skylion007/openwebtext none blocks.4.hook_zLoad this SAE standard gpt2-small/4-att-kk blocks.4.attn.hook_z 4 24576 128 Skylion007/openwebtext none blocks.5.hook_zLoad this SAE standard gpt2-small/5-att-kk blocks.5.attn.hook_z 5 49152 128 Skylion007/openwebtext none blocks.6.hook_zLoad this SAE standard gpt2-small/6-att-kk blocks.6.attn.hook_z 6 24576 128 Skylion007/openwebtext none blocks.7.hook_zLoad this SAE standard gpt2-small/7-att-kk blocks.7.attn.hook_z 7 49152 128 Skylion007/openwebtext none blocks.8.hook_zLoad this SAE standard gpt2-small/8-att-kk blocks.8.attn.hook_z 8 24576 128 Skylion007/openwebtext none blocks.9.hook_zLoad this SAE standard gpt2-small/9-att-kk blocks.9.attn.hook_z 9 24576 128 Skylion007/openwebtext none blocks.10.hook_zLoad this SAE standard gpt2-small/10-att-kk blocks.10.attn.hook_z 10 24576 128 Skylion007/openwebtext none blocks.11.hook_zLoad this SAE standard gpt2-small/11-att-kk blocks.11.attn.hook_z 11 24576 128 Skylion007/openwebtext none"},{"location":"sae_table/#gpt2-small-mlp-out-v5-128k","title":"gpt2-small-mlp-out-v5-128k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-128k-mlp-out-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_mlp_outLoad this SAE standard gpt2-small/0-mlp_128k-oai blocks.0.hook_mlp_out 0 131072 64 Skylion007/openwebtext layer_norm blocks.1.hook_mlp_outLoad this SAE standard gpt2-small/1-mlp_128k-oai blocks.1.hook_mlp_out 1 131072 64 Skylion007/openwebtext layer_norm blocks.2.hook_mlp_outLoad this SAE standard gpt2-small/2-mlp_128k-oai blocks.2.hook_mlp_out 2 131072 64 Skylion007/openwebtext layer_norm blocks.3.hook_mlp_outLoad this SAE standard gpt2-small/3-mlp_128k-oai blocks.3.hook_mlp_out 3 131072 64 Skylion007/openwebtext layer_norm blocks.4.hook_mlp_outLoad this SAE standard gpt2-small/4-mlp_128k-oai blocks.4.hook_mlp_out 4 131072 64 Skylion007/openwebtext layer_norm blocks.5.hook_mlp_outLoad this SAE standard gpt2-small/5-mlp_128k-oai blocks.5.hook_mlp_out 5 131072 64 Skylion007/openwebtext layer_norm blocks.6.hook_mlp_outLoad this SAE standard gpt2-small/6-mlp_128k-oai blocks.6.hook_mlp_out 6 131072 64 Skylion007/openwebtext layer_norm blocks.7.hook_mlp_outLoad this SAE standard gpt2-small/7-mlp_128k-oai blocks.7.hook_mlp_out 7 131072 64 Skylion007/openwebtext layer_norm blocks.8.hook_mlp_outLoad this SAE standard gpt2-small/8-mlp_128k-oai blocks.8.hook_mlp_out 8 131072 64 Skylion007/openwebtext layer_norm blocks.9.hook_mlp_outLoad this SAE standard gpt2-small/9-mlp_128k-oai blocks.9.hook_mlp_out 9 131072 64 Skylion007/openwebtext layer_norm blocks.10.hook_mlp_outLoad this SAE standard gpt2-small/10-mlp_128k-oai blocks.10.hook_mlp_out 10 131072 64 Skylion007/openwebtext layer_norm blocks.11.hook_mlp_outLoad this SAE standard gpt2-small/11-mlp_128k-oai blocks.11.hook_mlp_out 11 131072 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#gpt2-small-mlp-out-v5-32k","title":"gpt2-small-mlp-out-v5-32k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-32k-mlp-out-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_mlp_outLoad this SAE standard gpt2-small/0-mlp_32k-oai blocks.0.hook_mlp_out 0 32768 64 Skylion007/openwebtext layer_norm blocks.1.hook_mlp_outLoad this SAE standard gpt2-small/1-mlp_32k-oai blocks.1.hook_mlp_out 1 32768 64 Skylion007/openwebtext layer_norm blocks.2.hook_mlp_outLoad this SAE standard gpt2-small/2-mlp_32k-oai blocks.2.hook_mlp_out 2 32768 64 Skylion007/openwebtext layer_norm blocks.3.hook_mlp_outLoad this SAE standard gpt2-small/3-mlp_32k-oai blocks.3.hook_mlp_out 3 32768 64 Skylion007/openwebtext layer_norm blocks.4.hook_mlp_outLoad this SAE standard gpt2-small/4-mlp_32k-oai blocks.4.hook_mlp_out 4 32768 64 Skylion007/openwebtext layer_norm blocks.5.hook_mlp_outLoad this SAE standard gpt2-small/5-mlp_32k-oai blocks.5.hook_mlp_out 5 32768 64 Skylion007/openwebtext layer_norm blocks.6.hook_mlp_outLoad this SAE standard gpt2-small/6-mlp_32k-oai blocks.6.hook_mlp_out 6 32768 64 Skylion007/openwebtext layer_norm blocks.7.hook_mlp_outLoad this SAE standard gpt2-small/7-mlp_32k-oai blocks.7.hook_mlp_out 7 32768 64 Skylion007/openwebtext layer_norm blocks.8.hook_mlp_outLoad this SAE standard gpt2-small/8-mlp_32k-oai blocks.8.hook_mlp_out 8 32768 64 Skylion007/openwebtext layer_norm blocks.9.hook_mlp_outLoad this SAE standard gpt2-small/9-mlp_32k-oai blocks.9.hook_mlp_out 9 32768 64 Skylion007/openwebtext layer_norm blocks.10.hook_mlp_outLoad this SAE standard gpt2-small/10-mlp_32k-oai blocks.10.hook_mlp_out 10 32768 64 Skylion007/openwebtext layer_norm blocks.11.hook_mlp_outLoad this SAE standard gpt2-small/11-mlp_32k-oai blocks.11.hook_mlp_out 11 32768 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#gpt2-small-mlp-tm","title":"gpt2-small-mlp-tm","text":"<ul> <li>Huggingface Repo: tommmcgrath/gpt2-small-mlp-out-saes</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_mlp_outLoad this SAE standard blocks.0.hook_mlp_out 0 24576 512 Skylion007/openwebtext expected_average_only_in blocks.1.hook_mlp_outLoad this SAE standard blocks.1.hook_mlp_out 1 24576 512 Skylion007/openwebtext expected_average_only_in blocks.2.hook_mlp_outLoad this SAE standard blocks.2.hook_mlp_out 2 24576 512 Skylion007/openwebtext expected_average_only_in blocks.3.hook_mlp_outLoad this SAE standard blocks.3.hook_mlp_out 3 24576 512 Skylion007/openwebtext expected_average_only_in blocks.4.hook_mlp_outLoad this SAE standard blocks.4.hook_mlp_out 4 24576 512 Skylion007/openwebtext expected_average_only_in blocks.5.hook_mlp_outLoad this SAE standard blocks.5.hook_mlp_out 5 24576 512 Skylion007/openwebtext expected_average_only_in blocks.6.hook_mlp_outLoad this SAE standard blocks.6.hook_mlp_out 6 24576 512 Skylion007/openwebtext expected_average_only_in blocks.7.hook_mlp_outLoad this SAE standard blocks.7.hook_mlp_out 7 24576 512 Skylion007/openwebtext expected_average_only_in blocks.8.hook_mlp_outLoad this SAE standard blocks.8.hook_mlp_out 8 24576 512 Skylion007/openwebtext expected_average_only_in blocks.9.hook_mlp_outLoad this SAE standard blocks.9.hook_mlp_out 9 24576 512 Skylion007/openwebtext expected_average_only_in blocks.10.hook_mlp_outLoad this SAE standard blocks.10.hook_mlp_out 10 24576 512 Skylion007/openwebtext expected_average_only_in blocks.11.hook_mlp_outLoad this SAE standard blocks.11.hook_mlp_out 11 24576 512 Skylion007/openwebtext expected_average_only_in"},{"location":"sae_table/#gpt2-small-res-jb","title":"gpt2-small-res-jb","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-SAEs-Reformatted</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> <li>Publication</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_preLoad this SAE standard gpt2-small/0-res-jb blocks.0.hook_resid_pre 0 24576 128 Skylion007/openwebtext none blocks.1.hook_resid_preLoad this SAE standard gpt2-small/1-res-jb blocks.1.hook_resid_pre 1 24576 128 Skylion007/openwebtext none blocks.2.hook_resid_preLoad this SAE standard gpt2-small/2-res-jb blocks.2.hook_resid_pre 2 24576 128 Skylion007/openwebtext none blocks.3.hook_resid_preLoad this SAE standard gpt2-small/3-res-jb blocks.3.hook_resid_pre 3 24576 128 Skylion007/openwebtext none blocks.4.hook_resid_preLoad this SAE standard gpt2-small/4-res-jb blocks.4.hook_resid_pre 4 24576 128 Skylion007/openwebtext none blocks.5.hook_resid_preLoad this SAE standard gpt2-small/5-res-jb blocks.5.hook_resid_pre 5 24576 128 Skylion007/openwebtext none blocks.6.hook_resid_preLoad this SAE standard gpt2-small/6-res-jb blocks.6.hook_resid_pre 6 24576 128 Skylion007/openwebtext none blocks.7.hook_resid_preLoad this SAE standard gpt2-small/7-res-jb blocks.7.hook_resid_pre 7 24576 128 Skylion007/openwebtext none blocks.8.hook_resid_preLoad this SAE standard gpt2-small/8-res-jb blocks.8.hook_resid_pre 8 24576 128 Skylion007/openwebtext none blocks.9.hook_resid_preLoad this SAE standard gpt2-small/9-res-jb blocks.9.hook_resid_pre 9 24576 128 Skylion007/openwebtext none blocks.10.hook_resid_preLoad this SAE standard gpt2-small/10-res-jb blocks.10.hook_resid_pre 10 24576 128 Skylion007/openwebtext none blocks.11.hook_resid_preLoad this SAE standard gpt2-small/11-res-jb blocks.11.hook_resid_pre 11 24576 128 Skylion007/openwebtext none blocks.11.hook_resid_postLoad this SAE standard gpt2-small/12-res-jb blocks.11.hook_resid_post 11 24576 128 Skylion007/openwebtext none"},{"location":"sae_table/#gpt2-small-res-jb-feature-splitting","title":"gpt2-small-res-jb-feature-splitting","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-Feature-Splitting-Experiment-Layer-8</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.8.hook_resid_pre_768Load this SAE standard gpt2-small/8-res_fs768-jb blocks.8.hook_resid_pre 8 768 128 Skylion007/openwebtext none blocks.8.hook_resid_pre_1536Load this SAE standard gpt2-small/8-res_fs1536-jb blocks.8.hook_resid_pre 8 1536 128 Skylion007/openwebtext none blocks.8.hook_resid_pre_3072Load this SAE standard gpt2-small/8-res_fs3072-jb blocks.8.hook_resid_pre 8 3072 128 Skylion007/openwebtext none blocks.8.hook_resid_pre_6144Load this SAE standard gpt2-small/8-res_fs6144-jb blocks.8.hook_resid_pre 8 6144 128 Skylion007/openwebtext none blocks.8.hook_resid_pre_12288Load this SAE standard gpt2-small/8-res_fs12288-jb blocks.8.hook_resid_pre 8 12288 128 Skylion007/openwebtext none blocks.8.hook_resid_pre_24576Load this SAE standard gpt2-small/8-res_fs24576-jb blocks.8.hook_resid_pre 8 24576 128 Skylion007/openwebtext none blocks.8.hook_resid_pre_49152Load this SAE standard gpt2-small/8-res_fs49152-jb blocks.8.hook_resid_pre 8 49152 128 Skylion007/openwebtext none blocks.8.hook_resid_pre_98304Load this SAE standard gpt2-small/8-res_fs98304-jb blocks.8.hook_resid_pre 8 98304 128 Skylion007/openwebtext none"},{"location":"sae_table/#gpt2-small-res_sce-ajt","title":"gpt2-small-res_sce-ajt","text":"<ul> <li>Huggingface Repo: neuronpedia/gpt2-small__res_sce-ajt</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.2.hook_resid_preLoad this SAE standard gpt2-small/2-res_sce-ajt blocks.2.hook_resid_pre 2 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.6.hook_resid_preLoad this SAE standard gpt2-small/6-res_sce-ajt blocks.6.hook_resid_pre 6 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.10.hook_resid_preLoad this SAE standard gpt2-small/10-res_sce-ajt blocks.10.hook_resid_pre 10 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none"},{"location":"sae_table/#gpt2-small-res_scefr-ajt","title":"gpt2-small-res_scefr-ajt","text":"<ul> <li>Huggingface Repo: neuronpedia/gpt2-small__res_scefr-ajt</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.2.hook_resid_preLoad this SAE standard gpt2-small/2-res_scefr-ajt blocks.2.hook_resid_pre 2 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.6.hook_resid_preLoad this SAE standard gpt2-small/6-res_scefr-ajt blocks.6.hook_resid_pre 6 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.10.hook_resid_preLoad this SAE standard gpt2-small/10-res_scefr-ajt blocks.10.hook_resid_pre 10 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none"},{"location":"sae_table/#gpt2-small-res_scl-ajt","title":"gpt2-small-res_scl-ajt","text":"<ul> <li>Huggingface Repo: neuronpedia/gpt2-small__res_scl-ajt</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.2.hook_resid_preLoad this SAE standard gpt2-small/2-res_scl-ajt blocks.2.hook_resid_pre 2 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.6.hook_resid_preLoad this SAE standard gpt2-small/6-res_scl-ajt blocks.6.hook_resid_pre 6 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.10.hook_resid_preLoad this SAE standard gpt2-small/10-res_scl-ajt blocks.10.hook_resid_pre 10 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none"},{"location":"sae_table/#gpt2-small-res_sle-ajt","title":"gpt2-small-res_sle-ajt","text":"<ul> <li>Huggingface Repo: neuronpedia/gpt2-small__res_sle-ajt</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.2.hook_resid_preLoad this SAE standard gpt2-small/2-res_sle-ajt blocks.2.hook_resid_pre 2 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.6.hook_resid_preLoad this SAE standard gpt2-small/6-res_sle-ajt blocks.6.hook_resid_pre 6 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.10.hook_resid_preLoad this SAE standard gpt2-small/10-res_sle-ajt blocks.10.hook_resid_pre 10 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none"},{"location":"sae_table/#gpt2-small-res_slefr-ajt","title":"gpt2-small-res_slefr-ajt","text":"<ul> <li>Huggingface Repo: neuronpedia/gpt2-small__res_slefr-ajt</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.2.hook_resid_preLoad this SAE standard gpt2-small/2-res_slefr-ajt blocks.2.hook_resid_pre 2 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.6.hook_resid_preLoad this SAE standard gpt2-small/6-res_slefr-ajt blocks.6.hook_resid_pre 6 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.10.hook_resid_preLoad this SAE standard gpt2-small/10-res_slefr-ajt blocks.10.hook_resid_pre 10 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none"},{"location":"sae_table/#gpt2-small-res_sll-ajt","title":"gpt2-small-res_sll-ajt","text":"<ul> <li>Huggingface Repo: neuronpedia/gpt2-small__res_sll-ajt</li> <li>model: gpt2-small</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.2.hook_resid_preLoad this SAE standard gpt2-small/2-res_sll-ajt blocks.2.hook_resid_pre 2 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.6.hook_resid_preLoad this SAE standard gpt2-small/6-res_sll-ajt blocks.6.hook_resid_pre 6 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none blocks.10.hook_resid_preLoad this SAE standard gpt2-small/10-res_sll-ajt blocks.10.hook_resid_pre 10 46080 128 apollo-research/Skylion007-openwebtext-tokenizer-gpt2 none"},{"location":"sae_table/#gpt2-small-resid-mid-v5-128k","title":"gpt2-small-resid-mid-v5-128k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-128k-resid-mid-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_midLoad this SAE standard gpt2-small/0-res_mid_128k-oai blocks.0.hook_resid_mid 0 131072 64 Skylion007/openwebtext layer_norm blocks.1.hook_resid_midLoad this SAE standard gpt2-small/1-res_mid_128k-oai blocks.1.hook_resid_mid 1 131072 64 Skylion007/openwebtext layer_norm blocks.2.hook_resid_midLoad this SAE standard gpt2-small/2-res_mid_128k-oai blocks.2.hook_resid_mid 2 131072 64 Skylion007/openwebtext layer_norm blocks.3.hook_resid_midLoad this SAE standard gpt2-small/3-res_mid_128k-oai blocks.3.hook_resid_mid 3 131072 64 Skylion007/openwebtext layer_norm blocks.4.hook_resid_midLoad this SAE standard gpt2-small/4-res_mid_128k-oai blocks.4.hook_resid_mid 4 131072 64 Skylion007/openwebtext layer_norm blocks.5.hook_resid_midLoad this SAE standard gpt2-small/5-res_mid_128k-oai blocks.5.hook_resid_mid 5 131072 64 Skylion007/openwebtext layer_norm blocks.6.hook_resid_midLoad this SAE standard gpt2-small/6-res_mid_128k-oai blocks.6.hook_resid_mid 6 131072 64 Skylion007/openwebtext layer_norm blocks.7.hook_resid_midLoad this SAE standard gpt2-small/7-res_mid_128k-oai blocks.7.hook_resid_mid 7 131072 64 Skylion007/openwebtext layer_norm blocks.8.hook_resid_midLoad this SAE standard gpt2-small/8-res_mid_128k-oai blocks.8.hook_resid_mid 8 131072 64 Skylion007/openwebtext layer_norm blocks.9.hook_resid_midLoad this SAE standard gpt2-small/9-res_mid_128k-oai blocks.9.hook_resid_mid 9 131072 64 Skylion007/openwebtext layer_norm blocks.10.hook_resid_midLoad this SAE standard gpt2-small/10-res_mid_128k-oai blocks.10.hook_resid_mid 10 131072 64 Skylion007/openwebtext layer_norm blocks.11.hook_resid_midLoad this SAE standard gpt2-small/11-res_mid_128k-oai blocks.11.hook_resid_mid 11 131072 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#gpt2-small-resid-mid-v5-32k","title":"gpt2-small-resid-mid-v5-32k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-32k-resid-mid-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_midLoad this SAE standard gpt2-small/0-res_mid_32k-oai blocks.0.hook_resid_mid 0 32768 64 Skylion007/openwebtext layer_norm blocks.1.hook_resid_midLoad this SAE standard gpt2-small/1-res_mid_32k-oai blocks.1.hook_resid_mid 1 32768 64 Skylion007/openwebtext layer_norm blocks.2.hook_resid_midLoad this SAE standard gpt2-small/2-res_mid_32k-oai blocks.2.hook_resid_mid 2 32768 64 Skylion007/openwebtext layer_norm blocks.3.hook_resid_midLoad this SAE standard gpt2-small/3-res_mid_32k-oai blocks.3.hook_resid_mid 3 32768 64 Skylion007/openwebtext layer_norm blocks.4.hook_resid_midLoad this SAE standard gpt2-small/4-res_mid_32k-oai blocks.4.hook_resid_mid 4 32768 64 Skylion007/openwebtext layer_norm blocks.5.hook_resid_midLoad this SAE standard gpt2-small/5-res_mid_32k-oai blocks.5.hook_resid_mid 5 32768 64 Skylion007/openwebtext layer_norm blocks.6.hook_resid_midLoad this SAE standard gpt2-small/6-res_mid_32k-oai blocks.6.hook_resid_mid 6 32768 64 Skylion007/openwebtext layer_norm blocks.7.hook_resid_midLoad this SAE standard gpt2-small/7-res_mid_32k-oai blocks.7.hook_resid_mid 7 32768 64 Skylion007/openwebtext layer_norm blocks.8.hook_resid_midLoad this SAE standard gpt2-small/8-res_mid_32k-oai blocks.8.hook_resid_mid 8 32768 64 Skylion007/openwebtext layer_norm blocks.9.hook_resid_midLoad this SAE standard gpt2-small/9-res_mid_32k-oai blocks.9.hook_resid_mid 9 32768 64 Skylion007/openwebtext layer_norm blocks.10.hook_resid_midLoad this SAE standard gpt2-small/10-res_mid_32k-oai blocks.10.hook_resid_mid 10 32768 64 Skylion007/openwebtext layer_norm blocks.11.hook_resid_midLoad this SAE standard gpt2-small/11-res_mid_32k-oai blocks.11.hook_resid_mid 11 32768 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#gpt2-small-resid-post-v5-128k","title":"gpt2-small-resid-post-v5-128k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-128k-resid-post-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_postLoad this SAE standard gpt2-small/0-res_post_128k-oai blocks.0.hook_resid_post 0 131072 64 Skylion007/openwebtext layer_norm blocks.1.hook_resid_postLoad this SAE standard gpt2-small/1-res_post_128k-oai blocks.1.hook_resid_post 1 131072 64 Skylion007/openwebtext layer_norm blocks.2.hook_resid_postLoad this SAE standard gpt2-small/2-res_post_128k-oai blocks.2.hook_resid_post 2 131072 64 Skylion007/openwebtext layer_norm blocks.3.hook_resid_postLoad this SAE standard gpt2-small/3-res_post_128k-oai blocks.3.hook_resid_post 3 131072 64 Skylion007/openwebtext layer_norm blocks.4.hook_resid_postLoad this SAE standard gpt2-small/4-res_post_128k-oai blocks.4.hook_resid_post 4 131072 64 Skylion007/openwebtext layer_norm blocks.5.hook_resid_postLoad this SAE standard gpt2-small/5-res_post_128k-oai blocks.5.hook_resid_post 5 131072 64 Skylion007/openwebtext layer_norm blocks.6.hook_resid_postLoad this SAE standard gpt2-small/6-res_post_128k-oai blocks.6.hook_resid_post 6 131072 64 Skylion007/openwebtext layer_norm blocks.7.hook_resid_postLoad this SAE standard gpt2-small/7-res_post_128k-oai blocks.7.hook_resid_post 7 131072 64 Skylion007/openwebtext layer_norm blocks.8.hook_resid_postLoad this SAE standard gpt2-small/8-res_post_128k-oai blocks.8.hook_resid_post 8 131072 64 Skylion007/openwebtext layer_norm blocks.9.hook_resid_postLoad this SAE standard gpt2-small/9-res_post_128k-oai blocks.9.hook_resid_post 9 131072 64 Skylion007/openwebtext layer_norm blocks.10.hook_resid_postLoad this SAE standard gpt2-small/10-res_post_128k-oai blocks.10.hook_resid_post 10 131072 64 Skylion007/openwebtext layer_norm blocks.11.hook_resid_postLoad this SAE standard gpt2-small/11-res_post_128k-oai blocks.11.hook_resid_post 11 131072 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#gpt2-small-resid-post-v5-32k","title":"gpt2-small-resid-post-v5-32k","text":"<ul> <li>Huggingface Repo: jbloom/GPT2-Small-OAI-v5-32k-resid-post-SAEs</li> <li>model: gpt2-small</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_postLoad this SAE standard gpt2-small/0-res_post_32k-oai blocks.0.hook_resid_post 0 32768 64 Skylion007/openwebtext layer_norm blocks.1.hook_resid_postLoad this SAE standard gpt2-small/1-res_post_32k-oai blocks.1.hook_resid_post 1 32768 64 Skylion007/openwebtext layer_norm blocks.2.hook_resid_postLoad this SAE standard gpt2-small/2-res_post_32k-oai blocks.2.hook_resid_post 2 32768 64 Skylion007/openwebtext layer_norm blocks.3.hook_resid_postLoad this SAE standard gpt2-small/3-res_post_32k-oai blocks.3.hook_resid_post 3 32768 64 Skylion007/openwebtext layer_norm blocks.4.hook_resid_postLoad this SAE standard gpt2-small/4-res_post_32k-oai blocks.4.hook_resid_post 4 32768 64 Skylion007/openwebtext layer_norm blocks.5.hook_resid_postLoad this SAE standard gpt2-small/5-res_post_32k-oai blocks.5.hook_resid_post 5 32768 64 Skylion007/openwebtext layer_norm blocks.6.hook_resid_postLoad this SAE standard gpt2-small/6-res_post_32k-oai blocks.6.hook_resid_post 6 32768 64 Skylion007/openwebtext layer_norm blocks.7.hook_resid_postLoad this SAE standard gpt2-small/7-res_post_32k-oai blocks.7.hook_resid_post 7 32768 64 Skylion007/openwebtext layer_norm blocks.8.hook_resid_postLoad this SAE standard gpt2-small/8-res_post_32k-oai blocks.8.hook_resid_post 8 32768 64 Skylion007/openwebtext layer_norm blocks.9.hook_resid_postLoad this SAE standard gpt2-small/9-res_post_32k-oai blocks.9.hook_resid_post 9 32768 64 Skylion007/openwebtext layer_norm blocks.10.hook_resid_postLoad this SAE standard gpt2-small/10-res_post_32k-oai blocks.10.hook_resid_post 10 32768 64 Skylion007/openwebtext layer_norm blocks.11.hook_resid_postLoad this SAE standard gpt2-small/11-res_post_32k-oai blocks.11.hook_resid_post 11 32768 64 Skylion007/openwebtext layer_norm"},{"location":"sae_table/#llama-3-8b-it-res-jh","title":"llama-3-8b-it-res-jh","text":"<ul> <li>Huggingface Repo: Juliushanhanhan/llama-3-8b-it-res</li> <li>model: meta-llama/Meta-Llama-3-8B-Instruct</li> <li>Additional Links:<ul> <li>Dashboards</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.25.hook_resid_postLoad this SAE gated llama3-8b-it/25-res-jh blocks.25.hook_resid_post 25 65536 1024 Juliushanhanhan/openwebtext-1b-llama3-tokenized-cxt-1024 expected_average_only_in"},{"location":"sae_table/#llama_scope_lxa_32x","title":"llama_scope_lxa_32x","text":"<ul> <li>Huggingface Repo: fnlp/Llama3_1-8B-Base-LXA-32x</li> <li>model: meta-llama/Llama-3.1-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations l0a_32xLoad this SAE jumprelu llama3.1-8b/0-llamascope-att-131k blocks.0.hook_attn_out 0 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l1a_32xLoad this SAE jumprelu llama3.1-8b/1-llamascope-att-131k blocks.1.hook_attn_out 1 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l2a_32xLoad this SAE jumprelu llama3.1-8b/2-llamascope-att-131k blocks.2.hook_attn_out 2 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l3a_32xLoad this SAE jumprelu llama3.1-8b/3-llamascope-att-131k blocks.3.hook_attn_out 3 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l4a_32xLoad this SAE jumprelu llama3.1-8b/4-llamascope-att-131k blocks.4.hook_attn_out 4 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l5a_32xLoad this SAE jumprelu llama3.1-8b/5-llamascope-att-131k blocks.5.hook_attn_out 5 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l6a_32xLoad this SAE jumprelu llama3.1-8b/6-llamascope-att-131k blocks.6.hook_attn_out 6 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l7a_32xLoad this SAE jumprelu llama3.1-8b/7-llamascope-att-131k blocks.7.hook_attn_out 7 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l8a_32xLoad this SAE jumprelu llama3.1-8b/8-llamascope-att-131k blocks.8.hook_attn_out 8 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l9a_32xLoad this SAE jumprelu llama3.1-8b/9-llamascope-att-131k blocks.9.hook_attn_out 9 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l10a_32xLoad this SAE jumprelu llama3.1-8b/10-llamascope-att-131k blocks.10.hook_attn_out 10 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l11a_32xLoad this SAE jumprelu llama3.1-8b/11-llamascope-att-131k blocks.11.hook_attn_out 11 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l12a_32xLoad this SAE jumprelu llama3.1-8b/12-llamascope-att-131k blocks.12.hook_attn_out 12 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l13a_32xLoad this SAE jumprelu llama3.1-8b/13-llamascope-att-131k blocks.13.hook_attn_out 13 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l14a_32xLoad this SAE jumprelu llama3.1-8b/14-llamascope-att-131k blocks.14.hook_attn_out 14 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l15a_32xLoad this SAE jumprelu llama3.1-8b/15-llamascope-att-131k blocks.15.hook_attn_out 15 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l16a_32xLoad this SAE jumprelu llama3.1-8b/16-llamascope-att-131k blocks.16.hook_attn_out 16 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l17a_32xLoad this SAE jumprelu llama3.1-8b/17-llamascope-att-131k blocks.17.hook_attn_out 17 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l18a_32xLoad this SAE jumprelu llama3.1-8b/18-llamascope-att-131k blocks.18.hook_attn_out 18 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l19a_32xLoad this SAE jumprelu llama3.1-8b/19-llamascope-att-131k blocks.19.hook_attn_out 19 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l20a_32xLoad this SAE jumprelu llama3.1-8b/20-llamascope-att-131k blocks.20.hook_attn_out 20 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l21a_32xLoad this SAE jumprelu llama3.1-8b/21-llamascope-att-131k blocks.21.hook_attn_out 21 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l22a_32xLoad this SAE jumprelu llama3.1-8b/22-llamascope-att-131k blocks.22.hook_attn_out 22 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l23a_32xLoad this SAE jumprelu llama3.1-8b/23-llamascope-att-131k blocks.23.hook_attn_out 23 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l24a_32xLoad this SAE jumprelu llama3.1-8b/24-llamascope-att-131k blocks.24.hook_attn_out 24 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l25a_32xLoad this SAE jumprelu llama3.1-8b/25-llamascope-att-131k blocks.25.hook_attn_out 25 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l26a_32xLoad this SAE jumprelu llama3.1-8b/26-llamascope-att-131k blocks.26.hook_attn_out 26 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l27a_32xLoad this SAE jumprelu llama3.1-8b/27-llamascope-att-131k blocks.27.hook_attn_out 27 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l28a_32xLoad this SAE jumprelu llama3.1-8b/28-llamascope-att-131k blocks.28.hook_attn_out 28 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l29a_32xLoad this SAE jumprelu llama3.1-8b/29-llamascope-att-131k blocks.29.hook_attn_out 29 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l30a_32xLoad this SAE jumprelu llama3.1-8b/30-llamascope-att-131k blocks.30.hook_attn_out 30 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l31a_32xLoad this SAE jumprelu llama3.1-8b/31-llamascope-att-131k blocks.31.hook_attn_out 31 131072 1024 cerebras/SlimPajama-627B expected_average_only_in"},{"location":"sae_table/#llama_scope_lxa_8x","title":"llama_scope_lxa_8x","text":"<ul> <li>Huggingface Repo: fnlp/Llama3_1-8B-Base-LXA-8x</li> <li>model: meta-llama/Llama-3.1-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations l0a_8xLoad this SAE jumprelu llama3.1-8b/0-llamascope-att-32k blocks.0.hook_attn_out 0 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l1a_8xLoad this SAE jumprelu llama3.1-8b/1-llamascope-att-32k blocks.1.hook_attn_out 1 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l2a_8xLoad this SAE jumprelu llama3.1-8b/2-llamascope-att-32k blocks.2.hook_attn_out 2 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l3a_8xLoad this SAE jumprelu llama3.1-8b/3-llamascope-att-32k blocks.3.hook_attn_out 3 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l4a_8xLoad this SAE jumprelu llama3.1-8b/4-llamascope-att-32k blocks.4.hook_attn_out 4 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l5a_8xLoad this SAE jumprelu llama3.1-8b/5-llamascope-att-32k blocks.5.hook_attn_out 5 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l6a_8xLoad this SAE jumprelu llama3.1-8b/6-llamascope-att-32k blocks.6.hook_attn_out 6 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l7a_8xLoad this SAE jumprelu llama3.1-8b/7-llamascope-att-32k blocks.7.hook_attn_out 7 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l8a_8xLoad this SAE jumprelu llama3.1-8b/8-llamascope-att-32k blocks.8.hook_attn_out 8 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l9a_8xLoad this SAE jumprelu llama3.1-8b/9-llamascope-att-32k blocks.9.hook_attn_out 9 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l10a_8xLoad this SAE jumprelu llama3.1-8b/10-llamascope-att-32k blocks.10.hook_attn_out 10 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l11a_8xLoad this SAE jumprelu llama3.1-8b/11-llamascope-att-32k blocks.11.hook_attn_out 11 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l12a_8xLoad this SAE jumprelu llama3.1-8b/12-llamascope-att-32k blocks.12.hook_attn_out 12 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l13a_8xLoad this SAE jumprelu llama3.1-8b/13-llamascope-att-32k blocks.13.hook_attn_out 13 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l14a_8xLoad this SAE jumprelu llama3.1-8b/14-llamascope-att-32k blocks.14.hook_attn_out 14 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l15a_8xLoad this SAE jumprelu llama3.1-8b/15-llamascope-att-32k blocks.15.hook_attn_out 15 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l16a_8xLoad this SAE jumprelu llama3.1-8b/16-llamascope-att-32k blocks.16.hook_attn_out 16 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l17a_8xLoad this SAE jumprelu llama3.1-8b/17-llamascope-att-32k blocks.17.hook_attn_out 17 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l18a_8xLoad this SAE jumprelu llama3.1-8b/18-llamascope-att-32k blocks.18.hook_attn_out 18 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l19a_8xLoad this SAE jumprelu llama3.1-8b/19-llamascope-att-32k blocks.19.hook_attn_out 19 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l20a_8xLoad this SAE jumprelu llama3.1-8b/20-llamascope-att-32k blocks.20.hook_attn_out 20 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l21a_8xLoad this SAE jumprelu llama3.1-8b/21-llamascope-att-32k blocks.21.hook_attn_out 21 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l22a_8xLoad this SAE jumprelu llama3.1-8b/22-llamascope-att-32k blocks.22.hook_attn_out 22 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l23a_8xLoad this SAE jumprelu llama3.1-8b/23-llamascope-att-32k blocks.23.hook_attn_out 23 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l24a_8xLoad this SAE jumprelu llama3.1-8b/24-llamascope-att-32k blocks.24.hook_attn_out 24 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l25a_8xLoad this SAE jumprelu llama3.1-8b/25-llamascope-att-32k blocks.25.hook_attn_out 25 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l26a_8xLoad this SAE jumprelu llama3.1-8b/26-llamascope-att-32k blocks.26.hook_attn_out 26 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l27a_8xLoad this SAE jumprelu llama3.1-8b/27-llamascope-att-32k blocks.27.hook_attn_out 27 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l28a_8xLoad this SAE jumprelu llama3.1-8b/28-llamascope-att-32k blocks.28.hook_attn_out 28 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l29a_8xLoad this SAE jumprelu llama3.1-8b/29-llamascope-att-32k blocks.29.hook_attn_out 29 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l30a_8xLoad this SAE jumprelu llama3.1-8b/30-llamascope-att-32k blocks.30.hook_attn_out 30 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l31a_8xLoad this SAE jumprelu llama3.1-8b/31-llamascope-att-32k blocks.31.hook_attn_out 31 32768 1024 cerebras/SlimPajama-627B expected_average_only_in"},{"location":"sae_table/#llama_scope_lxm_32x","title":"llama_scope_lxm_32x","text":"<ul> <li>Huggingface Repo: fnlp/Llama3_1-8B-Base-LXM-32x</li> <li>model: meta-llama/Llama-3.1-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations l0m_32xLoad this SAE jumprelu llama3.1-8b/0-llamascope-mlp-131k blocks.0.hook_mlp_out 0 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l1m_32xLoad this SAE jumprelu llama3.1-8b/1-llamascope-mlp-131k blocks.1.hook_mlp_out 1 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l2m_32xLoad this SAE jumprelu llama3.1-8b/2-llamascope-mlp-131k blocks.2.hook_mlp_out 2 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l3m_32xLoad this SAE jumprelu llama3.1-8b/3-llamascope-mlp-131k blocks.3.hook_mlp_out 3 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l4m_32xLoad this SAE jumprelu llama3.1-8b/4-llamascope-mlp-131k blocks.4.hook_mlp_out 4 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l5m_32xLoad this SAE jumprelu llama3.1-8b/5-llamascope-mlp-131k blocks.5.hook_mlp_out 5 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l6m_32xLoad this SAE jumprelu llama3.1-8b/6-llamascope-mlp-131k blocks.6.hook_mlp_out 6 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l7m_32xLoad this SAE jumprelu llama3.1-8b/7-llamascope-mlp-131k blocks.7.hook_mlp_out 7 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l8m_32xLoad this SAE jumprelu llama3.1-8b/8-llamascope-mlp-131k blocks.8.hook_mlp_out 8 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l9m_32xLoad this SAE jumprelu llama3.1-8b/9-llamascope-mlp-131k blocks.9.hook_mlp_out 9 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l10m_32xLoad this SAE jumprelu llama3.1-8b/10-llamascope-mlp-131k blocks.10.hook_mlp_out 10 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l11m_32xLoad this SAE jumprelu llama3.1-8b/11-llamascope-mlp-131k blocks.11.hook_mlp_out 11 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l12m_32xLoad this SAE jumprelu llama3.1-8b/12-llamascope-mlp-131k blocks.12.hook_mlp_out 12 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l13m_32xLoad this SAE jumprelu llama3.1-8b/13-llamascope-mlp-131k blocks.13.hook_mlp_out 13 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l14m_32xLoad this SAE jumprelu llama3.1-8b/14-llamascope-mlp-131k blocks.14.hook_mlp_out 14 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l15m_32xLoad this SAE jumprelu llama3.1-8b/15-llamascope-mlp-131k blocks.15.hook_mlp_out 15 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l16m_32xLoad this SAE jumprelu llama3.1-8b/16-llamascope-mlp-131k blocks.16.hook_mlp_out 16 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l17m_32xLoad this SAE jumprelu llama3.1-8b/17-llamascope-mlp-131k blocks.17.hook_mlp_out 17 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l18m_32xLoad this SAE jumprelu llama3.1-8b/18-llamascope-mlp-131k blocks.18.hook_mlp_out 18 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l19m_32xLoad this SAE jumprelu llama3.1-8b/19-llamascope-mlp-131k blocks.19.hook_mlp_out 19 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l20m_32xLoad this SAE jumprelu llama3.1-8b/20-llamascope-mlp-131k blocks.20.hook_mlp_out 20 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l21m_32xLoad this SAE jumprelu llama3.1-8b/21-llamascope-mlp-131k blocks.21.hook_mlp_out 21 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l22m_32xLoad this SAE jumprelu llama3.1-8b/22-llamascope-mlp-131k blocks.22.hook_mlp_out 22 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l23m_32xLoad this SAE jumprelu llama3.1-8b/23-llamascope-mlp-131k blocks.23.hook_mlp_out 23 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l24m_32xLoad this SAE jumprelu llama3.1-8b/24-llamascope-mlp-131k blocks.24.hook_mlp_out 24 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l25m_32xLoad this SAE jumprelu llama3.1-8b/25-llamascope-mlp-131k blocks.25.hook_mlp_out 25 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l26m_32xLoad this SAE jumprelu llama3.1-8b/26-llamascope-mlp-131k blocks.26.hook_mlp_out 26 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l27m_32xLoad this SAE jumprelu llama3.1-8b/27-llamascope-mlp-131k blocks.27.hook_mlp_out 27 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l28m_32xLoad this SAE jumprelu llama3.1-8b/28-llamascope-mlp-131k blocks.28.hook_mlp_out 28 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l29m_32xLoad this SAE jumprelu llama3.1-8b/29-llamascope-mlp-131k blocks.29.hook_mlp_out 29 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l30m_32xLoad this SAE jumprelu llama3.1-8b/30-llamascope-mlp-131k blocks.30.hook_mlp_out 30 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l31m_32xLoad this SAE jumprelu llama3.1-8b/31-llamascope-mlp-131k blocks.31.hook_mlp_out 31 131072 1024 cerebras/SlimPajama-627B expected_average_only_in"},{"location":"sae_table/#llama_scope_lxm_8x","title":"llama_scope_lxm_8x","text":"<ul> <li>Huggingface Repo: fnlp/Llama3_1-8B-Base-LXM-8x</li> <li>model: meta-llama/Llama-3.1-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations l0m_8xLoad this SAE jumprelu llama3.1-8b/0-llamascope-mlp-32k blocks.0.hook_mlp_out 0 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l1m_8xLoad this SAE jumprelu llama3.1-8b/1-llamascope-mlp-32k blocks.1.hook_mlp_out 1 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l2m_8xLoad this SAE jumprelu llama3.1-8b/2-llamascope-mlp-32k blocks.2.hook_mlp_out 2 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l3m_8xLoad this SAE jumprelu llama3.1-8b/3-llamascope-mlp-32k blocks.3.hook_mlp_out 3 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l4m_8xLoad this SAE jumprelu llama3.1-8b/4-llamascope-mlp-32k blocks.4.hook_mlp_out 4 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l5m_8xLoad this SAE jumprelu llama3.1-8b/5-llamascope-mlp-32k blocks.5.hook_mlp_out 5 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l6m_8xLoad this SAE jumprelu llama3.1-8b/6-llamascope-mlp-32k blocks.6.hook_mlp_out 6 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l7m_8xLoad this SAE jumprelu llama3.1-8b/7-llamascope-mlp-32k blocks.7.hook_mlp_out 7 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l8m_8xLoad this SAE jumprelu llama3.1-8b/8-llamascope-mlp-32k blocks.8.hook_mlp_out 8 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l9m_8xLoad this SAE jumprelu llama3.1-8b/9-llamascope-mlp-32k blocks.9.hook_mlp_out 9 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l10m_8xLoad this SAE jumprelu llama3.1-8b/10-llamascope-mlp-32k blocks.10.hook_mlp_out 10 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l11m_8xLoad this SAE jumprelu llama3.1-8b/11-llamascope-mlp-32k blocks.11.hook_mlp_out 11 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l12m_8xLoad this SAE jumprelu llama3.1-8b/12-llamascope-mlp-32k blocks.12.hook_mlp_out 12 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l13m_8xLoad this SAE jumprelu llama3.1-8b/13-llamascope-mlp-32k blocks.13.hook_mlp_out 13 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l14m_8xLoad this SAE jumprelu llama3.1-8b/14-llamascope-mlp-32k blocks.14.hook_mlp_out 14 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l15m_8xLoad this SAE jumprelu llama3.1-8b/15-llamascope-mlp-32k blocks.15.hook_mlp_out 15 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l16m_8xLoad this SAE jumprelu llama3.1-8b/16-llamascope-mlp-32k blocks.16.hook_mlp_out 16 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l17m_8xLoad this SAE jumprelu llama3.1-8b/17-llamascope-mlp-32k blocks.17.hook_mlp_out 17 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l18m_8xLoad this SAE jumprelu llama3.1-8b/18-llamascope-mlp-32k blocks.18.hook_mlp_out 18 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l19m_8xLoad this SAE jumprelu llama3.1-8b/19-llamascope-mlp-32k blocks.19.hook_mlp_out 19 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l20m_8xLoad this SAE jumprelu llama3.1-8b/20-llamascope-mlp-32k blocks.20.hook_mlp_out 20 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l21m_8xLoad this SAE jumprelu llama3.1-8b/21-llamascope-mlp-32k blocks.21.hook_mlp_out 21 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l22m_8xLoad this SAE jumprelu llama3.1-8b/22-llamascope-mlp-32k blocks.22.hook_mlp_out 22 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l23m_8xLoad this SAE jumprelu llama3.1-8b/23-llamascope-mlp-32k blocks.23.hook_mlp_out 23 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l24m_8xLoad this SAE jumprelu llama3.1-8b/24-llamascope-mlp-32k blocks.24.hook_mlp_out 24 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l25m_8xLoad this SAE jumprelu llama3.1-8b/25-llamascope-mlp-32k blocks.25.hook_mlp_out 25 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l26m_8xLoad this SAE jumprelu llama3.1-8b/26-llamascope-mlp-32k blocks.26.hook_mlp_out 26 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l27m_8xLoad this SAE jumprelu llama3.1-8b/27-llamascope-mlp-32k blocks.27.hook_mlp_out 27 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l28m_8xLoad this SAE jumprelu llama3.1-8b/28-llamascope-mlp-32k blocks.28.hook_mlp_out 28 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l29m_8xLoad this SAE jumprelu llama3.1-8b/29-llamascope-mlp-32k blocks.29.hook_mlp_out 29 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l30m_8xLoad this SAE jumprelu llama3.1-8b/30-llamascope-mlp-32k blocks.30.hook_mlp_out 30 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l31m_8xLoad this SAE jumprelu llama3.1-8b/31-llamascope-mlp-32k blocks.31.hook_mlp_out 31 32768 1024 cerebras/SlimPajama-627B expected_average_only_in"},{"location":"sae_table/#llama_scope_lxr_32x","title":"llama_scope_lxr_32x","text":"<ul> <li>Huggingface Repo: fnlp/Llama3_1-8B-Base-LXR-32x</li> <li>model: meta-llama/Llama-3.1-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations l0r_32xLoad this SAE jumprelu llama3.1-8b/0-llamascope-res-131k blocks.0.hook_resid_post 0 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l1r_32xLoad this SAE jumprelu llama3.1-8b/1-llamascope-res-131k blocks.1.hook_resid_post 1 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l2r_32xLoad this SAE jumprelu llama3.1-8b/2-llamascope-res-131k blocks.2.hook_resid_post 2 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l3r_32xLoad this SAE jumprelu llama3.1-8b/3-llamascope-res-131k blocks.3.hook_resid_post 3 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l4r_32xLoad this SAE jumprelu llama3.1-8b/4-llamascope-res-131k blocks.4.hook_resid_post 4 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l5r_32xLoad this SAE jumprelu llama3.1-8b/5-llamascope-res-131k blocks.5.hook_resid_post 5 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l6r_32xLoad this SAE jumprelu llama3.1-8b/6-llamascope-res-131k blocks.6.hook_resid_post 6 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l7r_32xLoad this SAE jumprelu llama3.1-8b/7-llamascope-res-131k blocks.7.hook_resid_post 7 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l8r_32xLoad this SAE jumprelu llama3.1-8b/8-llamascope-res-131k blocks.8.hook_resid_post 8 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l9r_32xLoad this SAE jumprelu llama3.1-8b/9-llamascope-res-131k blocks.9.hook_resid_post 9 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l10r_32xLoad this SAE jumprelu llama3.1-8b/10-llamascope-res-131k blocks.10.hook_resid_post 10 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l11r_32xLoad this SAE jumprelu llama3.1-8b/11-llamascope-res-131k blocks.11.hook_resid_post 11 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l12r_32xLoad this SAE jumprelu llama3.1-8b/12-llamascope-res-131k blocks.12.hook_resid_post 12 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l13r_32xLoad this SAE jumprelu llama3.1-8b/13-llamascope-res-131k blocks.13.hook_resid_post 13 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l14r_32xLoad this SAE jumprelu llama3.1-8b/14-llamascope-res-131k blocks.14.hook_resid_post 14 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l15r_32xLoad this SAE jumprelu llama3.1-8b/15-llamascope-res-131k blocks.15.hook_resid_post 15 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l16r_32xLoad this SAE jumprelu llama3.1-8b/16-llamascope-res-131k blocks.16.hook_resid_post 16 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l17r_32xLoad this SAE jumprelu llama3.1-8b/17-llamascope-res-131k blocks.17.hook_resid_post 17 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l18r_32xLoad this SAE jumprelu llama3.1-8b/18-llamascope-res-131k blocks.18.hook_resid_post 18 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l19r_32xLoad this SAE jumprelu llama3.1-8b/19-llamascope-res-131k blocks.19.hook_resid_post 19 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l20r_32xLoad this SAE jumprelu llama3.1-8b/20-llamascope-res-131k blocks.20.hook_resid_post 20 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l21r_32xLoad this SAE jumprelu llama3.1-8b/21-llamascope-res-131k blocks.21.hook_resid_post 21 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l22r_32xLoad this SAE jumprelu llama3.1-8b/22-llamascope-res-131k blocks.22.hook_resid_post 22 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l23r_32xLoad this SAE jumprelu llama3.1-8b/23-llamascope-res-131k blocks.23.hook_resid_post 23 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l24r_32xLoad this SAE jumprelu llama3.1-8b/24-llamascope-res-131k blocks.24.hook_resid_post 24 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l25r_32xLoad this SAE jumprelu llama3.1-8b/25-llamascope-res-131k blocks.25.hook_resid_post 25 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l26r_32xLoad this SAE jumprelu llama3.1-8b/26-llamascope-res-131k blocks.26.hook_resid_post 26 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l27r_32xLoad this SAE jumprelu llama3.1-8b/27-llamascope-res-131k blocks.27.hook_resid_post 27 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l28r_32xLoad this SAE jumprelu llama3.1-8b/28-llamascope-res-131k blocks.28.hook_resid_post 28 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l29r_32xLoad this SAE jumprelu llama3.1-8b/29-llamascope-res-131k blocks.29.hook_resid_post 29 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l30r_32xLoad this SAE jumprelu llama3.1-8b/30-llamascope-res-131k blocks.30.hook_resid_post 30 131072 1024 cerebras/SlimPajama-627B expected_average_only_in l31r_32xLoad this SAE jumprelu llama3.1-8b/31-llamascope-res-131k blocks.31.hook_resid_post 31 131072 1024 cerebras/SlimPajama-627B expected_average_only_in"},{"location":"sae_table/#llama_scope_lxr_8x","title":"llama_scope_lxr_8x","text":"<ul> <li>Huggingface Repo: fnlp/Llama3_1-8B-Base-LXR-8x</li> <li>model: meta-llama/Llama-3.1-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations l0r_8xLoad this SAE jumprelu llama3.1-8b/0-llamascope-res-32k blocks.0.hook_resid_post 0 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l1r_8xLoad this SAE jumprelu llama3.1-8b/1-llamascope-res-32k blocks.1.hook_resid_post 1 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l2r_8xLoad this SAE jumprelu llama3.1-8b/2-llamascope-res-32k blocks.2.hook_resid_post 2 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l3r_8xLoad this SAE jumprelu llama3.1-8b/3-llamascope-res-32k blocks.3.hook_resid_post 3 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l4r_8xLoad this SAE jumprelu llama3.1-8b/4-llamascope-res-32k blocks.4.hook_resid_post 4 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l5r_8xLoad this SAE jumprelu llama3.1-8b/5-llamascope-res-32k blocks.5.hook_resid_post 5 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l6r_8xLoad this SAE jumprelu llama3.1-8b/6-llamascope-res-32k blocks.6.hook_resid_post 6 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l7r_8xLoad this SAE jumprelu llama3.1-8b/7-llamascope-res-32k blocks.7.hook_resid_post 7 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l8r_8xLoad this SAE jumprelu llama3.1-8b/8-llamascope-res-32k blocks.8.hook_resid_post 8 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l9r_8xLoad this SAE jumprelu llama3.1-8b/9-llamascope-res-32k blocks.9.hook_resid_post 9 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l10r_8xLoad this SAE jumprelu llama3.1-8b/10-llamascope-res-32k blocks.10.hook_resid_post 10 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l11r_8xLoad this SAE jumprelu llama3.1-8b/11-llamascope-res-32k blocks.11.hook_resid_post 11 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l12r_8xLoad this SAE jumprelu llama3.1-8b/12-llamascope-res-32k blocks.12.hook_resid_post 12 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l13r_8xLoad this SAE jumprelu llama3.1-8b/13-llamascope-res-32k blocks.13.hook_resid_post 13 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l14r_8xLoad this SAE jumprelu llama3.1-8b/14-llamascope-res-32k blocks.14.hook_resid_post 14 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l15r_8xLoad this SAE jumprelu llama3.1-8b/15-llamascope-res-32k blocks.15.hook_resid_post 15 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l16r_8xLoad this SAE jumprelu llama3.1-8b/16-llamascope-res-32k blocks.16.hook_resid_post 16 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l17r_8xLoad this SAE jumprelu llama3.1-8b/17-llamascope-res-32k blocks.17.hook_resid_post 17 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l18r_8xLoad this SAE jumprelu llama3.1-8b/18-llamascope-res-32k blocks.18.hook_resid_post 18 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l19r_8xLoad this SAE jumprelu llama3.1-8b/19-llamascope-res-32k blocks.19.hook_resid_post 19 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l20r_8xLoad this SAE jumprelu llama3.1-8b/20-llamascope-res-32k blocks.20.hook_resid_post 20 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l21r_8xLoad this SAE jumprelu llama3.1-8b/21-llamascope-res-32k blocks.21.hook_resid_post 21 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l22r_8xLoad this SAE jumprelu llama3.1-8b/22-llamascope-res-32k blocks.22.hook_resid_post 22 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l23r_8xLoad this SAE jumprelu llama3.1-8b/23-llamascope-res-32k blocks.23.hook_resid_post 23 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l24r_8xLoad this SAE jumprelu llama3.1-8b/24-llamascope-res-32k blocks.24.hook_resid_post 24 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l25r_8xLoad this SAE jumprelu llama3.1-8b/25-llamascope-res-32k blocks.25.hook_resid_post 25 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l26r_8xLoad this SAE jumprelu llama3.1-8b/26-llamascope-res-32k blocks.26.hook_resid_post 26 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l27r_8xLoad this SAE jumprelu llama3.1-8b/27-llamascope-res-32k blocks.27.hook_resid_post 27 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l28r_8xLoad this SAE jumprelu llama3.1-8b/28-llamascope-res-32k blocks.28.hook_resid_post 28 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l29r_8xLoad this SAE jumprelu llama3.1-8b/29-llamascope-res-32k blocks.29.hook_resid_post 29 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l30r_8xLoad this SAE jumprelu llama3.1-8b/30-llamascope-res-32k blocks.30.hook_resid_post 30 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l31r_8xLoad this SAE jumprelu llama3.1-8b/31-llamascope-res-32k blocks.31.hook_resid_post 31 32768 1024 cerebras/SlimPajama-627B expected_average_only_in"},{"location":"sae_table/#llama_scope_r1_distill","title":"llama_scope_r1_distill","text":"<ul> <li>Huggingface Repo: fnlp/Llama-Scope-R1-Distill</li> <li>model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations l0r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/0-llamascope-slimpj-res-32k blocks.0.hook_resid_post 0 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l1r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/1-llamascope-slimpj-res-32k blocks.1.hook_resid_post 1 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l2r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/2-llamascope-slimpj-res-32k blocks.2.hook_resid_post 2 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l3r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/3-llamascope-slimpj-res-32k blocks.3.hook_resid_post 3 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l4r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/4-llamascope-slimpj-res-32k blocks.4.hook_resid_post 4 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l5r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/5-llamascope-slimpj-res-32k blocks.5.hook_resid_post 5 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l6r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/6-llamascope-slimpj-res-32k blocks.6.hook_resid_post 6 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l7r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/7-llamascope-slimpj-res-32k blocks.7.hook_resid_post 7 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l8r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/8-llamascope-slimpj-res-32k blocks.8.hook_resid_post 8 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l9r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/9-llamascope-slimpj-res-32k blocks.9.hook_resid_post 9 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l10r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/10-llamascope-slimpj-res-32k blocks.10.hook_resid_post 10 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l11r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/11-llamascope-slimpj-res-32k blocks.11.hook_resid_post 11 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l12r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/12-llamascope-slimpj-res-32k blocks.12.hook_resid_post 12 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l13r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/13-llamascope-slimpj-res-32k blocks.13.hook_resid_post 13 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l14r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/14-llamascope-slimpj-res-32k blocks.14.hook_resid_post 14 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l15r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/15-llamascope-slimpj-res-32k blocks.15.hook_resid_post 15 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l16r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/16-llamascope-slimpj-res-32k blocks.16.hook_resid_post 16 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l17r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/17-llamascope-slimpj-res-32k blocks.17.hook_resid_post 17 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l18r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/18-llamascope-slimpj-res-32k blocks.18.hook_resid_post 18 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l19r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/19-llamascope-slimpj-res-32k blocks.19.hook_resid_post 19 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l20r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/20-llamascope-slimpj-res-32k blocks.20.hook_resid_post 20 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l21r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/21-llamascope-slimpj-res-32k blocks.21.hook_resid_post 21 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l22r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/22-llamascope-slimpj-res-32k blocks.22.hook_resid_post 22 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l23r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/23-llamascope-slimpj-res-32k blocks.23.hook_resid_post 23 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l24r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/24-llamascope-slimpj-res-32k blocks.24.hook_resid_post 24 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l25r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/25-llamascope-slimpj-res-32k blocks.25.hook_resid_post 25 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l26r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/26-llamascope-slimpj-res-32k blocks.26.hook_resid_post 26 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l27r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/27-llamascope-slimpj-res-32k blocks.27.hook_resid_post 27 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l28r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/28-llamascope-slimpj-res-32k blocks.28.hook_resid_post 28 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l29r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/29-llamascope-slimpj-res-32k blocks.29.hook_resid_post 29 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l30r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/30-llamascope-slimpj-res-32k blocks.30.hook_resid_post 30 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l31r_800m_slimpajamaLoad this SAE jumprelu deepseek-r1-distill-llama-8b/31-llamascope-slimpj-res-32k blocks.31.hook_resid_post 31 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l0r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/0-llamascope-slimpj-openr1-res-32k blocks.0.hook_resid_post 0 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l1r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/1-llamascope-slimpj-openr1-res-32k blocks.1.hook_resid_post 1 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l2r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/2-llamascope-slimpj-openr1-res-32k blocks.2.hook_resid_post 2 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l3r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/3-llamascope-slimpj-openr1-res-32k blocks.3.hook_resid_post 3 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l4r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/4-llamascope-slimpj-openr1-res-32k blocks.4.hook_resid_post 4 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l5r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/5-llamascope-slimpj-openr1-res-32k blocks.5.hook_resid_post 5 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l6r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/6-llamascope-slimpj-openr1-res-32k blocks.6.hook_resid_post 6 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l7r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/7-llamascope-slimpj-openr1-res-32k blocks.7.hook_resid_post 7 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l8r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/8-llamascope-slimpj-openr1-res-32k blocks.8.hook_resid_post 8 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l9r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/9-llamascope-slimpj-openr1-res-32k blocks.9.hook_resid_post 9 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l10r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/10-llamascope-slimpj-openr1-res-32k blocks.10.hook_resid_post 10 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l11r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/11-llamascope-slimpj-openr1-res-32k blocks.11.hook_resid_post 11 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l12r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/12-llamascope-slimpj-openr1-res-32k blocks.12.hook_resid_post 12 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l13r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/13-llamascope-slimpj-openr1-res-32k blocks.13.hook_resid_post 13 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l14r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/14-llamascope-slimpj-openr1-res-32k blocks.14.hook_resid_post 14 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l15r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/15-llamascope-slimpj-openr1-res-32k blocks.15.hook_resid_post 15 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l16r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/16-llamascope-slimpj-openr1-res-32k blocks.16.hook_resid_post 16 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l17r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/17-llamascope-slimpj-openr1-res-32k blocks.17.hook_resid_post 17 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l18r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/18-llamascope-slimpj-openr1-res-32k blocks.18.hook_resid_post 18 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l19r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/19-llamascope-slimpj-openr1-res-32k blocks.19.hook_resid_post 19 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l20r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/20-llamascope-slimpj-openr1-res-32k blocks.20.hook_resid_post 20 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l21r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/21-llamascope-slimpj-openr1-res-32k blocks.21.hook_resid_post 21 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l22r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/22-llamascope-slimpj-openr1-res-32k blocks.22.hook_resid_post 22 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l23r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/23-llamascope-slimpj-openr1-res-32k blocks.23.hook_resid_post 23 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l24r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/24-llamascope-slimpj-openr1-res-32k blocks.24.hook_resid_post 24 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l25r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/25-llamascope-slimpj-openr1-res-32k blocks.25.hook_resid_post 25 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l26r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/26-llamascope-slimpj-openr1-res-32k blocks.26.hook_resid_post 26 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l27r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/27-llamascope-slimpj-openr1-res-32k blocks.27.hook_resid_post 27 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l28r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/28-llamascope-slimpj-openr1-res-32k blocks.28.hook_resid_post 28 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l29r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/29-llamascope-slimpj-openr1-res-32k blocks.29.hook_resid_post 29 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l30r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/30-llamascope-slimpj-openr1-res-32k blocks.30.hook_resid_post 30 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l31r_400m_slimpajama_400m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/31-llamascope-slimpj-openr1-res-32k blocks.31.hook_resid_post 31 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l0r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/0-llamascope-openr1-res-32k blocks.0.hook_resid_post 0 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l1r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/1-llamascope-openr1-res-32k blocks.1.hook_resid_post 1 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l2r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/2-llamascope-openr1-res-32k blocks.2.hook_resid_post 2 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l3r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/3-llamascope-openr1-res-32k blocks.3.hook_resid_post 3 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l4r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/4-llamascope-openr1-res-32k blocks.4.hook_resid_post 4 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l5r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/5-llamascope-openr1-res-32k blocks.5.hook_resid_post 5 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l6r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/6-llamascope-openr1-res-32k blocks.6.hook_resid_post 6 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l7r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/7-llamascope-openr1-res-32k blocks.7.hook_resid_post 7 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l8r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/8-llamascope-openr1-res-32k blocks.8.hook_resid_post 8 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l9r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/9-llamascope-openr1-res-32k blocks.9.hook_resid_post 9 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l10r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/10-llamascope-openr1-res-32k blocks.10.hook_resid_post 10 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l11r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/11-llamascope-openr1-res-32k blocks.11.hook_resid_post 11 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l12r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/12-llamascope-openr1-res-32k blocks.12.hook_resid_post 12 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l13r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/13-llamascope-openr1-res-32k blocks.13.hook_resid_post 13 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l14r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/14-llamascope-openr1-res-32k blocks.14.hook_resid_post 14 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l15r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/15-llamascope-openr1-res-32k blocks.15.hook_resid_post 15 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l16r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/16-llamascope-openr1-res-32k blocks.16.hook_resid_post 16 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l17r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/17-llamascope-openr1-res-32k blocks.17.hook_resid_post 17 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l18r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/18-llamascope-openr1-res-32k blocks.18.hook_resid_post 18 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l19r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/19-llamascope-openr1-res-32k blocks.19.hook_resid_post 19 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l20r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/20-llamascope-openr1-res-32k blocks.20.hook_resid_post 20 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l21r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/21-llamascope-openr1-res-32k blocks.21.hook_resid_post 21 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l22r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/22-llamascope-openr1-res-32k blocks.22.hook_resid_post 22 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l23r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/23-llamascope-openr1-res-32k blocks.23.hook_resid_post 23 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l24r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/24-llamascope-openr1-res-32k blocks.24.hook_resid_post 24 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l25r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/25-llamascope-openr1-res-32k blocks.25.hook_resid_post 25 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l26r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/26-llamascope-openr1-res-32k blocks.26.hook_resid_post 26 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l27r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/27-llamascope-openr1-res-32k blocks.27.hook_resid_post 27 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l28r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/28-llamascope-openr1-res-32k blocks.28.hook_resid_post 28 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l29r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/29-llamascope-openr1-res-32k blocks.29.hook_resid_post 29 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l30r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/30-llamascope-openr1-res-32k blocks.30.hook_resid_post 30 32768 1024 cerebras/SlimPajama-627B expected_average_only_in l31r_800m_openr1_mathLoad this SAE jumprelu deepseek-r1-distill-llama-8b/31-llamascope-openr1-res-32k blocks.31.hook_resid_post 31 32768 1024 cerebras/SlimPajama-627B expected_average_only_in"},{"location":"sae_table/#mistral-7b-res-wg","title":"mistral-7b-res-wg","text":"<ul> <li>Huggingface Repo: JoshEngels/Mistral-7B-Residual-Stream-SAEs</li> <li>model: mistral-7b</li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.8.hook_resid_preLoad this SAE standard blocks.8.hook_resid_pre 8 65536 256 monology/pile-uncopyrighted constant_norm_rescale blocks.16.hook_resid_preLoad this SAE standard blocks.16.hook_resid_pre 16 65536 256 monology/pile-uncopyrighted constant_norm_rescale blocks.24.hook_resid_preLoad this SAE standard blocks.24.hook_resid_pre 24 65536 256 monology/pile-uncopyrighted constant_norm_rescale"},{"location":"sae_table/#pythia-70m-deduped-att-sm","title":"pythia-70m-deduped-att-sm","text":"<ul> <li>Huggingface Repo: ctigges/pythia-70m-deduped__att-sm_processed</li> <li>model: pythia-70m-deduped</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_attn_outLoad this SAE standard pythia-70m-deduped/0-att-sm blocks.0.hook_attn_out 0 32768 128 EleutherAI/the_pile_deduplicated none blocks.1.hook_attn_outLoad this SAE standard pythia-70m-deduped/1-att-sm blocks.1.hook_attn_out 1 32768 128 EleutherAI/the_pile_deduplicated none blocks.2.hook_attn_outLoad this SAE standard pythia-70m-deduped/2-att-sm blocks.2.hook_attn_out 2 32768 128 EleutherAI/the_pile_deduplicated none blocks.3.hook_attn_outLoad this SAE standard pythia-70m-deduped/3-att-sm blocks.3.hook_attn_out 3 32768 128 EleutherAI/the_pile_deduplicated none blocks.4.hook_attn_outLoad this SAE standard pythia-70m-deduped/4-att-sm blocks.4.hook_attn_out 4 32768 128 EleutherAI/the_pile_deduplicated none blocks.5.hook_attn_outLoad this SAE standard pythia-70m-deduped/5-att-sm blocks.5.hook_attn_out 5 32768 128 EleutherAI/the_pile_deduplicated none"},{"location":"sae_table/#pythia-70m-deduped-mlp-sm","title":"pythia-70m-deduped-mlp-sm","text":"<ul> <li>Huggingface Repo: ctigges/pythia-70m-deduped__mlp-sm_processed</li> <li>model: pythia-70m-deduped</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_mlp_outLoad this SAE standard pythia-70m-deduped/0-mlp-sm blocks.0.hook_mlp_out 0 32768 128 EleutherAI/the_pile_deduplicated none blocks.1.hook_mlp_outLoad this SAE standard pythia-70m-deduped/1-mlp-sm blocks.1.hook_mlp_out 1 32768 128 EleutherAI/the_pile_deduplicated none blocks.2.hook_mlp_outLoad this SAE standard pythia-70m-deduped/2-mlp-sm blocks.2.hook_mlp_out 2 32768 128 EleutherAI/the_pile_deduplicated none blocks.3.hook_mlp_outLoad this SAE standard pythia-70m-deduped/3-mlp-sm blocks.3.hook_mlp_out 3 32768 128 EleutherAI/the_pile_deduplicated none blocks.4.hook_mlp_outLoad this SAE standard pythia-70m-deduped/4-mlp-sm blocks.4.hook_mlp_out 4 32768 128 EleutherAI/the_pile_deduplicated none blocks.5.hook_mlp_outLoad this SAE standard pythia-70m-deduped/5-mlp-sm blocks.5.hook_mlp_out 5 32768 128 EleutherAI/the_pile_deduplicated none"},{"location":"sae_table/#pythia-70m-deduped-res-sm","title":"pythia-70m-deduped-res-sm","text":"<ul> <li>Huggingface Repo: ctigges/pythia-70m-deduped__res-sm_processed</li> <li>model: pythia-70m-deduped</li> <li>Additional Links:<ul> <li>Dashboards</li> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_preLoad this SAE standard pythia-70m-deduped/e-att-sm blocks.0.hook_resid_pre 0 32768 128 EleutherAI/the_pile_deduplicated none blocks.0.hook_resid_postLoad this SAE standard pythia-70m-deduped/0-res-sm blocks.0.hook_resid_post 0 32768 128 EleutherAI/the_pile_deduplicated none blocks.1.hook_resid_postLoad this SAE standard pythia-70m-deduped/1-res-sm blocks.1.hook_resid_post 1 32768 128 EleutherAI/the_pile_deduplicated none blocks.2.hook_resid_postLoad this SAE standard pythia-70m-deduped/2-res-sm blocks.2.hook_resid_post 2 32768 128 EleutherAI/the_pile_deduplicated none blocks.3.hook_resid_postLoad this SAE standard pythia-70m-deduped/3-res-sm blocks.3.hook_resid_post 3 32768 128 EleutherAI/the_pile_deduplicated none blocks.4.hook_resid_postLoad this SAE standard pythia-70m-deduped/4-res-sm blocks.4.hook_resid_post 4 32768 128 EleutherAI/the_pile_deduplicated none blocks.5.hook_resid_postLoad this SAE standard pythia-70m-deduped/5-res-sm blocks.5.hook_resid_post 5 32768 128 EleutherAI/the_pile_deduplicated none"},{"location":"sae_table/#sae_bench_gemma-2-2b_topk_width-2pow12_date-1109","title":"sae_bench_gemma-2-2b_topk_width-2pow12_date-1109","text":"<ul> <li>Huggingface Repo: canrager/saebench_gemma-2-2b_width-2pow12_date-1109</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.12.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_308Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_97Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_976Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_0_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_308Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_97Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_976Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_1_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_308Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_97Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_976Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_2_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_308Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_97Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_976Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_3_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_308Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_97Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_976Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_4_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_308Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_97Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_976Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-4k__trainer_5_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_308Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_97Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_976Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_0_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_308Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_97Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_976Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_1_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_308Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_97Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_976Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_2_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_308Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_97Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_976Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_3_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_308Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_97Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_976Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_4_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_308Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_97Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_976Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-4k__trainer_5_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_308Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_97Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_976Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_0_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_308Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_97Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_976Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_1_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_308Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_97Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_976Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_2_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_308Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_97Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_976Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_3_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_308Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_97Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_976Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_4_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_308Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_97Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_976Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-4k__trainer_5_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_gemma-2-2b_topk_width-2pow14_date-1109","title":"sae_bench_gemma-2-2b_topk_width-2pow14_date-1109","text":"<ul> <li>Huggingface Repo: canrager/saebench_gemma-2-2b_width-2pow14_date-1109</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.12.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_146Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_463Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_0_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_146Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_463Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_1_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_146Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_463Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_2_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_146Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_463Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_3_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_146Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_463Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_4_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_146Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_463Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-16k__trainer_5_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_146Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_463Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_0_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_146Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_463Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_1_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_146Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_463Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_2_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_146Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_463Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_3_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_146Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_463Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_4_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_146Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_463Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-16k__trainer_5_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_146Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_463Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_0_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_146Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_463Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_1_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_146Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_463Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_2_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_146Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_463Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_3_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_146Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_463Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_4_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_146Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_463Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-16k__trainer_5_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_gemma-2-2b_topk_width-2pow16_date-1109","title":"sae_bench_gemma-2-2b_topk_width-2pow16_date-1109","text":"<ul> <li>Huggingface Repo: canrager/saebench_gemma-2-2b_width-2pow16_date-1109</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.12.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-65k__trainer_0_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-65k__trainer_1_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-65k__trainer_2_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-65k__trainer_3_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-65k__trainer_4_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/12-sae_bench-topk-res-65k__trainer_5_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-65k__trainer_0_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-65k__trainer_1_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-65k__trainer_2_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-65k__trainer_3_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-65k__trainer_4_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/19-sae_bench-topk-res-65k__trainer_5_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-65k__trainer_0_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-65k__trainer_1_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-65k__trainer_2_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-65k__trainer_3_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-65k__trainer_4_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/5-sae_bench-topk-res-65k__trainer_5_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_gemma-2-2b_vanilla_width-2pow12_date-1109","title":"sae_bench_gemma-2-2b_vanilla_width-2pow12_date-1109","text":"<ul> <li>Huggingface Repo: canrager/saebench_gemma-2-2b_width-2pow12_date-1109</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.12.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_308Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_97Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_976Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_0_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_308Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_97Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_976Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_1_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_308Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_97Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_976Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_2_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_308Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_97Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_976Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_3_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_308Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_97Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_976Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_4_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_final blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_0 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_308Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_308 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_3088Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_3088 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_30881Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_30881 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_97Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_97 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_976Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_976 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_9765Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-4k__trainer_5_step_9765 blocks.12.hook_resid_post 12 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_308Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_97Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_976Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_0_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_308Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_97Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_976Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_1_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_308Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_97Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_976Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_2_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_308Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_97Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_976Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_3_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_308Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_97Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_976Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_4_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_final blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_0 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_308Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_308 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_3088Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_3088 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_30881Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_30881 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_97Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_97 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_976Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_976 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_9765Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-4k__trainer_5_step_9765 blocks.19.hook_resid_post 19 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_308Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_97Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_976Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_0_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_308Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_97Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_976Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_1_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_308Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_97Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_976Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_2_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_308Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_97Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_976Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_3_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_308Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_97Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_976Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_4_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_final blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_0 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_308Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_308 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_3088Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_3088 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_30881Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_30881 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_97Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_97 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_976Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_976 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_9765Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-4k__trainer_5_step_9765 blocks.5.hook_resid_post 5 4096 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_gemma-2-2b_vanilla_width-2pow14_date-1109","title":"sae_bench_gemma-2-2b_vanilla_width-2pow14_date-1109","text":"<ul> <li>Huggingface Repo: canrager/saebench_gemma-2-2b_width-2pow14_date-1109</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.12.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_146Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_463Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_0_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_0_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_146Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_463Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_1_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_146Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_463Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_2_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_146Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_463Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_3_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_146Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_463Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_4_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_final blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_0 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_146Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_146 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_1464Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_1464 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_14648Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_14648 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_463Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_463 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_4632Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_4632 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5_step_46322Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-16k__trainer_5_step_46322 blocks.12.hook_resid_post 12 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_146Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_463Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_0_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_146Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_463Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_1_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_146Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_463Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_2_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_146Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_463Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_3_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_146Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_463Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_4_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_final blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_0 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_146Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_146 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_1464Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_1464 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_14648Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_14648 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_463Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_463 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_4632Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_4632 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5_step_46322Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-16k__trainer_5_step_46322 blocks.19.hook_resid_post 19 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_146Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_463Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_0_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_146Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_463Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_1_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_146Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_463Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_2_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_146Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_463Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_3_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_146Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_463Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_4_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_final blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_0 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_146Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_146 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_1464Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_1464 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_14648Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_14648 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_463Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_463 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_4632Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_4632 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5_step_46322Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-16k__trainer_5_step_46322 blocks.5.hook_resid_post 5 16384 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_gemma-2-2b_vanilla_width-2pow16_date-1109","title":"sae_bench_gemma-2-2b_vanilla_width-2pow16_date-1109","text":"<ul> <li>Huggingface Repo: canrager/saebench_gemma-2-2b_width-2pow16_date-1109</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.12.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-65k__trainer_0_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-65k__trainer_1_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-65k__trainer_2_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-65k__trainer_3_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-65k__trainer_4_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.12.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/12-sae_bench-standard-res-65k__trainer_5_step_final blocks.12.hook_resid_post 12 65536 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-65k__trainer_0_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-65k__trainer_1_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-65k__trainer_2_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-65k__trainer_3_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-65k__trainer_4_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.19.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/19-sae_bench-standard-res-65k__trainer_5_step_final blocks.19.hook_resid_post 19 64512 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_0Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-65k__trainer_0_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_1Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-65k__trainer_1_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_2Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-65k__trainer_2_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_3Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-65k__trainer_3_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_4Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-65k__trainer_4_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none blocks.5.hook_resid_post__trainer_5Load this SAE standard gemma-2-2b/5-sae_bench-standard-res-65k__trainer_5_step_final blocks.5.hook_resid_post 5 65536 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_pythia70m_sweep_gated_ctx128_0730","title":"sae_bench_pythia70m_sweep_gated_ctx128_0730","text":"<ul> <li>Huggingface Repo: canrager/lm_sae</li> <li>model: pythia-70m-deduped</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.3.hook_resid_post__trainer_0Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_0_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_1Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_1_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_10Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_10_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_12Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_12_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_13Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_13_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_14Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_14_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_15Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_15_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_16Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_16_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_17Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_17_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_18Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_18_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_19Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_19_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_2Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_2_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_3Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_3_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_4Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_4_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_5Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_5_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_6Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_6_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_7Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_7_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_8Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_8_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_9Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-4k__trainer_9_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_11Load this SAE gated pythia-70m-deduped/3-sae_bench-gated-res-16k__trainer_11_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_0Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_0_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_1Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_1_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_10Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_10_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_11Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_11_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_12Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_12_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_13Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_13_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_14Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_14_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_15Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_15_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_16Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_16_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_17Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_17_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_18Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_18_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_19Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_19_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_2Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_2_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_3Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_3_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_4Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_4_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_5Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_5_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_6Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_6_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_9Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_9_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_8Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-4k__trainer_8_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_7Load this SAE gated pythia-70m-deduped/4-sae_bench-gated-res-16k__trainer_7_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_pythia70m_sweep_panneal_ctx128_0730","title":"sae_bench_pythia70m_sweep_panneal_ctx128_0730","text":"<ul> <li>Huggingface Repo: canrager/lm_sae</li> <li>model: pythia-70m-deduped</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.3.hook_resid_post__trainer_16Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_16_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_17Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_17_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_18Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_18_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_19Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_19_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_2Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_2_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_20Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_20_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_21Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_21_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_22Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_22_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_15Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_15_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_23Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_23_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_25Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_25_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_26Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_26_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_27Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_27_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_3Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_3_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_4Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_4_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_5Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_5_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_6Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_6_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_7Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_7_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_24Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_24_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_14Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_14_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_13Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_13_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_12Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_12_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_0Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_0_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_1Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_1_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_10Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_10_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_11Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-16k__trainer_11_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_8Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_8_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_9Load this SAE standard pythia-70m-deduped/3-sae_bench-panneal-res-4k__trainer_9_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_17Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_17_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_18Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_18_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_19Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_19_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_16Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_16_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_15Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_15_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_14Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_14_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_13Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_13_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_12Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_12_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_11Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_11_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_10Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_10_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_1Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_1_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_0Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_0_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_2Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_2_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_20Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_20_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_22Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_22_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_9Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_9_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_8Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_8_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_7Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_7_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_6Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_6_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_5Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_5_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_4Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_4_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_27Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_27_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_26Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_26_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_25Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_25_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_3Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_3_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_24Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_24_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_21Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-4k__trainer_21_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_23Load this SAE standard pythia-70m-deduped/4-sae_bench-panneal-res-16k__trainer_23_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_pythia70m_sweep_standard_ctx128_0712","title":"sae_bench_pythia70m_sweep_standard_ctx128_0712","text":"<ul> <li>Huggingface Repo: canrager/lm_sae</li> <li>model: pythia-70m-deduped</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.3.hook_resid_post__trainer_10Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_10_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_11Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_11_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_8Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_8_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_7Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_7_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_6Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_6_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_5Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_5_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_4Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_4_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_3Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_3_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_2Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_2_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_19Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_19_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_18Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_18_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_17Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_17_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_16Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_16_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_15Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_15_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_14Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-16k__trainer_14_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_0Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_0_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_1Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_1_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_13Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_13_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_12Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_12_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_9Load this SAE standard pythia-70m-deduped/3-sae_bench-standard-res-4k__trainer_9_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_0Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_0_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_11Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_11_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_10Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_10_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_1Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_1_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_13Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_13_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_14Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_14_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_16Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_16_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_17Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_17_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_18Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_18_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_2Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_2_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_20Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_20_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_21Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_21_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_12Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_12_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_22Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_22_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_3Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_3_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_4Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_4_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_5Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_5_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_6Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_6_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_7Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_7_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_8Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_8_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_9Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-4k__trainer_9_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_23Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_23_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_15Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_15_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_19Load this SAE standard pythia-70m-deduped/4-sae_bench-standard-res-16k__trainer_19_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#sae_bench_pythia70m_sweep_topk_ctx128_0730","title":"sae_bench_pythia70m_sweep_topk_ctx128_0730","text":"<ul> <li>Huggingface Repo: canrager/lm_sae</li> <li>model: pythia-70m-deduped</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.3.hook_resid_post__trainer_0Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_0_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_1Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_1_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_10Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_10_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_11Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_11_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_12Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_12_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_13Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_13_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_14Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_14_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_22Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_22_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_19Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_19_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_2Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_2_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_20Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_20_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_21Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_21_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_16Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_16_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_23Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_23_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_18Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_18_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_3Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_3_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_5Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_5_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_6Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_6_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_7Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_7_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_8Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_8_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_9Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_9_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_15Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-16k__trainer_15_step_final blocks.3.hook_resid_post 3 16384 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_4Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_4_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.3.hook_resid_post__trainer_17Load this SAE standard pythia-70m-deduped/3-sae_bench-topk-res-4k__trainer_17_step_final blocks.3.hook_resid_post 3 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_13Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_13_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_14Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_14_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_15Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_15_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_16Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_16_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_17Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_17_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_18Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_18_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_19Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_19_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_2Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_2_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_20Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_20_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_21Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_21_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_22Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_22_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_23Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_23_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_3Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_3_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_4Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_4_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_5Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_5_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_6Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_6_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_7Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_7_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_12Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_12_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_11Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_11_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_10Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-16k__trainer_10_step_final blocks.4.hook_resid_post 4 16384 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_1Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_1_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_0Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_0_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_9Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_9_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none blocks.4.hook_resid_post__trainer_8Load this SAE standard pythia-70m-deduped/4-sae_bench-topk-res-4k__trainer_8_step_final blocks.4.hook_resid_post 4 4096 128 monology/pile-uncopyrighted none"},{"location":"sae_table/#gemma-2-2b-res-matryoshka-dc","title":"gemma-2-2b-res-matryoshka-dc","text":"<ul> <li>Huggingface Repo: chanind/gemma-2-2b-batch-topk-matryoshka-saes-w-32k-l0-40</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_postLoad this SAE jumprelu blocks.0.hook_resid_post 0 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.1.hook_resid_postLoad this SAE jumprelu blocks.1.hook_resid_post 1 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.2.hook_resid_postLoad this SAE jumprelu blocks.2.hook_resid_post 2 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.3.hook_resid_postLoad this SAE jumprelu blocks.3.hook_resid_post 3 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.4.hook_resid_postLoad this SAE jumprelu blocks.4.hook_resid_post 4 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.5.hook_resid_postLoad this SAE jumprelu blocks.5.hook_resid_post 5 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.6.hook_resid_postLoad this SAE jumprelu blocks.6.hook_resid_post 6 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.7.hook_resid_postLoad this SAE jumprelu blocks.7.hook_resid_post 7 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.8.hook_resid_postLoad this SAE jumprelu blocks.8.hook_resid_post 8 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.9.hook_resid_postLoad this SAE jumprelu blocks.9.hook_resid_post 9 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.10.hook_resid_postLoad this SAE jumprelu blocks.10.hook_resid_post 10 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.11.hook_resid_postLoad this SAE jumprelu blocks.11.hook_resid_post 11 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.12.hook_resid_postLoad this SAE jumprelu gemma-2-2b/12-res-matryoshka-dc blocks.12.hook_resid_post 12 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.13.hook_resid_postLoad this SAE jumprelu gemma-2-2b/13-res-matryoshka-dc blocks.13.hook_resid_post 13 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.14.hook_resid_postLoad this SAE jumprelu gemma-2-2b/14-res-matryoshka-dc blocks.14.hook_resid_post 14 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.15.hook_resid_postLoad this SAE jumprelu gemma-2-2b/15-res-matryoshka-dc blocks.15.hook_resid_post 15 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.16.hook_resid_postLoad this SAE jumprelu gemma-2-2b/16-res-matryoshka-dc blocks.16.hook_resid_post 16 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.17.hook_resid_postLoad this SAE jumprelu gemma-2-2b/17-res-matryoshka-dc blocks.17.hook_resid_post 17 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.18.hook_resid_postLoad this SAE jumprelu gemma-2-2b/18-res-matryoshka-dc blocks.18.hook_resid_post 18 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.19.hook_resid_postLoad this SAE jumprelu gemma-2-2b/19-res-matryoshka-dc blocks.19.hook_resid_post 19 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.20.hook_resid_postLoad this SAE jumprelu gemma-2-2b/20-res-matryoshka-dc blocks.20.hook_resid_post 20 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.21.hook_resid_postLoad this SAE jumprelu gemma-2-2b/21-res-matryoshka-dc blocks.21.hook_resid_post 21 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.22.hook_resid_postLoad this SAE jumprelu gemma-2-2b/22-res-matryoshka-dc blocks.22.hook_resid_post 22 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.23.hook_resid_postLoad this SAE jumprelu gemma-2-2b/23-res-matryoshka-dc blocks.23.hook_resid_post 23 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.24.hook_resid_postLoad this SAE jumprelu gemma-2-2b/24-res-matryoshka-dc blocks.24.hook_resid_post 24 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none"},{"location":"sae_table/#gemma-2-2b-res-snap-matryoshka-dc","title":"gemma-2-2b-res-snap-matryoshka-dc","text":"<ul> <li>Huggingface Repo: chanind/gemma-2-2b-batch-topk-matryoshka-saes-w-32k-l0-40</li> <li>model: gemma-2-2b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_postLoad this SAE jumprelu blocks.0.hook_resid_post 0 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.1.hook_resid_postLoad this SAE jumprelu blocks.1.hook_resid_post 1 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.2.hook_resid_postLoad this SAE jumprelu blocks.2.hook_resid_post 2 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.3.hook_resid_postLoad this SAE jumprelu blocks.3.hook_resid_post 3 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.4.hook_resid_postLoad this SAE jumprelu blocks.4.hook_resid_post 4 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.5.hook_resid_postLoad this SAE jumprelu blocks.5.hook_resid_post 5 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.6.hook_resid_postLoad this SAE jumprelu blocks.6.hook_resid_post 6 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.7.hook_resid_postLoad this SAE jumprelu blocks.7.hook_resid_post 7 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.8.hook_resid_postLoad this SAE jumprelu blocks.8.hook_resid_post 8 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.9.hook_resid_postLoad this SAE jumprelu blocks.9.hook_resid_post 9 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.10.hook_resid_postLoad this SAE jumprelu blocks.10.hook_resid_post 10 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.11.hook_resid_postLoad this SAE jumprelu blocks.11.hook_resid_post 11 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.12.hook_resid_postLoad this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.13.hook_resid_postLoad this SAE jumprelu blocks.13.hook_resid_post 13 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.14.hook_resid_postLoad this SAE jumprelu blocks.14.hook_resid_post 14 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.15.hook_resid_postLoad this SAE jumprelu blocks.15.hook_resid_post 15 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.16.hook_resid_postLoad this SAE jumprelu blocks.16.hook_resid_post 16 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.17.hook_resid_postLoad this SAE jumprelu blocks.17.hook_resid_post 17 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.18.hook_resid_postLoad this SAE jumprelu blocks.18.hook_resid_post 18 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.19.hook_resid_postLoad this SAE jumprelu blocks.19.hook_resid_post 19 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.20.hook_resid_postLoad this SAE jumprelu blocks.20.hook_resid_post 20 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.21.hook_resid_postLoad this SAE jumprelu blocks.21.hook_resid_post 21 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.22.hook_resid_postLoad this SAE jumprelu blocks.22.hook_resid_post 22 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.23.hook_resid_postLoad this SAE jumprelu blocks.23.hook_resid_post 23 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.24.hook_resid_postLoad this SAE jumprelu blocks.24.hook_resid_post 24 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none"},{"location":"sae_table/#gemma-2-9b-res-matryoshka-dc","title":"gemma-2-9b-res-matryoshka-dc","text":"<ul> <li>Huggingface Repo: chanind/gemma-2-9b-batch-topk-matryoshka-saes-w-32k-l0-60</li> <li>model: gemma-2-9b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_postLoad this SAE jumprelu blocks.0.hook_resid_post 0 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.1.hook_resid_postLoad this SAE jumprelu blocks.1.hook_resid_post 1 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.2.hook_resid_postLoad this SAE jumprelu blocks.2.hook_resid_post 2 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.3.hook_resid_postLoad this SAE jumprelu blocks.3.hook_resid_post 3 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.4.hook_resid_postLoad this SAE jumprelu blocks.4.hook_resid_post 4 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.5.hook_resid_postLoad this SAE jumprelu blocks.5.hook_resid_post 5 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.6.hook_resid_postLoad this SAE jumprelu blocks.6.hook_resid_post 6 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.7.hook_resid_postLoad this SAE jumprelu blocks.7.hook_resid_post 7 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.8.hook_resid_postLoad this SAE jumprelu blocks.8.hook_resid_post 8 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.9.hook_resid_postLoad this SAE jumprelu blocks.9.hook_resid_post 9 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.10.hook_resid_postLoad this SAE jumprelu blocks.10.hook_resid_post 10 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.11.hook_resid_postLoad this SAE jumprelu blocks.11.hook_resid_post 11 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.12.hook_resid_postLoad this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.13.hook_resid_postLoad this SAE jumprelu blocks.13.hook_resid_post 13 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.14.hook_resid_postLoad this SAE jumprelu blocks.14.hook_resid_post 14 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.15.hook_resid_postLoad this SAE jumprelu blocks.15.hook_resid_post 15 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.16.hook_resid_postLoad this SAE jumprelu blocks.16.hook_resid_post 16 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.17.hook_resid_postLoad this SAE jumprelu blocks.17.hook_resid_post 17 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.18.hook_resid_postLoad this SAE jumprelu blocks.18.hook_resid_post 18 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.19.hook_resid_postLoad this SAE jumprelu blocks.19.hook_resid_post 19 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.20.hook_resid_postLoad this SAE jumprelu gemma-2-9b/20-res-matryoshka-dc blocks.20.hook_resid_post 20 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.21.hook_resid_postLoad this SAE jumprelu blocks.21.hook_resid_post 21 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.22.hook_resid_postLoad this SAE jumprelu blocks.22.hook_resid_post 22 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.23.hook_resid_postLoad this SAE jumprelu blocks.23.hook_resid_post 23 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.24.hook_resid_postLoad this SAE jumprelu blocks.24.hook_resid_post 24 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.25.hook_resid_postLoad this SAE jumprelu blocks.25.hook_resid_post 25 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.26.hook_resid_postLoad this SAE jumprelu blocks.26.hook_resid_post 26 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.27.hook_resid_postLoad this SAE jumprelu blocks.27.hook_resid_post 27 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.28.hook_resid_postLoad this SAE jumprelu blocks.28.hook_resid_post 28 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.29.hook_resid_postLoad this SAE jumprelu blocks.29.hook_resid_post 29 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.30.hook_resid_postLoad this SAE jumprelu blocks.30.hook_resid_post 30 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.31.hook_resid_postLoad this SAE jumprelu blocks.31.hook_resid_post 31 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.32.hook_resid_postLoad this SAE jumprelu blocks.32.hook_resid_post 32 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.33.hook_resid_postLoad this SAE jumprelu blocks.33.hook_resid_post 33 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.34.hook_resid_postLoad this SAE jumprelu blocks.34.hook_resid_post 34 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.35.hook_resid_postLoad this SAE jumprelu blocks.35.hook_resid_post 35 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.36.hook_resid_postLoad this SAE jumprelu blocks.36.hook_resid_post 36 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.37.hook_resid_postLoad this SAE jumprelu blocks.37.hook_resid_post 37 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.38.hook_resid_postLoad this SAE jumprelu blocks.38.hook_resid_post 38 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.39.hook_resid_postLoad this SAE jumprelu blocks.39.hook_resid_post 39 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none blocks.40.hook_resid_postLoad this SAE jumprelu blocks.40.hook_resid_post 40 32768 1024 chanind/pile-uncopyrighted-gemma-1024-abbrv-1B none"},{"location":"sae_table/#gemma-3-1b-res-matryoshka-dc","title":"gemma-3-1b-res-matryoshka-dc","text":"<ul> <li>Huggingface Repo: chanind/gemma-3-1b-batch-topk-matryoshka-saes-w-32k-l0-40</li> <li>model: gemma-3-1b</li> <li>Additional Links:<ul> <li>Model</li> </ul> </li> </ul> id architecture neuronpedia hook_name hook_layer d_sae context_size dataset_path normalize_activations blocks.0.hook_resid_postLoad this SAE jumprelu blocks.0.hook_resid_post 0 32768 1024 monology/pile-uncopyrighted none blocks.1.hook_resid_postLoad this SAE jumprelu blocks.1.hook_resid_post 1 32768 1024 monology/pile-uncopyrighted none blocks.2.hook_resid_postLoad this SAE jumprelu blocks.2.hook_resid_post 2 32768 1024 monology/pile-uncopyrighted none blocks.3.hook_resid_postLoad this SAE jumprelu blocks.3.hook_resid_post 3 32768 1024 monology/pile-uncopyrighted none blocks.4.hook_resid_postLoad this SAE jumprelu blocks.4.hook_resid_post 4 32768 1024 monology/pile-uncopyrighted none blocks.5.hook_resid_postLoad this SAE jumprelu blocks.5.hook_resid_post 5 32768 1024 monology/pile-uncopyrighted none blocks.6.hook_resid_postLoad this SAE jumprelu blocks.6.hook_resid_post 6 32768 1024 monology/pile-uncopyrighted none blocks.7.hook_resid_postLoad this SAE jumprelu blocks.7.hook_resid_post 7 32768 1024 monology/pile-uncopyrighted none blocks.8.hook_resid_postLoad this SAE jumprelu blocks.8.hook_resid_post 8 32768 1024 monology/pile-uncopyrighted none blocks.9.hook_resid_postLoad this SAE jumprelu blocks.9.hook_resid_post 9 32768 1024 monology/pile-uncopyrighted none blocks.10.hook_resid_postLoad this SAE jumprelu blocks.10.hook_resid_post 10 32768 1024 monology/pile-uncopyrighted none blocks.11.hook_resid_postLoad this SAE jumprelu blocks.11.hook_resid_post 11 32768 1024 monology/pile-uncopyrighted none blocks.12.hook_resid_postLoad this SAE jumprelu blocks.12.hook_resid_post 12 32768 1024 monology/pile-uncopyrighted none blocks.13.hook_resid_postLoad this SAE jumprelu blocks.13.hook_resid_post 13 32768 1024 monology/pile-uncopyrighted none blocks.14.hook_resid_postLoad this SAE jumprelu blocks.14.hook_resid_post 14 32768 1024 monology/pile-uncopyrighted none blocks.15.hook_resid_postLoad this SAE jumprelu blocks.15.hook_resid_post 15 32768 1024 monology/pile-uncopyrighted none blocks.16.hook_resid_postLoad this SAE jumprelu blocks.16.hook_resid_post 16 32768 1024 monology/pile-uncopyrighted none blocks.17.hook_resid_postLoad this SAE jumprelu blocks.17.hook_resid_post 17 32768 1024 monology/pile-uncopyrighted none blocks.18.hook_resid_postLoad this SAE jumprelu blocks.18.hook_resid_post 18 32768 1024 monology/pile-uncopyrighted none blocks.19.hook_resid_postLoad this SAE jumprelu blocks.19.hook_resid_post 19 32768 1024 monology/pile-uncopyrighted none blocks.20.hook_resid_postLoad this SAE jumprelu blocks.20.hook_resid_post 20 32768 1024 monology/pile-uncopyrighted none blocks.21.hook_resid_postLoad this SAE jumprelu blocks.21.hook_resid_post 21 32768 1024 monology/pile-uncopyrighted none blocks.22.hook_resid_postLoad this SAE jumprelu blocks.22.hook_resid_post 22 32768 1024 monology/pile-uncopyrighted none blocks.23.hook_resid_postLoad this SAE jumprelu blocks.23.hook_resid_post 23 32768 1024 monology/pile-uncopyrighted none blocks.24.hook_resid_postLoad this SAE jumprelu blocks.24.hook_resid_post 24 32768 1024 monology/pile-uncopyrighted none \u00d7 Copy Code"},{"location":"training_saes/","title":"Training Sparse Autoencoders","text":"<p>Methods development for training SAEs is rapidly evolving, so these docs may change frequently. For all available training options, see LanguageModelSAERunnerConfig.</p> <p>However, we are attempting to maintain this tutorial .</p> <p>We encourage readers to join the Open Source Mechanistic Interpretability Slack for support!</p>"},{"location":"training_saes/#basic-training-setup","title":"Basic training setup","text":"<p>Training a SAE is done using the SAETrainingRunner class. This class is configured using a LanguageModelSAERunnerConfig, and has a single method, run(), which performs training.</p> <p>Some of the core config options are below:</p> <ul> <li><code>architecture</code>: The architecture of the SAE to train. This can be <code>\"standard\"</code>, <code>\"gated\"</code>, or <code>\"jumprelu\"</code>. TopK training will be coming soon!</li> <li><code>model_name</code>: The base model name to train a SAE on. This must correspond to a model from TransformerLens.</li> <li><code>hook_name</code>: This is a TransformerLens hook in the model where our SAE will be trained from. More info on hooks can be found here.</li> <li><code>dataset_path</code>: The path to a dataset on Huggingface for training.</li> <li><code>hook_layer</code>: This is an int which corresponds to the layer specified in <code>hook_name</code>. This must match! e.g. if <code>hook_name</code> is <code>\"blocks.3.hook_mlp_out\"</code>, then <code>layer</code> must be <code>3</code>.</li> <li><code>d_in</code>: The input size of the SAE. This must match the size of the hook in the model where the SAE is trained.</li> <li><code>expansion_factor</code>: The hidden layer of the SAE will have size <code>expansion_factor * d_in</code>.</li> <li><code>l1_coefficient</code>: This controls how much sparsity the SAE will have after training.</li> <li><code>training_tokens</code>: The total tokens used for training.</li> <li><code>train_batch_size_tokens</code>: The batch size used for training. Adjust this to keep the GPU saturated.</li> <li><code>model_from_pretrained_kwargs</code>: A dictionary of keyword arguments to pass to HookedTransformer.from_pretrained when loading the model. It's best to set \"center_writing_weights\" to False (this will be the default in the future).</li> </ul> <p>A sample training run from the tutorial is shown below:</p> <pre><code>total_training_steps = 30_000\nbatch_size = 4096\ntotal_training_tokens = total_training_steps * batch_size\n\nlr_warm_up_steps = 0\nlr_decay_steps = total_training_steps // 5  # 20% of training\nl1_warm_up_steps = total_training_steps // 20  # 5% of training\n\ncfg = LanguageModelSAERunnerConfig(\n    # Data Generating Function (Model + Training Distibuion)\n    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n    hook_layer=0,  # Only one layer in the model.\n    d_in=1024,  # the width of the mlp output.\n    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n    is_dataset_tokenized=True,\n    streaming=True,  # we could pre-download the token dataset if it was small.\n    # SAE Parameters\n    mse_loss_normalization=None,  # We won't normalize the mse loss,\n    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n    normalize_sae_decoder=False,\n    scale_sparsity_penalty_by_decoder_norm=True,\n    decoder_heuristic_init=True,\n    init_encoder_as_decoder_transpose=True,\n    normalize_activations=\"expected_average_only_in\",\n    # Training Parameters\n    lr=5e-5,\n    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n    adam_beta2=0.999,\n    lr_scheduler_name=\"constant\",  # constant learning rate with warmup.\n    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n    l1_coefficient=5,  # will control how sparse the feature activations are\n    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n    lp_norm=1.0,  # the L1 penalty (and not a Lp for p &lt; 1)\n    train_batch_size_tokens=batch_size,\n    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n    # Activation Store Parameters\n    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n    store_batch_size_prompts=16,\n    # Resampling protocol\n    use_ghost_grads=False,  # we don't use ghost grads anymore.\n    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n    # WANDB\n    log_to_wandb=True,  # always use wandb unless you are just testing code.\n    wandb_project=\"sae_lens_tutorial\",\n    wandb_log_frequency=30,\n    eval_every_n_wandb_logs=20,\n    # Misc\n    device=device,\n    seed=42,\n    n_checkpoints=0,\n    checkpoint_path=\"checkpoints\",\n    dtype=\"float32\"\n)\nsparse_autoencoder = SAETrainingRunner(cfg).run()\n</code></pre> <p>As you can see, the training setup provides a large number of options to explore. The full list of options can be found in the LanguageModelSAERunnerConfig class.</p>"},{"location":"training_saes/#training-topk-saes","title":"Training Topk SAEs","text":"<p>By default, SAELens will train SAEs using a L1 loss term with ReLU activation. A popular alternative architecture is the TopK architecture, which fixes the L0 of the SAE using a TopK activation function. To train a TopK SAE, set the <code>architecture</code> parameter to <code>\"topk\"</code> in the config. You can set the <code>k</code> parameter via <code>activation_fn_kwargs</code>. If not set, the default is <code>k=100</code>. The TopK architecture ignores the <code>l1_coefficient</code> parameter.</p> <pre><code>cfg = LanguageModelSAERunnerConfig(\n    architecture=\"topk\",\n    activation_fn_kwargs={\"k\": 100},\n    # ...\n)\nsparse_autoencoder = SAETrainingRunner(cfg).run()\n</code></pre>"},{"location":"training_saes/#training-jumprelu-saes","title":"Training JumpReLU SAEs","text":"<p>JumpReLU SAEs are the current state-of-the-art SAE architecture, but are often more tricky to train than other architectures. To train a JumpReLU SAE, set the <code>architecture</code> parameter to <code>\"jumprelu\"</code> in the config. JumpReLU SAEs use an sparsity penalty that is controlled using the <code>l1_coefficient</code> parameter. This is technically a misnomer as the JumpReLU sparsity penalty is not a L1 penalty, but we keep the parameter name for consistency with the L1 penalty used by the standard architecture. The JumpReLU architecture also has two additional parameters: <code>jumprelu_bandwidth</code> and <code>jumprelu_init_threshold</code>. Both of these are likely fine at their default values, but may be worth experimenting with if JumpReLU training is too slow to converge.</p> <pre><code>cfg = LanguageModelSAERunnerConfig(\n    architecture=\"jumprelu\",\n    l1_coefficient=5.0,\n    jumprelu_bandwidth=0.001,\n    jumprelu_init_threshold=0.001,\n    # ...\n)\nsparse_autoencoder = SAETrainingRunner(cfg).run()\n</code></pre>"},{"location":"training_saes/#training-gated-saes","title":"Training Gated SAEs","text":"<p>Gated SAEs are a precursor to JumpReLU SAEs, but using a simpler training procedure that should make them easier to train. To train a Gated SAE, set the <code>architecture</code> parameter to <code>\"gated\"</code> in the config. Gated SAEs use the <code>l1_coefficient</code> parameter to control the sparsity of the SAE, the same as standard SAEs. If JumpReLU training is too slow to converge, it may be worth trying a Gated SAE instead.</p> <pre><code>cfg = LanguageModelSAERunnerConfig(\n    architecture=\"gated\",\n    l1_coefficient=5.0,\n    # ...\n)\nsparse_autoencoder = SAETrainingRunner(cfg).run()\n</code></pre>"},{"location":"training_saes/#cli-runner","title":"CLI Runner","text":"<p>The SAE training runner can also be run from the command line via the <code>sae_lens.sae_training_runner</code> module. This can be useful for quickly testing different hyperparameters or running training on a remote server. The command line interface is shown below. All options to the CLI are the same as the LanguageModelSAERunnerConfig with a <code>--</code> prefix. E.g., <code>--model_name</code> is the same as <code>model_name</code> in the config.</p> <pre><code>python -m sae_lens.sae_training_runner --help\n</code></pre>"},{"location":"training_saes/#logging-to-weights-and-biases","title":"Logging to Weights and Biases","text":"<p>For any real training run, you should be logging to Weights and Biases (WandB). This will allow you to track your training progress and compare different runs. To enable WandB, set <code>log_to_wandb=True</code>. The <code>wandb_project</code> parameter in the config controls the project name in WandB. You can also control the logging frequency with <code>wandb_log_frequency</code> and <code>eval_every_n_wandb_logs</code>.</p> <p>A number of helpful metrics are logged to WandB, including the sparsity of the SAE, the mean squared error (MSE) of the SAE, dead features, and explained variance. These metrics can be used to monitor the training progress and adjust the training parameters. Below is a screenshot from one training run.</p> <p></p>"},{"location":"training_saes/#best-practices-for-real-saes","title":"Best practices for real SAEs","text":"<p>It may sound daunting to train a real SAE but nothing could be further from the truth! You can typically train a decent SAE for a real LLM on a single A100 GPU in a matter of hours.</p> <p>SAE Training best practices are still rapidly evolving, so the default settings in SAELens may not be optimal for real SAEs. Fortunately, it's easy to see what any SAE trained using SAELens used for its training configuration and just copy its values as a starting point! If there's a SAE on Huggingface trained using SAELens, you can see all the training settings used by looking at the <code>cfg.json</code> file in the SAE's repo. For instance, here's the cfg.json for a Gemma 2B standard SAE trained by Joseph Bloom. You can also get the config in SAELens as the second return value from <code>SAE.from_pretrained()</code>. For instance, the same config mentioned above can be accessed as <code>cfg_dict = SAE.from_pretrained(\"jbloom/Gemma-2b-Residual-Stream-SAEs\", \"gemma_2b_blocks.12.hook_resid_post_16384\")[1]</code>. You can browse all SAEs uploaded to Huggingface via SAELens to get some inspiration with the SAELens library tag.</p> <p>Some general performance tips:</p> <ul> <li>If your GPU supports it (most modern nvidia-GPUs do), setting <code>autocast=True</code> and <code>autocast_lm=True</code> in the config will dramatically speed up training.</li> <li>We find that often SAEs struggle to train well with <code>dtype=\"bfloat16\"</code>. We aren't sure why this is, but make sure to compare the SAE quality if you change the dtype.</li> <li>You can try turning on <code>compile_sae=True</code> and <code>compile_llm=True</code>in the config to see if it makes training faster. Your mileage may vary though, compilation can be finicky.</li> </ul>"},{"location":"training_saes/#jumprelu-saes","title":"JumpReLU SAEs","text":"<p>JumpReLU SAEs are a state-of-the-art SAE architecture from DeepMind which at present gives the best known sparsity vs reconstruction error trade-off, and is the architecture used for Gemma Scope SAEs. However, JumpReLU SAEs are slightly trickier to train than standard SAEs due to how the threshold is learned. We recommend the following tips for training JumpReLU SAEs:</p> <ul> <li>Make sure to train on enough tokens. We've found that at least 2B tokens and ideally 4B tokens is needed for good performance with the default <code>jumprelu_bandwidth</code> setting. This may vary depending on the model and SAE size though, so make sure to monitor the training logs to ensure convergence.</li> <li>Set <code>normalize_activations=\"expected_average_only_in\"</code> in the config. This helps with convergence and is generally a good idea for all SAEs.</li> </ul> <p>You can find a sample config for a Gemma-2-2B JumpReLU SAE trained via SAELens here: cfg.json</p>"},{"location":"training_saes/#checkpoints","title":"Checkpoints","text":"<p>Checkpoints allow you to save a snapshot of the SAE and sparsitity statistics during training. To enable checkpointing, set <code>n_checkpoints</code> to a value larger than 0. If WandB logging is enabled, checkpoints will be uploaded as WandB artifacts. To save checkpoints locally, the <code>checkpoint_path</code> parameter can be set to a local directory.</p>"},{"location":"training_saes/#optimizers-and-schedulers","title":"Optimizers and Schedulers","text":"<p>The SAE training runner uses the Adam optimizer with a constant learning rate by default. The optimizer betas can be controlled with the settings <code>adam_beta1</code> and <code>adam_beta2</code>.</p> <p>The learning rate scheduler can be controlled with the <code>lr_scheduler_name</code> parameter. The available schedulers are: <code>constant</code> (default), <code>consineannealing</code>, and <code>cosineannealingwarmrestarts</code>. All schedulers can be used with linear warmup and linear decay, set via <code>lr_warm_up_steps</code> and <code>lr_decay_steps</code>.</p> <p>To avoid dead features, it's often helpful to slowly increase the L1 penalty. This can be done by setting <code>l1_warm_up_steps</code> to a value larger than 0. This will linearly increase the L1 penalty over the first <code>l1_warm_up_steps</code> training steps.</p>"},{"location":"training_saes/#training-on-huggingface-models","title":"Training on Huggingface Models","text":"<p>While TransformerLens is the recommended way to use SAELens, it is also possible to use any Huggingface AutoModelForCausalLM as the model. This is useful if you want to use a model that is not supported by TransformerLens, or if you cannot use TransformerLens due to memory or performance reasons. To use a Huggingface AutoModelForCausalLM, you can specify <code>model_class_name = 'AutoModelForCausalLM'</code> in the SAE config. Your hook points will then need to correspond to the named parameters of the Huggingface model rather than the typical TransformerLens hook points. For instance, if you were using GPT2 from Huggingface, you would use <code>hook_name = 'transformer.h.1'</code> rather than <code>hook_name = 'blocks.1.hook_resid_post'</code>. Otherwise everything should work the same as with TransformerLens models.</p>"},{"location":"training_saes/#datasets-streaming-and-context-size","title":"Datasets, streaming, and context size","text":"<p>SAELens works with datasets hosted on Huggingface. However, these datsets are often very large and take a long time and a lot of disk space to download. To speed this up, you can set <code>streaming=True</code> in the config. This will stream the dataset from Huggingface during training, which will allow training to start immediately and save disk space.</p> <p>The <code>context_size</code> parameter controls the length of the prompts fed to the model. Larger context sizes will result in better SAE performance, but will also slow down training. Each training batch will be tokens of size <code>train_batch_size_tokens x context_size</code>.</p> <p>It's also possible to use pre-tokenized datasets to speed up training, since tokenization can be a bottleneck. To use a pre-tokenized dataset on Huggingface, update the <code>dataset_path</code> parameter and set <code>is_dataset_tokenized=True</code> in the config.</p>"},{"location":"training_saes/#pretokenizing-datasets","title":"Pretokenizing datasets","text":"<p>We also provider a runner, PretokenizeRunner, which can be used to pre-tokenize a dataset and upload it to Huggingface. See [PretokenizeRunnerConfig][sae_lens.PretokenizeRunnerConfig] for all available options. We also provide a pretokenizing datasets tutorial with more details.</p> <p>A sample run from the tutorial for GPT2 and the NeelNanda/c4-10k dataset is shown below.</p> <pre><code>from sae_lens import PretokenizeRunner, PretokenizeRunnerConfig\n\ncfg = PretokenizeRunnerConfig(\n    tokenizer_name=\"gpt2\",\n    dataset_path=\"NeelNanda/c4-10k\", # this is just a tiny test dataset\n    shuffle=True,\n    num_proc=4, # increase this number depending on how many CPUs you have\n\n    # tweak these settings depending on the model\n    context_size=128,\n    begin_batch_token=\"bos\",\n    begin_sequence_token=None,\n    sequence_separator_token=\"eos\",\n\n    # uncomment to upload to huggingface\n    # hf_repo_id=\"your-username/c4-10k-tokenized-gpt2\"\n\n    # uncomment to save the dataset locally\n    # save_path=\"./c4-10k-tokenized-gpt2\"\n)\n\ndataset = PretokenizeRunner(cfg).run()\n</code></pre>"},{"location":"training_saes/#list-of-pretokenized-datasets","title":"List of Pretokenized datasets","text":"<p>Below is a list of pre-tokenized datasets that can be used with SAELens. If you have a dataset you would like to add to this list, please open a PR!</p> Huggingface ID Tokenizer Source Dataset context size Created with SAELens chanind/openwebtext-gemma gemma Skylion007/openwebtext 8192 Yes chanind/openwebtext-llama3 llama3 Skylion007/openwebtext 8192 Yes apollo-research/Skylion007-openwebtext-tokenizer-EleutherAI-gpt-neox-20b EleutherAI/gpt-neox-20b Skylion007/openwebtext 2048 No apollo-research/monology-pile-uncopyrighted-tokenizer-EleutherAI-gpt-neox-20b EleutherAI/gpt-neox-20b monology/pile-uncopyrighted 2048 No apollo-research/monology-pile-uncopyrighted-tokenizer-gpt2 gpt2 monology/pile-uncopyrighted 1024 No apollo-research/Skylion007-openwebtext-tokenizer-gpt2 gpt2 Skylion007/openwebtext 1024 No GulkoA/TinyStories-tokenized-Llama-3.2 llama3.2 roneneldan/TinyStories 128 Yes"},{"location":"training_saes/#caching-activations","title":"Caching activations","text":"<p>The next step in improving performance beyond pre-tokenizing datasets is to cache model activations. This allows you to pre-calculate all the training activations for your SAE in advance so the model does not need to be run during training to generate activations. This allows rapid training of SAEs and is especially helpful for experimenting with training hyperparameters. However, pre-calculating activations can take a very large amount of disk space, so it may not always be possible.</p> <p>SAELens provides a CacheActivationsRunner class to help with pre-calculating activations. See CacheActivationsRunnerConfig for all available options. This runner intentionally shares a lot of options with LanguageModelSAERunnerConfig. These options should be set identically when using the cached activations in training. The CacheActivationsRunner can be used as below:</p> <pre><code>from sae_lens import CacheActivationsRunner, CacheActivationsRunnerConfig\n\ncfg = CacheActivationsRunnerConfig(\n    model_name=\"tiny-stories-1L-21M\",\n    hook_name=\"blocks.0.hook_mlp_out\",\n    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",\n    # ...\n    new_cached_activations_path=\"./tiny-stories-1L-21M-cache\",\n    hf_repo_id=\"your-username/tiny-stories-1L-21M-cache\", # To push to hub\n)\n\nCacheActivationsRunner(cfg).run()\n</code></pre> <p>To use the cached activations during training, set <code>use_cached_activations=True</code> and <code>cached_activations_path</code> to match the <code>new_cached_activations_path</code> above option in training configuration.</p>"},{"location":"training_saes/#uploading-saes-to-huggingface","title":"Uploading SAEs to Huggingface","text":"<p>Once you have a set of SAEs that you're happy with, your next step is to share them with the world! SAELens has a <code>upload_saes_to_huggingface()</code> function which makes this easy to do. We also provide a uploading saes to huggingface tutorial with more details.</p> <p>You'll just need to pass a dictionary of SAEs to upload along with the huggingface repo id to upload to. The dictionary keys will become the folders in the repo where each SAE will be located. It's best practice to use the hook point that the SAE was trained on as the key to make it clear to users where in the model to apply the SAE. The values of this dictionary can be either an SAE object, or a path to a saved SAE object on disk from the <code>sae.save_model()</code> method.</p> <p>A sample is shown below:</p> <pre><code>from sae_lens import upload_saes_to_huggingface\n\nsaes_dict = {\n    \"blocks.0.hook_resid_pre\": layer_0_sae,\n    \"blocks.1.hook_resid_pre\": layer_1_sae,\n    # ...\n}\n\nupload_saes_to_huggingface(\n    saes_dict,\n    hf_repo_id=\"your-username/your-sae-repo\",\n)\n</code></pre>"}]}